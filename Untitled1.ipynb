{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96938a6e-e77a-4bdd-9d47-b7734242eb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d611c6-edc2-47a6-9b96-03481f4ecc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://pandas.pydata.org/docs/user_guide/10min.html'\n",
    "output_filename = 'documentation_content.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f6dfcb-ad1a-4c6c-93ed-fd16e7acbf60",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url, timeout=10)\n",
    "response.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff754b3f-c80f-4888-96e4-91c1eebb6f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03485e4-7e27-4c01-bab7-c1b70ec5b5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d496aac-9622-4b29-8880-973dc6b25283",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9518ef4a-6baa-4b93-a185-372fd49ddc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_content = soup.find('div', class_='bd-content')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91e85b9-45a4-4ac0-afd6-03a41cd14a1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a34d4-4e69-4ecc-a776-169152249bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_content = main_content.get_text(separator='\\n', strip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a45b471-f80a-4f85-8e90-2af3396c2086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c399207a-2f96-45fc-b980-0b0aa810e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "        f.write(text_content)\n",
    "    print(f\"Success! Content saved to '{output_filename}'.\")\n",
    "\n",
    "except IOError as e:\n",
    "    print(f\"Error: Could not write to file '{output_filename}'. {e}\")\n",
    "    sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e27eee-7116-4e7b-b268-4d1bed597f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"documentation_content.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    documentation_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8118a8f8-932f-403e-9e4f-2762998783a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "texts = text_splitter.split_text(documentation_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f22a06-bd80-470a-8ef9-aa600eb8b029",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac28c56-b5c3-4084-a9e1-e53a83137ac6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc6992a-02d5-404d-909c-bcb6003849e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8f16cd-a438-45b7-a261-963f7957df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672089b0-899c-47fd-9ad1-0c03d903194f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_filename = 'documentation_content.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07950a0-6acc-47f3-8bb0-b029d8babe70",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open(input_filename, 'r', encoding='utf-8') as f:\n",
    "        documentation_text = f.read()\n",
    "            \n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file '{input_filename}' was not found.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(\"Content read successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e2239-11a7-455b-9e2f-e8f1806c3b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfb97ef-5a33-4e9c-b48c-120f0d9e9ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_text(documentation_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c82867b0-8e2a-4436-84a4-0dae8abe4284",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = len(chunks)\n",
    "print(f\"Success! The text was split into {num_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d911e6db-d9b2-4bbb-89ae-8009509451cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b20484d-6ab3-457f-abfc-9e56a8e28d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686b9ce-2527-4c4e-89eb-84f3b3f409cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'chroma_db'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0002898-24a3-46ec-b3cc-46232e2c6080",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f5bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2863e-ab4d-46a8-b009-5c69987e8d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_texts(\n",
    "    texts=chunks, \n",
    "    embedding=embedding_model,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2287282-9b7f-4b0b-a7af-e3dbceb7bd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404ae7bd-1c79-4835-a46c-e4f4811d75ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aed5852-b5f1-4fab-87ee-498808b04f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b779e26-c313-481b-b0ef-ad8b6f30c31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PERSIST_DIRECTORY = 'chroma_db'\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16390c3-00f5-4583-a2be-3c5fa7082577",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain():\n",
    "    embedding_model = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    vectordb = Chroma(\n",
    "        persist_directory=PERSIST_DIRECTORY, \n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "    \n",
    "    retriever = vectordb.as_retriever()\n",
    "    \n",
    "    #llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")\n",
    "    llm = ChatOllama(model=\"llama3\") \n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39bb9d42-46ce-403d-8db9-9ee7545efcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question(chain, query):\n",
    "    result = chain.invoke({\"query\" : query})\n",
    "    print(\"\\n Answer: \")\n",
    "    print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5c1a32-dbeb-4232-91c3-c76d55d6eb76",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = create_qa_chain()\n",
    "\n",
    "question = \"How do I create a Series in pandas?\"\n",
    "\n",
    "ask_question(qa_chain, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3e79fa-b6f3-4fb0-b556-bcc62317ae90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12da430b-fa4d-482f-80b3-407409400f80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8904238-3e1c-444c-a71b-b706c5f3a14b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c07c60e-2da1-4cf4-9a71-7b5b204f679f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66e0aaa-ed42-4b83-b6c1-3351aac67ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fba62d7-a3c6-4b28-81e7-052ff4eaaeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a20ec79-989f-40f4-b333-2a9684d4f56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b15fa7ba-d460-440c-a43c-768628f0f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Number of URL(s):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "url 0:  https://pandas.pydata.org/docs/user_guide/10min.html\n",
      "url 1:  https://pandas.pydata.org/docs/user_guide/dsintro.html\n",
      "url 2:  https://pandas.pydata.org/docs/user_guide/basics.html\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://pandas.pydata.org/docs/user_guide/10min.html', 'https://pandas.pydata.org/docs/user_guide/dsintro.html', 'https://pandas.pydata.org/docs/user_guide/basics.html']\n"
     ]
    }
   ],
   "source": [
    "count = int(input(\"Number of URL(s): \"))\n",
    "u = []\n",
    "print(count)\n",
    "\n",
    "for i in range(count):\n",
    "    url = input(f\"url {i}: \")\n",
    "    u.append(url)\n",
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f186741-1ffe-445c-9cea-ed5e8f0d06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    'https://pandas.pydata.org/docs/user_guide/10min.html',\n",
    "    'https://pandas.pydata.org/docs/user_guide/dsintro.html',\n",
    "    'https://pandas.pydata.org/docs/user_guide/basics.html'\n",
    "]\n",
    "\n",
    "output_filename = 'docs_content.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ef97a3f-0b5e-4c52-8adb-382a713f2a6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to process 3 URL(s)...\n",
      "Scraping content from: https://pandas.pydata.org/docs/user_guide/10min.html\n",
      "Scraping content from: https://pandas.pydata.org/docs/user_guide/dsintro.html\n",
      "Scraping content from: https://pandas.pydata.org/docs/user_guide/basics.html\n",
      "\\nSuccess! All content has been combined and saved to 'docs_content.txt'.\n"
     ]
    }
   ],
   "source": [
    "all_text_content = \"\"\n",
    "\n",
    "print(f\"Starting to process {len(urls)} URL(s)...\")\n",
    "\n",
    "for url in urls:\n",
    "    print(f\"Scraping content from: {url}\")\n",
    "    response = requests.get(url, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    main_content = soup.find('div', class_='bd-content')\n",
    "        \n",
    "    if main_content:\n",
    "        text_content = main_content.get_text(separator='\\\\n', strip=True)\n",
    "        all_text_content += text_content + \"\\\\n\\\\n--- Page Break ---\\\\n\\\\n\"\n",
    "    else:\n",
    "        print(f\"Warning: Could not find the main content for {url}. The page structure might be different.\")\n",
    "\n",
    "\n",
    "with open(output_filename, 'w', encoding='utf-8') as f:\n",
    "    f.write(all_text_content)\n",
    "print(f\"\\\\nSuccess! All content has been combined and saved to '{output_filename}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67a846cb-d53d-4d37-a673-f511e9414c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docs_content.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    docs_content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e63033-ecf9-4564-a423-fb03f48d4d24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User Guide\\\\n10 minutes to pandas\\\\n10 minutes to pandas\\\\n#\\\\nThis is a short introduction to pandas, geared mainly for new users.\\nYou can see more complex recipes in the\\\\nCookbook\\\\n.\\\\nCustomarily, we import as follows:\\\\nIn [1]:\\\\nimport\\\\nnumpy\\\\nas\\\\nnp\\\\nIn [2]:\\\\nimport\\\\npandas\\\\nas\\\\npd\\\\nBasic data structures in pandas\\\\n#\\\\nPandas provides two types of classes for handling data:\\\\nSeries\\\\n: a one-dimensional labeled array holding data of any type\\\\nsuch as integers, strings, Python objects etc.\\\\nDataFrame\\\\n: a two-dimensional data structure that holds data like\\na two-dimension array or a table with rows and columns.\\\\nObject creation\\\\n#\\\\nSee the\\\\nIntro to data structures section\\\\n.\\\\nCreating a\\\\nSeries\\\\nby passing a list of values, letting pandas create\\na default\\\\nRangeIndex\\\\n.\\\\nIn [3]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n3\\\\n,\\\\n5\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n6\\\\n,\\\\n8\\\\n])\\\\nIn [4]:\\\\ns\\\\nOut[4]:\\\\n0    1.0\\\\n1    3.0\\\\n2    5.0\\\\n3    NaN\\\\n4    6.0\\\\n5    8.0\\\\ndtype: float64\\\\nCreating a\\\\nDataFrame\\\\nby passing a NumPy array with a datetime index using\\\\ndate_range()\\\\nand labeled columns:\\\\nIn [5]:\\\\ndates\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n6\\\\n)\\\\nIn [6]:\\\\ndates\\\\nOut[6]:\\\\nDatetimeIndex([\\'2013-01-01\\', \\'2013-01-02\\', \\'2013-01-03\\', \\'2013-01-04\\',\\\\n\\'2013-01-05\\', \\'2013-01-06\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=\\'D\\')\\\\nIn [7]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n6\\\\n,\\\\n4\\\\n),\\\\nindex\\\\n=\\\\ndates\\\\n,\\\\ncolumns\\\\n=\\\\nlist\\\\n(\\\\n\"ABCD\"\\\\n))\\\\nIn [8]:\\\\ndf\\\\nOut[8]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988\\\\nCreating a\\\\nDataFrame\\\\nby passing a dictionary of objects where the keys are the column\\nlabels and the values are the column values.\\\\nIn [9]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n...:\\\\n{\\\\n...:\\\\n\"A\"\\\\n:\\\\n1.0\\\\n,\\\\n...:\\\\n\"B\"\\\\n:\\\\npd\\\\n.\\\\nTimestamp\\\\n(\\\\n\"20130102\"\\\\n),\\\\n...:\\\\n\"C\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n1\\\\n,\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\nrange\\\\n(\\\\n4\\\\n)),\\\\ndtype\\\\n=\\\\n\"float32\"\\\\n),\\\\n...:\\\\n\"D\"\\\\n:\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n3\\\\n]\\\\n*\\\\n4\\\\n,\\\\ndtype\\\\n=\\\\n\"int32\"\\\\n),\\\\n...:\\\\n\"E\"\\\\n:\\\\npd\\\\n.\\\\nCategorical\\\\n([\\\\n\"test\"\\\\n,\\\\n\"train\"\\\\n,\\\\n\"test\"\\\\n,\\\\n\"train\"\\\\n]),\\\\n...:\\\\n\"F\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n...:\\\\n}\\\\n...:\\\\n)\\\\n...:\\\\nIn [10]:\\\\ndf2\\\\nOut[10]:\\\\nA          B    C  D      E    F\\\\n0  1.0 2013-01-02  1.0  3   test  foo\\\\n1  1.0 2013-01-02  1.0  3  train  foo\\\\n2  1.0 2013-01-02  1.0  3   test  foo\\\\n3  1.0 2013-01-02  1.0  3  train  foo\\\\nThe columns of the resulting\\\\nDataFrame\\\\nhave different\\\\ndtypes\\\\n:\\\\nIn [11]:\\\\ndf2\\\\n.\\\\ndtypes\\\\nOut[11]:\\\\nA          float64\\\\nB    datetime64[s]\\\\nC          float32\\\\nD            int32\\\\nE         category\\\\nF           object\\\\ndtype: object\\\\nIf you’re using IPython, tab completion for column names (as well as public\\nattributes) is automatically enabled. Here’s a subset of the attributes that\\nwill be completed:\\\\nIn [12]:\\\\ndf2\\\\n.<\\\\nTAB\\\\n>\\\\n# noqa: E225, E999\\\\ndf2.A                  df2.bool\\\\ndf2.abs                df2.boxplot\\\\ndf2.add                df2.C\\\\ndf2.add_prefix         df2.clip\\\\ndf2.add_suffix         df2.columns\\\\ndf2.align              df2.copy\\\\ndf2.all                df2.count\\\\ndf2.any                df2.combine\\\\ndf2.append             df2.D\\\\ndf2.apply              df2.describe\\\\ndf2.applymap           df2.diff\\\\ndf2.B                  df2.duplicated\\\\nAs you can see, the columns\\\\nA\\\\n,\\\\nB\\\\n,\\\\nC\\\\n, and\\\\nD\\\\nare automatically\\ntab completed.\\\\nE\\\\nand\\\\nF\\\\nare there as well; the rest of the attributes have been\\ntruncated for brevity.\\\\nViewing data\\\\n#\\\\nSee the\\\\nEssentially basics functionality section\\\\n.\\\\nUse\\\\nDataFrame.head()\\\\nand\\\\nDataFrame.tail()\\\\nto view the top and bottom rows of the frame\\nrespectively:\\\\nIn [13]:\\\\ndf\\\\n.\\\\nhead\\\\n()\\\\nOut[13]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\nIn [14]:\\\\ndf\\\\n.\\\\ntail\\\\n(\\\\n3\\\\n)\\\\nOut[14]:\\\\nA         B         C         D\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988\\\\nDisplay the\\\\nDataFrame.index\\\\nor\\\\nDataFrame.columns\\\\n:\\\\nIn [15]:\\\\ndf\\\\n.\\\\nindex\\\\nOut[15]:\\\\nDatetimeIndex([\\'2013-01-01\\', \\'2013-01-02\\', \\'2013-01-03\\', \\'2013-01-04\\',\\\\n\\'2013-01-05\\', \\'2013-01-06\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=\\'D\\')\\\\nIn [16]:\\\\ndf\\\\n.\\\\ncolumns\\\\nOut[16]:\\\\nIndex([\\'A\\', \\'B\\', \\'C\\', \\'D\\'], dtype=\\'object\\')\\\\nReturn a NumPy representation of the underlying data with\\\\nDataFrame.to_numpy()\\\\nwithout the index or column labels:\\\\nIn [17]:\\\\ndf\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[17]:\\\\narray([[ 0.4691, -0.2829, -1.5091, -1.1356],\\\\n[ 1.2121, -0.1732,  0.1192, -1.0442],\\\\n[-0.8618, -2.1046, -0.4949,  1.0718],\\\\n[ 0.7216, -0.7068, -1.0396,  0.2719],\\\\n[-0.425 ,  0.567 ,  0.2762, -1.0874],\\\\n[-0.6737,  0.1136, -1.4784,  0.525 ]])\\\\nNote\\\\nNumPy arrays have one dtype for the entire array while pandas DataFrames\\nhave one dtype per column\\\\n. When you call\\\\nDataFrame.to_numpy()\\\\n, pandas will\\nfind the NumPy dtype that can hold\\\\nall\\\\nof the dtypes in the DataFrame.\\nIf the common data type is\\\\nobject\\\\n,\\\\nDataFrame.to_numpy()\\\\nwill require\\ncopying data.\\\\nIn [18]:\\\\ndf2\\\\n.\\\\ndtypes\\\\nOut[18]:\\\\nA          float64\\\\nB    datetime64[s]\\\\nC          float32\\\\nD            int32\\\\nE         category\\\\nF           object\\\\ndtype: object\\\\nIn [19]:\\\\ndf2\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[19]:\\\\narray([[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'test\\', \\'foo\\'],\\\\n[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'train\\', \\'foo\\'],\\\\n[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'test\\', \\'foo\\'],\\\\n[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'train\\', \\'foo\\']],\\\\ndtype=object)\\\\ndescribe()\\\\nshows a quick statistic summary of your data:\\\\nIn [20]:\\\\ndf\\\\n.\\\\ndescribe\\\\n()\\\\nOut[20]:\\\\nA         B         C         D\\\\ncount  6.000000  6.000000  6.000000  6.000000\\\\nmean   0.073711 -0.431125 -0.687758 -0.233103\\\\nstd    0.843157  0.922818  0.779887  0.973118\\\\nmin   -0.861849 -2.104569 -1.509059 -1.135632\\\\n25%   -0.611510 -0.600794 -1.368714 -1.076610\\\\n50%    0.022070 -0.228039 -0.767252 -0.386188\\\\n75%    0.658444  0.041933 -0.034326  0.461706\\\\nmax    1.212112  0.567020  0.276232  1.071804\\\\nTransposing your data:\\\\nIn [21]:\\\\ndf\\\\n.\\\\nT\\\\nOut[21]:\\\\n2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06\\\\nA    0.469112    1.212112   -0.861849    0.721555   -0.424972   -0.673690\\\\nB   -0.282863   -0.173215   -2.104569   -0.706771    0.567020    0.113648\\\\nC   -1.509059    0.119209   -0.494929   -1.039575    0.276232   -1.478427\\\\nD   -1.135632   -1.044236    1.071804    0.271860   -1.087401    0.524988\\\\nDataFrame.sort_index()\\\\nsorts by an axis:\\\\nIn [22]:\\\\ndf\\\\n.\\\\nsort_index\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n,\\\\nascending\\\\n=\\\\nFalse\\\\n)\\\\nOut[22]:\\\\nD         C         B         A\\\\n2013-01-01 -1.135632 -1.509059 -0.282863  0.469112\\\\n2013-01-02 -1.044236  0.119209 -0.173215  1.212112\\\\n2013-01-03  1.071804 -0.494929 -2.104569 -0.861849\\\\n2013-01-04  0.271860 -1.039575 -0.706771  0.721555\\\\n2013-01-05 -1.087401  0.276232  0.567020 -0.424972\\\\n2013-01-06  0.524988 -1.478427  0.113648 -0.673690\\\\nDataFrame.sort_values()\\\\nsorts by values:\\\\nIn [23]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"B\"\\\\n)\\\\nOut[23]:\\\\nA         B         C         D\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\nSelection\\\\n#\\\\nNote\\\\nWhile standard Python / NumPy expressions for selecting and setting are\\nintuitive and come in handy for interactive work, for production code, we\\nrecommend the optimized pandas data access methods,\\\\nDataFrame.at()\\\\n,\\\\nDataFrame.iat()\\\\n,\\\\nDataFrame.loc()\\\\nand\\\\nDataFrame.iloc()\\\\n.\\\\nSee the indexing documentation\\\\nIndexing and Selecting Data\\\\nand\\\\nMultiIndex / Advanced Indexing\\\\n.\\\\nGetitem (\\\\n[]\\\\n)\\\\n#\\\\nFor a\\\\nDataFrame\\\\n, passing a single label selects a columns and\\nyields a\\\\nSeries\\\\nequivalent to\\\\ndf.A\\\\n:\\\\nIn [24]:\\\\ndf\\\\n[\\\\n\"A\"\\\\n]\\\\nOut[24]:\\\\n2013-01-01    0.469112\\\\n2013-01-02    1.212112\\\\n2013-01-03   -0.861849\\\\n2013-01-04    0.721555\\\\n2013-01-05   -0.424972\\\\n2013-01-06   -0.673690\\\\nFreq: D, Name: A, dtype: float64\\\\nFor a\\\\nDataFrame\\\\n, passing a slice\\\\n:\\\\nselects matching rows:\\\\nIn [25]:\\\\ndf\\\\n[\\\\n0\\\\n:\\\\n3\\\\n]\\\\nOut[25]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\nIn [26]:\\\\ndf\\\\n[\\\\n\"20130102\"\\\\n:\\\\n\"20130104\"\\\\n]\\\\nOut[26]:\\\\nA         B         C         D\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\nSelection by label\\\\n#\\\\nSee more in\\\\nSelection by Label\\\\nusing\\\\nDataFrame.loc()\\\\nor\\\\nDataFrame.at()\\\\n.\\\\nSelecting a row matching a label:\\\\nIn [27]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n]]\\\\nOut[27]:\\\\nA    0.469112\\\\nB   -0.282863\\\\nC   -1.509059\\\\nD   -1.135632\\\\nName: 2013-01-01 00:00:00, dtype: float64\\\\nSelecting all rows (\\\\n:\\\\n) with a select column labels:\\\\nIn [28]:\\\\ndf\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n]]\\\\nOut[28]:\\\\nA         B\\\\n2013-01-01  0.469112 -0.282863\\\\n2013-01-02  1.212112 -0.173215\\\\n2013-01-03 -0.861849 -2.104569\\\\n2013-01-04  0.721555 -0.706771\\\\n2013-01-05 -0.424972  0.567020\\\\n2013-01-06 -0.673690  0.113648\\\\nFor label slicing, both endpoints are\\\\nincluded\\\\n:\\\\nIn [29]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\n\"20130102\"\\\\n:\\\\n\"20130104\"\\\\n,\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n]]\\\\nOut[29]:\\\\nA         B\\\\n2013-01-02  1.212112 -0.173215\\\\n2013-01-03 -0.861849 -2.104569\\\\n2013-01-04  0.721555 -0.706771\\\\nSelecting a single row and column label returns a scalar:\\\\nIn [30]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n],\\\\n\"A\"\\\\n]\\\\nOut[30]:\\\\n0.4691122999071863\\\\nFor getting fast access to a scalar (equivalent to the prior method):\\\\nIn [31]:\\\\ndf\\\\n.\\\\nat\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n],\\\\n\"A\"\\\\n]\\\\nOut[31]:\\\\n0.4691122999071863\\\\nSelection by position\\\\n#\\\\nSee more in\\\\nSelection by Position\\\\nusing\\\\nDataFrame.iloc()\\\\nor\\\\nDataFrame.iat()\\\\n.\\\\nSelect via the position of the passed integers:\\\\nIn [32]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n]\\\\nOut[32]:\\\\nA    0.721555\\\\nB   -0.706771\\\\nC   -1.039575\\\\nD    0.271860\\\\nName: 2013-01-04 00:00:00, dtype: float64\\\\nInteger slices acts similar to NumPy/Python:\\\\nIn [33]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n5\\\\n,\\\\n0\\\\n:\\\\n2\\\\n]\\\\nOut[33]:\\\\nA         B\\\\n2013-01-04  0.721555 -0.706771\\\\n2013-01-05 -0.424972  0.567020\\\\nLists of integer position locations:\\\\nIn [34]:\\\\ndf\\\\n.\\\\niloc\\\\n[[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n4\\\\n],\\\\n[\\\\n0\\\\n,\\\\n2\\\\n]]\\\\nOut[34]:\\\\nA         C\\\\n2013-01-02  1.212112  0.119209\\\\n2013-01-03 -0.861849 -0.494929\\\\n2013-01-05 -0.424972  0.276232\\\\nFor slicing rows explicitly:\\\\nIn [35]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n:\\\\n3\\\\n,\\\\n:]\\\\nOut[35]:\\\\nA         B         C         D\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\nFor slicing columns explicitly:\\\\nIn [36]:\\\\ndf\\\\n.\\\\niloc\\\\n[:,\\\\n1\\\\n:\\\\n3\\\\n]\\\\nOut[36]:\\\\nB         C\\\\n2013-01-01 -0.282863 -1.509059\\\\n2013-01-02 -0.173215  0.119209\\\\n2013-01-03 -2.104569 -0.494929\\\\n2013-01-04 -0.706771 -1.039575\\\\n2013-01-05  0.567020  0.276232\\\\n2013-01-06  0.113648 -1.478427\\\\nFor getting a value explicitly:\\\\nIn [37]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n,\\\\n1\\\\n]\\\\nOut[37]:\\\\n-0.17321464905330858\\\\nFor getting fast access to a scalar (equivalent to the prior method):\\\\nIn [38]:\\\\ndf\\\\n.\\\\niat\\\\n[\\\\n1\\\\n,\\\\n1\\\\n]\\\\nOut[38]:\\\\n-0.17321464905330858\\\\nBoolean indexing\\\\n#\\\\nSelect rows where\\\\ndf.A\\\\nis greater than\\\\n0\\\\n.\\\\nIn [39]:\\\\ndf\\\\n[\\\\ndf\\\\n[\\\\n\"A\"\\\\n]\\\\n>\\\\n0\\\\n]\\\\nOut[39]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\nSelecting values from a\\\\nDataFrame\\\\nwhere a boolean condition is met:\\\\nIn [40]:\\\\ndf\\\\n[\\\\ndf\\\\n>\\\\n0\\\\n]\\\\nOut[40]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112       NaN       NaN       NaN\\\\n2013-01-02  1.212112       NaN  0.119209       NaN\\\\n2013-01-03       NaN       NaN       NaN  1.071804\\\\n2013-01-04  0.721555       NaN       NaN  0.271860\\\\n2013-01-05       NaN  0.567020  0.276232       NaN\\\\n2013-01-06       NaN  0.113648       NaN  0.524988\\\\nUsing\\\\nisin()\\\\nmethod for filtering:\\\\nIn [41]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [42]:\\\\ndf2\\\\n[\\\\n\"E\"\\\\n]\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n,\\\\n\"four\"\\\\n,\\\\n\"three\"\\\\n]\\\\nIn [43]:\\\\ndf2\\\\nOut[43]:\\\\nA         B         C         D      E\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three\\\\nIn [44]:\\\\ndf2\\\\n[\\\\ndf2\\\\n[\\\\n\"E\"\\\\n]\\\\n.\\\\nisin\\\\n([\\\\n\"two\"\\\\n,\\\\n\"four\"\\\\n])]\\\\nOut[44]:\\\\nA         B         C         D     E\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four\\\\nSetting\\\\n#\\\\nSetting a new column automatically aligns the data by the indexes:\\\\nIn [45]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130102\"\\\\n,\\\\nperiods\\\\n=\\\\n6\\\\n))\\\\nIn [46]:\\\\ns1\\\\nOut[46]:\\\\n2013-01-02    1\\\\n2013-01-03    2\\\\n2013-01-04    3\\\\n2013-01-05    4\\\\n2013-01-06    5\\\\n2013-01-07    6\\\\nFreq: D, dtype: int64\\\\nIn [47]:\\\\ndf\\\\n[\\\\n\"F\"\\\\n]\\\\n=\\\\ns1\\\\nSetting values by label:\\\\nIn [48]:\\\\ndf\\\\n.\\\\nat\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n],\\\\n\"A\"\\\\n]\\\\n=\\\\n0\\\\nSetting values by position:\\\\nIn [49]:\\\\ndf\\\\n.\\\\niat\\\\n[\\\\n0\\\\n,\\\\n1\\\\n]\\\\n=\\\\n0\\\\nSetting by assigning with a NumPy array:\\\\nIn [50]:\\\\ndf\\\\n.\\\\nloc\\\\n[:,\\\\n\"D\"\\\\n]\\\\n=\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n5\\\\n]\\\\n*\\\\nlen\\\\n(\\\\ndf\\\\n))\\\\nThe result of the prior setting operations:\\\\nIn [51]:\\\\ndf\\\\nOut[51]:\\\\nA         B         C    D    F\\\\n2013-01-01  0.000000  0.000000 -1.509059  5.0  NaN\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0\\\\n2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0\\\\n2013-01-05 -0.424972  0.567020  0.276232  5.0  4.0\\\\n2013-01-06 -0.673690  0.113648 -1.478427  5.0  5.0\\\\nA\\\\nwhere\\\\noperation with setting:\\\\nIn [52]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [53]:\\\\ndf2\\\\n[\\\\ndf2\\\\n>\\\\n0\\\\n]\\\\n=\\\\n-\\\\ndf2\\\\nIn [54]:\\\\ndf2\\\\nOut[54]:\\\\nA         B         C    D    F\\\\n2013-01-01  0.000000  0.000000 -1.509059 -5.0  NaN\\\\n2013-01-02 -1.212112 -0.173215 -0.119209 -5.0 -1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929 -5.0 -2.0\\\\n2013-01-04 -0.721555 -0.706771 -1.039575 -5.0 -3.0\\\\n2013-01-05 -0.424972 -0.567020 -0.276232 -5.0 -4.0\\\\n2013-01-06 -0.673690 -0.113648 -1.478427 -5.0 -5.0\\\\nMissing data\\\\n#\\\\nFor NumPy data types,\\\\nnp.nan\\\\nrepresents missing data. It is by\\ndefault not included in computations. See the\\\\nMissing Data section\\\\n.\\\\nReindexing allows you to change/add/delete the index on a specified axis. This\\nreturns a copy of the data:\\\\nIn [55]:\\\\ndf1\\\\n=\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\nindex\\\\n=\\\\ndates\\\\n[\\\\n0\\\\n:\\\\n4\\\\n],\\\\ncolumns\\\\n=\\\\nlist\\\\n(\\\\ndf\\\\n.\\\\ncolumns\\\\n)\\\\n+\\\\n[\\\\n\"E\"\\\\n])\\\\nIn [56]:\\\\ndf1\\\\n.\\\\nloc\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n]\\\\n:\\\\ndates\\\\n[\\\\n1\\\\n],\\\\n\"E\"\\\\n]\\\\n=\\\\n1\\\\nIn [57]:\\\\ndf1\\\\nOut[57]:\\\\nA         B         C    D    F    E\\\\n2013-01-01  0.000000  0.000000 -1.509059  5.0  NaN  1.0\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0  NaN\\\\n2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0  NaN\\\\nDataFrame.dropna()\\\\ndrops any rows that have missing data:\\\\nIn [58]:\\\\ndf1\\\\n.\\\\ndropna\\\\n(\\\\nhow\\\\n=\\\\n\"any\"\\\\n)\\\\nOut[58]:\\\\nA         B         C    D    F    E\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0\\\\nDataFrame.fillna()\\\\nfills missing data:\\\\nIn [59]:\\\\ndf1\\\\n.\\\\nfillna\\\\n(\\\\nvalue\\\\n=\\\\n5\\\\n)\\\\nOut[59]:\\\\nA         B         C    D    F    E\\\\n2013-01-01  0.000000  0.000000 -1.509059  5.0  5.0  1.0\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0  5.0\\\\n2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0  5.0\\\\nisna()\\\\ngets the boolean mask where values are\\\\nnan\\\\n:\\\\nIn [60]:\\\\npd\\\\n.\\\\nisna\\\\n(\\\\ndf1\\\\n)\\\\nOut[60]:\\\\nA      B      C      D      F      E\\\\n2013-01-01  False  False  False  False   True  False\\\\n2013-01-02  False  False  False  False  False  False\\\\n2013-01-03  False  False  False  False  False   True\\\\n2013-01-04  False  False  False  False  False   True\\\\nOperations\\\\n#\\\\nSee the\\\\nBasic section on Binary Ops\\\\n.\\\\nStats\\\\n#\\\\nOperations in general\\\\nexclude\\\\nmissing data.\\\\nCalculate the mean value for each column:\\\\nIn [61]:\\\\ndf\\\\n.\\\\nmean\\\\n()\\\\nOut[61]:\\\\nA   -0.004474\\\\nB   -0.383981\\\\nC   -0.687758\\\\nD    5.000000\\\\nF    3.000000\\\\ndtype: float64\\\\nCalculate the mean value for each row:\\\\nIn [62]:\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[62]:\\\\n2013-01-01    0.872735\\\\n2013-01-02    1.431621\\\\n2013-01-03    0.707731\\\\n2013-01-04    1.395042\\\\n2013-01-05    1.883656\\\\n2013-01-06    1.592306\\\\nFreq: D, dtype: float64\\\\nOperating with another\\\\nSeries\\\\nor\\\\nDataFrame\\\\nwith a different index or column\\nwill align the result with the union of the index or column labels. In addition, pandas\\nautomatically broadcasts along the specified dimension and will fill unaligned labels with\\\\nnp.nan\\\\n.\\\\nIn [63]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n3\\\\n,\\\\n5\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n6\\\\n,\\\\n8\\\\n],\\\\nindex\\\\n=\\\\ndates\\\\n)\\\\n.\\\\nshift\\\\n(\\\\n2\\\\n)\\\\nIn [64]:\\\\ns\\\\nOut[64]:\\\\n2013-01-01    NaN\\\\n2013-01-02    NaN\\\\n2013-01-03    1.0\\\\n2013-01-04    3.0\\\\n2013-01-05    5.0\\\\n2013-01-06    NaN\\\\nFreq: D, dtype: float64\\\\nIn [65]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ns\\\\n,\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[65]:\\\\nA         B         C    D    F\\\\n2013-01-01       NaN       NaN       NaN  NaN  NaN\\\\n2013-01-02       NaN       NaN       NaN  NaN  NaN\\\\n2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0\\\\n2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0\\\\n2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0\\\\n2013-01-06       NaN       NaN       NaN  NaN  NaN\\\\nUser defined functions\\\\n#\\\\nDataFrame.agg()\\\\nand\\\\nDataFrame.transform()\\\\napplies a user defined function\\nthat reduces or broadcasts its result respectively.\\\\nIn [66]:\\\\ndf\\\\n.\\\\nagg\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\nx\\\\n)\\\\n*\\\\n5.6\\\\n)\\\\nOut[66]:\\\\nA    -0.025054\\\\nB    -2.150294\\\\nC    -3.851445\\\\nD    28.000000\\\\nF    16.800000\\\\ndtype: float64\\\\nIn [67]:\\\\ndf\\\\n.\\\\ntransform\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n*\\\\n101.2\\\\n)\\\\nOut[67]:\\\\nA           B           C      D      F\\\\n2013-01-01    0.000000    0.000000 -152.716721  506.0    NaN\\\\n2013-01-02  122.665737  -17.529322   12.063922  506.0  101.2\\\\n2013-01-03  -87.219115 -212.982405  -50.086843  506.0  202.4\\\\n2013-01-04   73.021382  -71.525239 -105.204988  506.0  303.6\\\\n2013-01-05  -43.007200   57.382459   27.954680  506.0  404.8\\\\n2013-01-06  -68.177398   11.501219 -149.616767  506.0  506.0\\\\nValue Counts\\\\n#\\\\nSee more at\\\\nHistogramming and Discretization\\\\n.\\\\nIn [68]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n7\\\\n,\\\\nsize\\\\n=\\\\n10\\\\n))\\\\nIn [69]:\\\\ns\\\\nOut[69]:\\\\n0    4\\\\n1    2\\\\n2    1\\\\n3    2\\\\n4    6\\\\n5    4\\\\n6    4\\\\n7    6\\\\n8    4\\\\n9    4\\\\ndtype: int64\\\\nIn [70]:\\\\ns\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[70]:\\\\n4    5\\\\n2    2\\\\n6    2\\\\n1    1\\\\nName: count, dtype: int64\\\\nString Methods\\\\n#\\\\nSeries\\\\nis equipped with a set of string processing methods in the\\\\nstr\\\\nattribute that make it easy to operate on each element of the array, as in the\\ncode snippet below. See more at\\\\nVectorized String Methods\\\\n.\\\\nIn [71]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"Aaba\"\\\\n,\\\\n\"Baca\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n\"CABA\"\\\\n,\\\\n\"dog\"\\\\n,\\\\n\"cat\"\\\\n])\\\\nIn [72]:\\\\ns\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n()\\\\nOut[72]:\\\\n0       a\\\\n1       b\\\\n2       c\\\\n3    aaba\\\\n4    baca\\\\n5     NaN\\\\n6    caba\\\\n7     dog\\\\n8     cat\\\\ndtype: object\\\\nMerge\\\\n#\\\\nConcat\\\\n#\\\\npandas provides various facilities for easily combining together\\\\nSeries\\\\nand\\\\nDataFrame\\\\nobjects with various kinds of set logic for the indexes\\nand relational algebra functionality in the case of join / merge-type\\noperations.\\\\nSee the\\\\nMerging section\\\\n.\\\\nConcatenating pandas objects together row-wise with\\\\nconcat()\\\\n:\\\\nIn [73]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n4\\\\n))\\\\nIn [74]:\\\\ndf\\\\nOut[74]:\\\\n0         1         2         3\\\\n0 -0.548702  1.467327 -1.015962 -0.483075\\\\n1  1.637550 -1.217659 -0.291519 -1.745505\\\\n2 -0.263952  0.991460 -0.919069  0.266046\\\\n3 -0.709661  1.669052  1.037882 -1.705775\\\\n4 -0.919854 -0.042379  1.247642 -0.009920\\\\n5  0.290213  0.495767  0.362949  1.548106\\\\n6 -1.131345 -0.089329  0.337863 -0.945867\\\\n7 -0.932132  1.956030  0.017587 -0.016692\\\\n8 -0.575247  0.254161 -1.143704  0.215897\\\\n9  1.193555 -0.077118 -0.408530 -0.862495\\\\n# break it into pieces\\\\nIn [75]:\\\\npieces\\\\n=\\\\n[\\\\ndf\\\\n[:\\\\n3\\\\n],\\\\ndf\\\\n[\\\\n3\\\\n:\\\\n7\\\\n],\\\\ndf\\\\n[\\\\n7\\\\n:]]\\\\nIn [76]:\\\\npd\\\\n.\\\\nconcat\\\\n(\\\\npieces\\\\n)\\\\nOut[76]:\\\\n0         1         2         3\\\\n0 -0.548702  1.467327 -1.015962 -0.483075\\\\n1  1.637550 -1.217659 -0.291519 -1.745505\\\\n2 -0.263952  0.991460 -0.919069  0.266046\\\\n3 -0.709661  1.669052  1.037882 -1.705775\\\\n4 -0.919854 -0.042379  1.247642 -0.009920\\\\n5  0.290213  0.495767  0.362949  1.548106\\\\n6 -1.131345 -0.089329  0.337863 -0.945867\\\\n7 -0.932132  1.956030  0.017587 -0.016692\\\\n8 -0.575247  0.254161 -1.143704  0.215897\\\\n9  1.193555 -0.077118 -0.408530 -0.862495\\\\nNote\\\\nAdding a column to a\\\\nDataFrame\\\\nis relatively fast. However, adding\\na row requires a copy, and may be expensive. We recommend passing a\\npre-built list of records to the\\\\nDataFrame\\\\nconstructor instead\\nof building a\\\\nDataFrame\\\\nby iteratively appending records to it.\\\\nJoin\\\\n#\\\\nmerge()\\\\nenables SQL style join types along specific columns. See the\\\\nDatabase style joining\\\\nsection.\\\\nIn [77]:\\\\nleft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n],\\\\n\"lval\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]})\\\\nIn [78]:\\\\nright\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n],\\\\n\"rval\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n]})\\\\nIn [79]:\\\\nleft\\\\nOut[79]:\\\\nkey  lval\\\\n0  foo     1\\\\n1  foo     2\\\\nIn [80]:\\\\nright\\\\nOut[80]:\\\\nkey  rval\\\\n0  foo     4\\\\n1  foo     5\\\\nIn [81]:\\\\npd\\\\n.\\\\nmerge\\\\n(\\\\nleft\\\\n,\\\\nright\\\\n,\\\\non\\\\n=\\\\n\"key\"\\\\n)\\\\nOut[81]:\\\\nkey  lval  rval\\\\n0  foo     1     4\\\\n1  foo     1     5\\\\n2  foo     2     4\\\\n3  foo     2     5\\\\nmerge()\\\\non unique keys:\\\\nIn [82]:\\\\nleft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n],\\\\n\"lval\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]})\\\\nIn [83]:\\\\nright\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n],\\\\n\"rval\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n]})\\\\nIn [84]:\\\\nleft\\\\nOut[84]:\\\\nkey  lval\\\\n0  foo     1\\\\n1  bar     2\\\\nIn [85]:\\\\nright\\\\nOut[85]:\\\\nkey  rval\\\\n0  foo     4\\\\n1  bar     5\\\\nIn [86]:\\\\npd\\\\n.\\\\nmerge\\\\n(\\\\nleft\\\\n,\\\\nright\\\\n,\\\\non\\\\n=\\\\n\"key\"\\\\n)\\\\nOut[86]:\\\\nkey  lval  rval\\\\n0  foo     1     4\\\\n1  bar     2     5\\\\nGrouping\\\\n#\\\\nBy “group by” we are referring to a process involving one or more of the\\nfollowing steps:\\\\nSplitting\\\\nthe data into groups based on some criteria\\\\nApplying\\\\na function to each group independently\\\\nCombining\\\\nthe results into a data structure\\\\nSee the\\\\nGrouping section\\\\n.\\\\nIn [87]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n\"A\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n],\\\\n....:\\\\n\"B\"\\\\n:\\\\n[\\\\n\"one\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"three\"\\\\n],\\\\n....:\\\\n\"C\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\n....:\\\\n\"D\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nIn [88]:\\\\ndf\\\\nOut[88]:\\\\nA      B         C         D\\\\n0  foo    one  1.346061 -1.577585\\\\n1  bar    one  1.511763  0.396823\\\\n2  foo    two  1.627081 -0.105381\\\\n3  bar  three -0.990582 -0.532532\\\\n4  foo    two -0.441652  1.453749\\\\n5  bar    two  1.211526  1.208843\\\\n6  foo    one  0.268520 -0.080952\\\\n7  foo  three  0.024580 -0.264610\\\\nGrouping by a column label, selecting column labels, and then applying the\\\\nDataFrameGroupBy.sum()\\\\nfunction to the resulting\\ngroups:\\\\nIn [89]:\\\\ndf\\\\n.\\\\ngroupby\\\\n(\\\\n\"A\"\\\\n)[[\\\\n\"C\"\\\\n,\\\\n\"D\"\\\\n]]\\\\n.\\\\nsum\\\\n()\\\\nOut[89]:\\\\nC         D\\\\nA\\\\nbar  1.732707  1.073134\\\\nfoo  2.824590 -0.574779\\\\nGrouping by multiple columns label forms\\\\nMultiIndex\\\\n.\\\\nIn [90]:\\\\ndf\\\\n.\\\\ngroupby\\\\n([\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n])\\\\n.\\\\nsum\\\\n()\\\\nOut[90]:\\\\nC         D\\\\nA   B\\\\nbar one    1.511763  0.396823\\\\nthree -0.990582 -0.532532\\\\ntwo    1.211526  1.208843\\\\nfoo one    1.614581 -1.658537\\\\nthree  0.024580 -0.264610\\\\ntwo    1.185429  1.348368\\\\nReshaping\\\\n#\\\\nSee the sections on\\\\nHierarchical Indexing\\\\nand\\\\nReshaping\\\\n.\\\\nStack\\\\n#\\\\nIn [91]:\\\\narrays\\\\n=\\\\n[\\\\n....:\\\\n[\\\\n\"bar\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n,\\\\n\"baz\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"qux\"\\\\n,\\\\n\"qux\"\\\\n],\\\\n....:\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n],\\\\n....:\\\\n]\\\\n....:\\\\nIn [92]:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_arrays\\\\n(\\\\narrays\\\\n,\\\\nnames\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n])\\\\nIn [93]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n,\\\\n2\\\\n),\\\\nindex\\\\n=\\\\nindex\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n])\\\\nIn [94]:\\\\ndf2\\\\n=\\\\ndf\\\\n[:\\\\n4\\\\n]\\\\nIn [95]:\\\\ndf2\\\\nOut[95]:\\\\nA         B\\\\nfirst second\\\\nbar   one    -0.727965 -0.589346\\\\ntwo     0.339969 -0.693205\\\\nbaz   one    -0.339355  0.593616\\\\ntwo     0.884345  1.591431\\\\nThe\\\\nstack()\\\\nmethod “compresses” a level in the DataFrame’s\\ncolumns:\\\\nIn [96]:\\\\nstacked\\\\n=\\\\ndf2\\\\n.\\\\nstack\\\\n(\\\\nfuture_stack\\\\n=\\\\nTrue\\\\n)\\\\nIn [97]:\\\\nstacked\\\\nOut[97]:\\\\nfirst  second\\\\nbar    one     A   -0.727965\\\\nB   -0.589346\\\\ntwo     A    0.339969\\\\nB   -0.693205\\\\nbaz    one     A   -0.339355\\\\nB    0.593616\\\\ntwo     A    0.884345\\\\nB    1.591431\\\\ndtype: float64\\\\nWith a “stacked” DataFrame or Series (having a\\\\nMultiIndex\\\\nas the\\\\nindex\\\\n), the inverse operation of\\\\nstack()\\\\nis\\\\nunstack()\\\\n, which by default unstacks the\\\\nlast level\\\\n:\\\\nIn [98]:\\\\nstacked\\\\n.\\\\nunstack\\\\n()\\\\nOut[98]:\\\\nA         B\\\\nfirst second\\\\nbar   one    -0.727965 -0.589346\\\\ntwo     0.339969 -0.693205\\\\nbaz   one    -0.339355  0.593616\\\\ntwo     0.884345  1.591431\\\\nIn [99]:\\\\nstacked\\\\n.\\\\nunstack\\\\n(\\\\n1\\\\n)\\\\nOut[99]:\\\\nsecond        one       two\\\\nfirst\\\\nbar   A -0.727965  0.339969\\\\nB -0.589346 -0.693205\\\\nbaz   A -0.339355  0.884345\\\\nB  0.593616  1.591431\\\\nIn [100]:\\\\nstacked\\\\n.\\\\nunstack\\\\n(\\\\n0\\\\n)\\\\nOut[100]:\\\\nfirst          bar       baz\\\\nsecond\\\\none    A -0.727965 -0.339355\\\\nB -0.589346  0.593616\\\\ntwo    A  0.339969  0.884345\\\\nB -0.693205  1.591431\\\\nPivot tables\\\\n#\\\\nSee the section on\\\\nPivot Tables\\\\n.\\\\nIn [101]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\n[\\\\n\"one\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n]\\\\n*\\\\n3\\\\n,\\\\n.....:\\\\n\"B\"\\\\n:\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n]\\\\n*\\\\n4\\\\n,\\\\n.....:\\\\n\"C\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"bar\"\\\\n]\\\\n*\\\\n2\\\\n,\\\\n.....:\\\\n\"D\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n12\\\\n),\\\\n.....:\\\\n\"E\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n12\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [102]:\\\\ndf\\\\nOut[102]:\\\\nA  B    C         D         E\\\\n0     one  A  foo -1.202872  0.047609\\\\n1     one  B  foo -1.814470 -0.136473\\\\n2     two  C  foo  1.018601 -0.561757\\\\n3   three  A  bar -0.595447 -1.623033\\\\n4     one  B  bar  1.395433  0.029399\\\\n5     one  C  bar -0.392670 -0.542108\\\\n6     two  A  foo  0.007207  0.282696\\\\n7   three  B  foo  1.928123 -0.087302\\\\n8     one  C  foo -0.055224 -1.575170\\\\n9     one  A  bar  2.395985  1.771208\\\\n10    two  B  bar  1.552825  0.816482\\\\n11  three  C  bar  0.166599  1.100230\\\\npivot_table()\\\\npivots a\\\\nDataFrame\\\\nspecifying the\\\\nvalues\\\\n,\\\\nindex\\\\nand\\\\ncolumns\\\\nIn [103]:\\\\npd\\\\n.\\\\npivot_table\\\\n(\\\\ndf\\\\n,\\\\nvalues\\\\n=\\\\n\"D\"\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"C\"\\\\n])\\\\nOut[103]:\\\\nC             bar       foo\\\\nA     B\\\\none   A  2.395985 -1.202872\\\\nB  1.395433 -1.814470\\\\nC -0.392670 -0.055224\\\\nthree A -0.595447       NaN\\\\nB       NaN  1.928123\\\\nC  0.166599       NaN\\\\ntwo   A       NaN  0.007207\\\\nB  1.552825       NaN\\\\nC       NaN  1.018601\\\\nTime series\\\\n#\\\\npandas has simple, powerful, and efficient functionality for performing\\nresampling operations during frequency conversion (e.g., converting secondly\\ndata into 5-minutely data). This is extremely common in, but not limited to,\\nfinancial applications. See the\\\\nTime Series section\\\\n.\\\\nIn [104]:\\\\nrng\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2012\"\\\\n,\\\\nperiods\\\\n=\\\\n100\\\\n,\\\\nfreq\\\\n=\\\\n\"s\"\\\\n)\\\\nIn [105]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n500\\\\n,\\\\nlen\\\\n(\\\\nrng\\\\n)),\\\\nindex\\\\n=\\\\nrng\\\\n)\\\\nIn [106]:\\\\nts\\\\n.\\\\nresample\\\\n(\\\\n\"5Min\"\\\\n)\\\\n.\\\\nsum\\\\n()\\\\nOut[106]:\\\\n2012-01-01    24182\\\\nFreq: 5min, dtype: int64\\\\nSeries.tz_localize()\\\\nlocalizes a time series to a time zone:\\\\nIn [107]:\\\\nrng\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"3/6/2012 00:00\"\\\\n,\\\\nperiods\\\\n=\\\\n5\\\\n,\\\\nfreq\\\\n=\\\\n\"D\"\\\\n)\\\\nIn [108]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\nlen\\\\n(\\\\nrng\\\\n)),\\\\nrng\\\\n)\\\\nIn [109]:\\\\nts\\\\nOut[109]:\\\\n2012-03-06    1.857704\\\\n2012-03-07   -1.193545\\\\n2012-03-08    0.677510\\\\n2012-03-09   -0.153931\\\\n2012-03-10    0.520091\\\\nFreq: D, dtype: float64\\\\nIn [110]:\\\\nts_utc\\\\n=\\\\nts\\\\n.\\\\ntz_localize\\\\n(\\\\n\"UTC\"\\\\n)\\\\nIn [111]:\\\\nts_utc\\\\nOut[111]:\\\\n2012-03-06 00:00:00+00:00    1.857704\\\\n2012-03-07 00:00:00+00:00   -1.193545\\\\n2012-03-08 00:00:00+00:00    0.677510\\\\n2012-03-09 00:00:00+00:00   -0.153931\\\\n2012-03-10 00:00:00+00:00    0.520091\\\\nFreq: D, dtype: float64\\\\nSeries.tz_convert()\\\\nconverts a timezones aware time series to another time zone:\\\\nIn [112]:\\\\nts_utc\\\\n.\\\\ntz_convert\\\\n(\\\\n\"US/Eastern\"\\\\n)\\\\nOut[112]:\\\\n2012-03-05 19:00:00-05:00    1.857704\\\\n2012-03-06 19:00:00-05:00   -1.193545\\\\n2012-03-07 19:00:00-05:00    0.677510\\\\n2012-03-08 19:00:00-05:00   -0.153931\\\\n2012-03-09 19:00:00-05:00    0.520091\\\\nFreq: D, dtype: float64\\\\nAdding a non-fixed duration (\\\\nBusinessDay\\\\n) to a time series:\\\\nIn [113]:\\\\nrng\\\\nOut[113]:\\\\nDatetimeIndex([\\'2012-03-06\\', \\'2012-03-07\\', \\'2012-03-08\\', \\'2012-03-09\\',\\\\n\\'2012-03-10\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=\\'D\\')\\\\nIn [114]:\\\\nrng\\\\n+\\\\npd\\\\n.\\\\noffsets\\\\n.\\\\nBusinessDay\\\\n(\\\\n5\\\\n)\\\\nOut[114]:\\\\nDatetimeIndex([\\'2012-03-13\\', \\'2012-03-14\\', \\'2012-03-15\\', \\'2012-03-16\\',\\\\n\\'2012-03-16\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=None)\\\\nCategoricals\\\\n#\\\\npandas can include categorical data in a\\\\nDataFrame\\\\n. For full docs, see the\\\\ncategorical introduction\\\\nand the\\\\nAPI documentation\\\\n.\\\\nIn [115]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"id\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"raw_grade\"\\\\n:\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"e\"\\\\n]}\\\\n.....:\\\\n)\\\\n.....:\\\\nConverting the raw grades to a categorical data type:\\\\nIn [116]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"raw_grade\"\\\\n]\\\\n.\\\\nastype\\\\n(\\\\n\"category\"\\\\n)\\\\nIn [117]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\nOut[117]:\\\\n0    a\\\\n1    b\\\\n2    b\\\\n3    a\\\\n4    a\\\\n5    e\\\\nName: grade, dtype: category\\\\nCategories (3, object): [\\'a\\', \\'b\\', \\'e\\']\\\\nRename the categories to more meaningful names:\\\\nIn [118]:\\\\nnew_categories\\\\n=\\\\n[\\\\n\"very good\"\\\\n,\\\\n\"good\"\\\\n,\\\\n\"very bad\"\\\\n]\\\\nIn [119]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n.\\\\ncat\\\\n.\\\\nrename_categories\\\\n(\\\\nnew_categories\\\\n)\\\\nReorder the categories and simultaneously add the missing categories (methods under\\\\nSeries.cat()\\\\nreturn a new\\\\nSeries\\\\nby default):\\\\nIn [120]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n.\\\\ncat\\\\n.\\\\nset_categories\\\\n(\\\\n.....:\\\\n[\\\\n\"very bad\"\\\\n,\\\\n\"bad\"\\\\n,\\\\n\"medium\"\\\\n,\\\\n\"good\"\\\\n,\\\\n\"very good\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [121]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\nOut[121]:\\\\n0    very good\\\\n1         good\\\\n2         good\\\\n3    very good\\\\n4    very good\\\\n5     very bad\\\\nName: grade, dtype: category\\\\nCategories (5, object): [\\'very bad\\', \\'bad\\', \\'medium\\', \\'good\\', \\'very good\\']\\\\nSorting is per order in the categories, not lexical order:\\\\nIn [122]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"grade\"\\\\n)\\\\nOut[122]:\\\\nid raw_grade      grade\\\\n5   6         e   very bad\\\\n1   2         b       good\\\\n2   3         b       good\\\\n0   1         a  very good\\\\n3   4         a  very good\\\\n4   5         a  very good\\\\nGrouping by a categorical column with\\\\nobserved=False\\\\nalso shows empty categories:\\\\nIn [123]:\\\\ndf\\\\n.\\\\ngroupby\\\\n(\\\\n\"grade\"\\\\n,\\\\nobserved\\\\n=\\\\nFalse\\\\n)\\\\n.\\\\nsize\\\\n()\\\\nOut[123]:\\\\ngrade\\\\nvery bad     1\\\\nbad          0\\\\nmedium       0\\\\ngood         2\\\\nvery good    3\\\\ndtype: int64\\\\nPlotting\\\\n#\\\\nSee the\\\\nPlotting\\\\ndocs.\\\\nWe use the standard convention for referencing the matplotlib API:\\\\nIn [124]:\\\\nimport\\\\nmatplotlib.pyplot\\\\nas\\\\nplt\\\\nIn [125]:\\\\nplt\\\\n.\\\\nclose\\\\n(\\\\n\"all\"\\\\n)\\\\nThe\\\\nplt.close\\\\nmethod is used to\\\\nclose\\\\na figure window:\\\\nIn [126]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n),\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n1000\\\\n))\\\\nIn [127]:\\\\nts\\\\n=\\\\nts\\\\n.\\\\ncumsum\\\\n()\\\\nIn [128]:\\\\nts\\\\n.\\\\nplot\\\\n();\\\\nNote\\\\nWhen using Jupyter, the plot will appear using\\\\nplot()\\\\n.  Otherwise use\\\\nmatplotlib.pyplot.show\\\\nto show it or\\\\nmatplotlib.pyplot.savefig\\\\nto write it to a file.\\\\nplot()\\\\nplots all columns:\\\\nIn [129]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n,\\\\n4\\\\n),\\\\nindex\\\\n=\\\\nts\\\\n.\\\\nindex\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"D\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [130]:\\\\ndf\\\\n=\\\\ndf\\\\n.\\\\ncumsum\\\\n()\\\\nIn [131]:\\\\nplt\\\\n.\\\\nfigure\\\\n();\\\\nIn [132]:\\\\ndf\\\\n.\\\\nplot\\\\n();\\\\nIn [133]:\\\\nplt\\\\n.\\\\nlegend\\\\n(\\\\nloc\\\\n=\\\\n\\'best\\'\\\\n);\\\\nImporting and exporting data\\\\n#\\\\nSee the\\\\nIO Tools\\\\nsection.\\\\nCSV\\\\n#\\\\nWriting to a csv file:\\\\nusing\\\\nDataFrame.to_csv()\\\\nIn [134]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n5\\\\n,\\\\n(\\\\n10\\\\n,\\\\n5\\\\n)))\\\\nIn [135]:\\\\ndf\\\\n.\\\\nto_csv\\\\n(\\\\n\"foo.csv\"\\\\n)\\\\nReading from a csv file:\\\\nusing\\\\nread_csv()\\\\nIn [136]:\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"foo.csv\"\\\\n)\\\\nOut[136]:\\\\nUnnamed: 0  0  1  2  3  4\\\\n0           0  4  3  1  1  2\\\\n1           1  1  0  2  3  2\\\\n2           2  1  4  2  1  2\\\\n3           3  0  4  0  2  2\\\\n4           4  4  2  2  3  4\\\\n5           5  4  0  4  3  1\\\\n6           6  2  1  2  0  3\\\\n7           7  4  0  4  4  4\\\\n8           8  4  4  1  0  1\\\\n9           9  0  4  3  0  3\\\\nParquet\\\\n#\\\\nWriting to a Parquet file:\\\\nIn [137]:\\\\ndf\\\\n.\\\\nto_parquet\\\\n(\\\\n\"foo.parquet\"\\\\n)\\\\nReading from a Parquet file Store using\\\\nread_parquet()\\\\n:\\\\nIn [138]:\\\\npd\\\\n.\\\\nread_parquet\\\\n(\\\\n\"foo.parquet\"\\\\n)\\\\nOut[138]:\\\\n0  1  2  3  4\\\\n0  4  3  1  1  2\\\\n1  1  0  2  3  2\\\\n2  1  4  2  1  2\\\\n3  0  4  0  2  2\\\\n4  4  2  2  3  4\\\\n5  4  0  4  3  1\\\\n6  2  1  2  0  3\\\\n7  4  0  4  4  4\\\\n8  4  4  1  0  1\\\\n9  0  4  3  0  3\\\\nExcel\\\\n#\\\\nReading and writing to\\\\nExcel\\\\n.\\\\nWriting to an excel file using\\\\nDataFrame.to_excel()\\\\n:\\\\nIn [139]:\\\\ndf\\\\n.\\\\nto_excel\\\\n(\\\\n\"foo.xlsx\"\\\\n,\\\\nsheet_name\\\\n=\\\\n\"Sheet1\"\\\\n)\\\\nReading from an excel file using\\\\nread_excel()\\\\n:\\\\nIn [140]:\\\\npd\\\\n.\\\\nread_excel\\\\n(\\\\n\"foo.xlsx\"\\\\n,\\\\n\"Sheet1\"\\\\n,\\\\nindex_col\\\\n=\\\\nNone\\\\n,\\\\nna_values\\\\n=\\\\n[\\\\n\"NA\"\\\\n])\\\\nOut[140]:\\\\nUnnamed: 0  0  1  2  3  4\\\\n0           0  4  3  1  1  2\\\\n1           1  1  0  2  3  2\\\\n2           2  1  4  2  1  2\\\\n3           3  0  4  0  2  2\\\\n4           4  4  2  2  3  4\\\\n5           5  4  0  4  3  1\\\\n6           6  2  1  2  0  3\\\\n7           7  4  0  4  4  4\\\\n8           8  4  4  1  0  1\\\\n9           9  0  4  3  0  3\\\\nGotchas\\\\n#\\\\nIf you are attempting to perform a boolean operation on a\\\\nSeries\\\\nor\\\\nDataFrame\\\\nyou might see an exception like:\\\\nIn [141]:\\\\nif\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\nFalse\\\\n,\\\\nTrue\\\\n,\\\\nFalse\\\\n]):\\\\n.....:\\\\nprint\\\\n(\\\\n\"I was true\"\\\\n)\\\\n.....:\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\n<ipython-input-141-b27eb9c1dfc0>\\\\nin\\\\n?\\\\n()\\\\n---->\\\\n1\\\\nif\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\nFalse\\\\n,\\\\nTrue\\\\n,\\\\nFalse\\\\n]):\\\\n2\\\\nprint\\\\n(\\\\n\"I was true\"\\\\n)\\\\n~/work/pandas/pandas/pandas/core/generic.py\\\\nin\\\\n?\\\\n(self)\\\\n1575\\\\n@final\\\\n1576\\\\ndef\\\\n__nonzero__\\\\n(\\\\nself\\\\n)\\\\n->\\\\nNoReturn\\\\n:\\\\n->\\\\n1577\\\\nraise\\\\nValueError\\\\n(\\\\n1578\\\\nf\\\\n\"The truth value of a\\\\n{\\\\ntype\\\\n(\\\\nself\\\\n)\\\\n.\\\\n__name__\\\\n}\\\\nis ambiguous. \"\\\\n1579\\\\n\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\\\\n1580\\\\n)\\\\nValueError\\\\n: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\\nSee\\\\nComparisons\\\\nand\\\\nGotchas\\\\nfor an explanation and what to do.\\\\nprevious\\\\nUser Guide\\\\nnext\\\\nIntro to data structures\\\\nOn this page\\\\nBasic data structures in pandas\\\\nObject creation\\\\nViewing data\\\\nSelection\\\\nGetitem (\\\\n[]\\\\n)\\\\nSelection by label\\\\nSelection by position\\\\nBoolean indexing\\\\nSetting\\\\nMissing data\\\\nOperations\\\\nStats\\\\nUser defined functions\\\\nValue Counts\\\\nString Methods\\\\nMerge\\\\nConcat\\\\nJoin\\\\nGrouping\\\\nReshaping\\\\nStack\\\\nPivot tables\\\\nTime series\\\\nCategoricals\\\\nPlotting\\\\nImporting and exporting data\\\\nCSV\\\\nParquet\\\\nExcel\\\\nGotchas\\\\nShow Source\\\\n\\\\n--- Page Break ---\\\\n\\\\nUser Guide\\\\nIntro to...\\\\nIntro to data structures\\\\n#\\\\nWe’ll start with a quick, non-comprehensive overview of the fundamental data\\nstructures in pandas to get you started. The fundamental behavior about data\\ntypes, indexing, axis labeling, and alignment apply across all of the\\nobjects. To get started, import NumPy and load pandas into your namespace:\\\\nIn [1]:\\\\nimport\\\\nnumpy\\\\nas\\\\nnp\\\\nIn [2]:\\\\nimport\\\\npandas\\\\nas\\\\npd\\\\nFundamentally,\\\\ndata alignment is intrinsic\\\\n. The link\\nbetween labels and data will not be broken unless done so explicitly by you.\\\\nWe’ll give a brief intro to the data structures, then consider all of the broad\\ncategories of functionality and methods in separate sections.\\\\nSeries\\\\n#\\\\nSeries\\\\nis a one-dimensional labeled array capable of holding any data\\ntype (integers, strings, floating point numbers, Python objects, etc.). The axis\\nlabels are collectively referred to as the\\\\nindex\\\\n. The basic method to create a\\\\nSeries\\\\nis to call:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\ndata\\\\n,\\\\nindex\\\\n=\\\\nindex\\\\n)\\\\nHere,\\\\ndata\\\\ncan be many different things:\\\\na Python dict\\\\nan ndarray\\\\na scalar value (like 5)\\\\nThe passed\\\\nindex\\\\nis a list of axis labels. Thus, this separates into a few\\ncases depending on what\\\\ndata is\\\\n:\\\\nFrom ndarray\\\\nIf\\\\ndata\\\\nis an ndarray,\\\\nindex\\\\nmust be the same length as\\\\ndata\\\\n. If no\\nindex is passed, one will be created having values\\\\n[0,\\\\n...,\\\\nlen(data)\\\\n-\\\\n1]\\\\n.\\\\nIn [3]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [4]:\\\\ns\\\\nOut[4]:\\\\na    0.469112\\\\nb   -0.282863\\\\nc   -1.509059\\\\nd   -1.135632\\\\ne    1.212112\\\\ndtype: float64\\\\nIn [5]:\\\\ns\\\\n.\\\\nindex\\\\nOut[5]:\\\\nIndex([\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\'], dtype=\\'object\\')\\\\nIn [6]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n))\\\\nOut[6]:\\\\n0   -0.173215\\\\n1    0.119209\\\\n2   -1.044236\\\\n3   -0.861849\\\\n4   -2.104569\\\\ndtype: float64\\\\nNote\\\\npandas supports non-unique index values. If an operation\\nthat does not support duplicate index values is attempted, an exception\\nwill be raised at that time.\\\\nFrom dict\\\\nSeries\\\\ncan be instantiated from dicts:\\\\nIn [7]:\\\\nd\\\\n=\\\\n{\\\\n\"b\"\\\\n:\\\\n1\\\\n,\\\\n\"a\"\\\\n:\\\\n0\\\\n,\\\\n\"c\"\\\\n:\\\\n2\\\\n}\\\\nIn [8]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nd\\\\n)\\\\nOut[8]:\\\\nb    1\\\\na    0\\\\nc    2\\\\ndtype: int64\\\\nIf an index is passed, the values in data corresponding to the labels in the\\nindex will be pulled out.\\\\nIn [9]:\\\\nd\\\\n=\\\\n{\\\\n\"a\"\\\\n:\\\\n0.0\\\\n,\\\\n\"b\"\\\\n:\\\\n1.0\\\\n,\\\\n\"c\"\\\\n:\\\\n2.0\\\\n}\\\\nIn [10]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nd\\\\n)\\\\nOut[10]:\\\\na    0.0\\\\nb    1.0\\\\nc    2.0\\\\ndtype: float64\\\\nIn [11]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"a\"\\\\n])\\\\nOut[11]:\\\\nb    1.0\\\\nc    2.0\\\\nd    NaN\\\\na    0.0\\\\ndtype: float64\\\\nNote\\\\nNaN (not a number) is the standard missing data marker used in pandas.\\\\nFrom scalar value\\\\nIf\\\\ndata\\\\nis a scalar value, an index must be\\nprovided. The value will be repeated to match the length of\\\\nindex\\\\n.\\\\nIn [12]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n5.0\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nOut[12]:\\\\na    5.0\\\\nb    5.0\\\\nc    5.0\\\\nd    5.0\\\\ne    5.0\\\\ndtype: float64\\\\nSeries is ndarray-like\\\\n#\\\\nSeries\\\\nacts very similarly to a\\\\nndarray\\\\nand is a valid argument to most NumPy functions.\\nHowever, operations such as slicing will also slice the index.\\\\nIn [13]:\\\\ns\\\\n.\\\\niloc\\\\n[\\\\n0\\\\n]\\\\nOut[13]:\\\\n0.4691122999071863\\\\nIn [14]:\\\\ns\\\\n.\\\\niloc\\\\n[:\\\\n3\\\\n]\\\\nOut[14]:\\\\na    0.469112\\\\nb   -0.282863\\\\nc   -1.509059\\\\ndtype: float64\\\\nIn [15]:\\\\ns\\\\n[\\\\ns\\\\n>\\\\ns\\\\n.\\\\nmedian\\\\n()]\\\\nOut[15]:\\\\na    0.469112\\\\ne    1.212112\\\\ndtype: float64\\\\nIn [16]:\\\\ns\\\\n.\\\\niloc\\\\n[[\\\\n4\\\\n,\\\\n3\\\\n,\\\\n1\\\\n]]\\\\nOut[16]:\\\\ne    1.212112\\\\nd   -1.135632\\\\nb   -0.282863\\\\ndtype: float64\\\\nIn [17]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\ns\\\\n)\\\\nOut[17]:\\\\na    1.598575\\\\nb    0.753623\\\\nc    0.221118\\\\nd    0.321219\\\\ne    3.360575\\\\ndtype: float64\\\\nNote\\\\nWe will address array-based indexing like\\\\ns.iloc[[4,\\\\n3,\\\\n1]]\\\\nin\\\\nsection on indexing\\\\n.\\\\nLike a NumPy array, a pandas\\\\nSeries\\\\nhas a single\\\\ndtype\\\\n.\\\\nIn [18]:\\\\ns\\\\n.\\\\ndtype\\\\nOut[18]:\\\\ndtype(\\'float64\\')\\\\nThis is often a NumPy dtype. However, pandas and 3rd-party libraries\\nextend NumPy’s type system in a few places, in which case the dtype would\\nbe an\\\\nExtensionDtype\\\\n. Some examples within\\npandas are\\\\nCategorical data\\\\nand\\\\nNullable integer data type\\\\n. See\\\\ndtypes\\\\nfor more.\\\\nIf you need the actual array backing a\\\\nSeries\\\\n, use\\\\nSeries.array\\\\n.\\\\nIn [19]:\\\\ns\\\\n.\\\\narray\\\\nOut[19]:\\\\n<NumpyExtensionArray>\\\\n[ 0.4691122999071863, -0.2828633443286633, -1.5090585031735124,\\\\n-1.1356323710171934,  1.2121120250208506]\\\\nLength: 5, dtype: float64\\\\nAccessing the array can be useful when you need to do some operation without the\\nindex (to disable\\\\nautomatic alignment\\\\n, for example).\\\\nSeries.array\\\\nwill always be an\\\\nExtensionArray\\\\n.\\nBriefly, an ExtensionArray is a thin wrapper around one or more\\\\nconcrete\\\\narrays like a\\\\nnumpy.ndarray\\\\n. pandas knows how to take an\\\\nExtensionArray\\\\nand\\nstore it in a\\\\nSeries\\\\nor a column of a\\\\nDataFrame\\\\n.\\nSee\\\\ndtypes\\\\nfor more.\\\\nWhile\\\\nSeries\\\\nis ndarray-like, if you need an\\\\nactual\\\\nndarray, then use\\\\nSeries.to_numpy()\\\\n.\\\\nIn [20]:\\\\ns\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[20]:\\\\narray([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])\\\\nEven if the\\\\nSeries\\\\nis backed by a\\\\nExtensionArray\\\\n,\\\\nSeries.to_numpy()\\\\nwill return a NumPy ndarray.\\\\nSeries is dict-like\\\\n#\\\\nA\\\\nSeries\\\\nis also like a fixed-size dict in that you can get and set values by index\\nlabel:\\\\nIn [21]:\\\\ns\\\\n[\\\\n\"a\"\\\\n]\\\\nOut[21]:\\\\n0.4691122999071863\\\\nIn [22]:\\\\ns\\\\n[\\\\n\"e\"\\\\n]\\\\n=\\\\n12.0\\\\nIn [23]:\\\\ns\\\\nOut[23]:\\\\na     0.469112\\\\nb    -0.282863\\\\nc    -1.509059\\\\nd    -1.135632\\\\ne    12.000000\\\\ndtype: float64\\\\nIn [24]:\\\\n\"e\"\\\\nin\\\\ns\\\\nOut[24]:\\\\nTrue\\\\nIn [25]:\\\\n\"f\"\\\\nin\\\\ns\\\\nOut[25]:\\\\nFalse\\\\nIf a label is not contained in the index, an exception is raised:\\\\nIn [26]:\\\\ns\\\\n[\\\\n\"f\"\\\\n]\\\\n---------------------------------------------------------------------------\\\\nKeyError\\\\nTraceback (most recent call last)\\\\nFile ~/work/pandas/pandas/pandas/core/indexes/base.py:3812,\\\\nin\\\\nIndex.get_loc\\\\n(self, key)\\\\n3811\\\\ntry\\\\n:\\\\n->\\\\n3812\\\\nreturn\\\\nself\\\\n.\\\\n_engine\\\\n.\\\\nget_loc\\\\n(\\\\ncasted_key\\\\n)\\\\n3813\\\\nexcept\\\\nKeyError\\\\nas\\\\nerr\\\\n:\\\\nFile ~/work/pandas/pandas/pandas/_libs/index.pyx:167,\\\\nin\\\\npandas._libs.index.IndexEngine.get_loc\\\\n()\\\\nFile ~/work/pandas/pandas/pandas/_libs/index.pyx:196,\\\\nin\\\\npandas._libs.index.IndexEngine.get_loc\\\\n()\\\\nFile pandas/_libs/hashtable_class_helper.pxi:7088,\\\\nin\\\\npandas._libs.hashtable.PyObjectHashTable.get_item\\\\n()\\\\nFile pandas/_libs/hashtable_class_helper.pxi:7096,\\\\nin\\\\npandas._libs.hashtable.PyObjectHashTable.get_item\\\\n()\\\\nKeyError\\\\n: \\'f\\'\\\\nThe\\\\nabove\\\\nexception\\\\nwas\\\\nthe\\\\ndirect\\\\ncause\\\\nof\\\\nthe\\\\nfollowing\\\\nexception\\\\n:\\\\nKeyError\\\\nTraceback (most recent call last)\\\\nCell\\\\nIn\\\\n[\\\\n26\\\\n],\\\\nline\\\\n1\\\\n---->\\\\n1\\\\ns\\\\n[\\\\n\"f\"\\\\n]\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:1130,\\\\nin\\\\nSeries.__getitem__\\\\n(self, key)\\\\n1127\\\\nreturn\\\\nself\\\\n.\\\\n_values\\\\n[\\\\nkey\\\\n]\\\\n1129\\\\nelif\\\\nkey_is_scalar\\\\n:\\\\n->\\\\n1130\\\\nreturn\\\\nself\\\\n.\\\\n_get_value\\\\n(\\\\nkey\\\\n)\\\\n1132\\\\n# Convert generator to list before going through hashable part\\\\n1133\\\\n# (We will iterate through the generator there to check for slices)\\\\n1134\\\\nif\\\\nis_iterator\\\\n(\\\\nkey\\\\n):\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:1246,\\\\nin\\\\nSeries._get_value\\\\n(self, label, takeable)\\\\n1243\\\\nreturn\\\\nself\\\\n.\\\\n_values\\\\n[\\\\nlabel\\\\n]\\\\n1245\\\\n# Similar to Index.get_value, but we do not fall back to positional\\\\n->\\\\n1246\\\\nloc\\\\n=\\\\nself\\\\n.\\\\nindex\\\\n.\\\\nget_loc\\\\n(\\\\nlabel\\\\n)\\\\n1248\\\\nif\\\\nis_integer\\\\n(\\\\nloc\\\\n):\\\\n1249\\\\nreturn\\\\nself\\\\n.\\\\n_values\\\\n[\\\\nloc\\\\n]\\\\nFile ~/work/pandas/pandas/pandas/core/indexes/base.py:3819,\\\\nin\\\\nIndex.get_loc\\\\n(self, key)\\\\n3814\\\\nif\\\\nisinstance\\\\n(\\\\ncasted_key\\\\n,\\\\nslice\\\\n)\\\\nor\\\\n(\\\\n3815\\\\nisinstance\\\\n(\\\\ncasted_key\\\\n,\\\\nabc\\\\n.\\\\nIterable\\\\n)\\\\n3816\\\\nand\\\\nany\\\\n(\\\\nisinstance\\\\n(\\\\nx\\\\n,\\\\nslice\\\\n)\\\\nfor\\\\nx\\\\nin\\\\ncasted_key\\\\n)\\\\n3817\\\\n):\\\\n3818\\\\nraise\\\\nInvalidIndexError\\\\n(\\\\nkey\\\\n)\\\\n->\\\\n3819\\\\nraise\\\\nKeyError\\\\n(\\\\nkey\\\\n)\\\\nfrom\\\\nerr\\\\n3820\\\\nexcept\\\\nTypeError\\\\n:\\\\n3821\\\\n# If we have a listlike key, _check_indexing_error will raise\\\\n3822\\\\n#  InvalidIndexError. Otherwise we fall through and re-raise\\\\n3823\\\\n#  the TypeError.\\\\n3824\\\\nself\\\\n.\\\\n_check_indexing_error\\\\n(\\\\nkey\\\\n)\\\\nKeyError\\\\n: \\'f\\'\\\\nUsing the\\\\nSeries.get()\\\\nmethod, a missing label will return None or specified default:\\\\nIn [27]:\\\\ns\\\\n.\\\\nget\\\\n(\\\\n\"f\"\\\\n)\\\\nIn [28]:\\\\ns\\\\n.\\\\nget\\\\n(\\\\n\"f\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n)\\\\nOut[28]:\\\\nnan\\\\nThese labels can also be accessed by\\\\nattribute\\\\n.\\\\nVectorized operations and label alignment with Series\\\\n#\\\\nWhen working with raw NumPy arrays, looping through value-by-value is usually\\nnot necessary. The same is true when working with\\\\nSeries\\\\nin pandas.\\\\nSeries\\\\ncan also be passed into most NumPy methods expecting an ndarray.\\\\nIn [29]:\\\\ns\\\\n+\\\\ns\\\\nOut[29]:\\\\na     0.938225\\\\nb    -0.565727\\\\nc    -3.018117\\\\nd    -2.271265\\\\ne    24.000000\\\\ndtype: float64\\\\nIn [30]:\\\\ns\\\\n*\\\\n2\\\\nOut[30]:\\\\na     0.938225\\\\nb    -0.565727\\\\nc    -3.018117\\\\nd    -2.271265\\\\ne    24.000000\\\\ndtype: float64\\\\nIn [31]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\ns\\\\n)\\\\nOut[31]:\\\\na         1.598575\\\\nb         0.753623\\\\nc         0.221118\\\\nd         0.321219\\\\ne    162754.791419\\\\ndtype: float64\\\\nA key difference between\\\\nSeries\\\\nand ndarray is that operations between\\\\nSeries\\\\nautomatically align the data based on label. Thus, you can write computations\\nwithout giving consideration to whether the\\\\nSeries\\\\ninvolved have the same\\nlabels.\\\\nIn [32]:\\\\ns\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n:]\\\\n+\\\\ns\\\\n.\\\\niloc\\\\n[:\\\\n-\\\\n1\\\\n]\\\\nOut[32]:\\\\na         NaN\\\\nb   -0.565727\\\\nc   -3.018117\\\\nd   -2.271265\\\\ne         NaN\\\\ndtype: float64\\\\nThe result of an operation between unaligned\\\\nSeries\\\\nwill have the\\\\nunion\\\\nof\\nthe indexes involved. If a label is not found in one\\\\nSeries\\\\nor the other, the\\nresult will be marked as missing\\\\nNaN\\\\n. Being able to write code without doing\\nany explicit data alignment grants immense freedom and flexibility in\\ninteractive data analysis and research. The integrated data alignment features\\nof the pandas data structures set pandas apart from the majority of related\\ntools for working with labeled data.\\\\nNote\\\\nIn general, we chose to make the default result of operations between\\ndifferently indexed objects yield the\\\\nunion\\\\nof the indexes in order to\\navoid loss of information. Having an index label, though the data is\\nmissing, is typically important information as part of a computation. You\\nof course have the option of dropping labels with missing data via the\\\\ndropna\\\\nfunction.\\\\nName attribute\\\\n#\\\\nSeries\\\\nalso has a\\\\nname\\\\nattribute:\\\\nIn [33]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nname\\\\n=\\\\n\"something\"\\\\n)\\\\nIn [34]:\\\\ns\\\\nOut[34]:\\\\n0   -0.494929\\\\n1    1.071804\\\\n2    0.721555\\\\n3   -0.706771\\\\n4   -1.039575\\\\nName: something, dtype: float64\\\\nIn [35]:\\\\ns\\\\n.\\\\nname\\\\nOut[35]:\\\\n\\'something\\'\\\\nThe\\\\nSeries\\\\nname\\\\ncan be assigned automatically in many cases, in particular,\\nwhen selecting a single column from a\\\\nDataFrame\\\\n, the\\\\nname\\\\nwill be assigned\\nthe column label.\\\\nYou can rename a\\\\nSeries\\\\nwith the\\\\npandas.Series.rename()\\\\nmethod.\\\\nIn [36]:\\\\ns2\\\\n=\\\\ns\\\\n.\\\\nrename\\\\n(\\\\n\"different\"\\\\n)\\\\nIn [37]:\\\\ns2\\\\n.\\\\nname\\\\nOut[37]:\\\\n\\'different\\'\\\\nNote that\\\\ns\\\\nand\\\\ns2\\\\nrefer to different objects.\\\\nDataFrame\\\\n#\\\\nDataFrame\\\\nis a 2-dimensional labeled data structure with columns of\\npotentially different types. You can think of it like a spreadsheet or SQL\\ntable, or a dict of Series objects. It is generally the most commonly used\\npandas object. Like Series, DataFrame accepts many different kinds of input:\\\\nDict of 1D ndarrays, lists, dicts, or\\\\nSeries\\\\n2-D numpy.ndarray\\\\nStructured or record\\\\nndarray\\\\nA\\\\nSeries\\\\nAnother\\\\nDataFrame\\\\nAlong with the data, you can optionally pass\\\\nindex\\\\n(row labels) and\\\\ncolumns\\\\n(column labels) arguments. If you pass an index and / or columns,\\nyou are guaranteeing the index and / or columns of the resulting\\nDataFrame. Thus, a dict of Series plus a specific index will discard all data\\nnot matching up to the passed index.\\\\nIf axis labels are not passed, they will be constructed from the input data\\nbased on common sense rules.\\\\nFrom dict of Series or dicts\\\\n#\\\\nThe resulting\\\\nindex\\\\nwill be the\\\\nunion\\\\nof the indexes of the various\\nSeries. If there are any nested dicts, these will first be converted to\\nSeries. If no columns are passed, the columns will be the ordered list of dict\\nkeys.\\\\nIn [38]:\\\\nd\\\\n=\\\\n{\\\\n....:\\\\n\"one\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]),\\\\n....:\\\\n\"two\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n....:\\\\n}\\\\n....:\\\\nIn [39]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n)\\\\nIn [40]:\\\\ndf\\\\nOut[40]:\\\\none  two\\\\na  1.0  1.0\\\\nb  2.0  2.0\\\\nc  3.0  3.0\\\\nd  NaN  4.0\\\\nIn [41]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"d\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n])\\\\nOut[41]:\\\\none  two\\\\nd  NaN  4.0\\\\nb  2.0  2.0\\\\na  1.0  1.0\\\\nIn [42]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"d\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n])\\\\nOut[42]:\\\\ntwo three\\\\nd  4.0   NaN\\\\nb  2.0   NaN\\\\na  1.0   NaN\\\\nThe row and column labels can be accessed respectively by accessing the\\\\nindex\\\\nand\\\\ncolumns\\\\nattributes:\\\\nNote\\\\nWhen a particular set of columns is passed along with a dict of data, the\\npassed columns override the keys in the dict.\\\\nIn [43]:\\\\ndf\\\\n.\\\\nindex\\\\nOut[43]:\\\\nIndex([\\'a\\', \\'b\\', \\'c\\', \\'d\\'], dtype=\\'object\\')\\\\nIn [44]:\\\\ndf\\\\n.\\\\ncolumns\\\\nOut[44]:\\\\nIndex([\\'one\\', \\'two\\'], dtype=\\'object\\')\\\\nFrom dict of ndarrays / lists\\\\n#\\\\nAll ndarrays must share the same length. If an index is passed, it must\\nalso be the same length as the arrays. If no index is passed, the\\nresult will be\\\\nrange(n)\\\\n, where\\\\nn\\\\nis the array length.\\\\nIn [45]:\\\\nd\\\\n=\\\\n{\\\\n\"one\"\\\\n:\\\\n[\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n],\\\\n\"two\"\\\\n:\\\\n[\\\\n4.0\\\\n,\\\\n3.0\\\\n,\\\\n2.0\\\\n,\\\\n1.0\\\\n]}\\\\nIn [46]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n)\\\\nOut[46]:\\\\none  two\\\\n0  1.0  4.0\\\\n1  2.0  3.0\\\\n2  3.0  2.0\\\\n3  4.0  1.0\\\\nIn [47]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n])\\\\nOut[47]:\\\\none  two\\\\na  1.0  4.0\\\\nb  2.0  3.0\\\\nc  3.0  2.0\\\\nd  4.0  1.0\\\\nFrom structured or record array\\\\n#\\\\nThis case is handled identically to a dict of arrays.\\\\nIn [48]:\\\\ndata\\\\n=\\\\nnp\\\\n.\\\\nzeros\\\\n((\\\\n2\\\\n,),\\\\ndtype\\\\n=\\\\n[(\\\\n\"A\"\\\\n,\\\\n\"i4\"\\\\n),\\\\n(\\\\n\"B\"\\\\n,\\\\n\"f4\"\\\\n),\\\\n(\\\\n\"C\"\\\\n,\\\\n\"a10\"\\\\n)])\\\\nIn [49]:\\\\ndata\\\\n[:]\\\\n=\\\\n[(\\\\n1\\\\n,\\\\n2.0\\\\n,\\\\n\"Hello\"\\\\n),\\\\n(\\\\n2\\\\n,\\\\n3.0\\\\n,\\\\n\"World\"\\\\n)]\\\\nIn [50]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n)\\\\nOut[50]:\\\\nA    B         C\\\\n0  1  2.0  b\\'Hello\\'\\\\n1  2  3.0  b\\'World\\'\\\\nIn [51]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n])\\\\nOut[51]:\\\\nA    B         C\\\\nfirst   1  2.0  b\\'Hello\\'\\\\nsecond  2  3.0  b\\'World\\'\\\\nIn [52]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"C\"\\\\n,\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n])\\\\nOut[52]:\\\\nC  A    B\\\\n0  b\\'Hello\\'  1  2.0\\\\n1  b\\'World\\'  2  3.0\\\\nNote\\\\nDataFrame is not intended to work exactly like a 2-dimensional NumPy\\nndarray.\\\\nFrom a list of dicts\\\\n#\\\\nIn [53]:\\\\ndata2\\\\n=\\\\n[{\\\\n\"a\"\\\\n:\\\\n1\\\\n,\\\\n\"b\"\\\\n:\\\\n2\\\\n},\\\\n{\\\\n\"a\"\\\\n:\\\\n5\\\\n,\\\\n\"b\"\\\\n:\\\\n10\\\\n,\\\\n\"c\"\\\\n:\\\\n20\\\\n}]\\\\nIn [54]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata2\\\\n)\\\\nOut[54]:\\\\na   b     c\\\\n0  1   2   NaN\\\\n1  5  10  20.0\\\\nIn [55]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata2\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n])\\\\nOut[55]:\\\\na   b     c\\\\nfirst   1   2   NaN\\\\nsecond  5  10  20.0\\\\nIn [56]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata2\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n])\\\\nOut[56]:\\\\na   b\\\\n0  1   2\\\\n1  5  10\\\\nFrom a dict of tuples\\\\n#\\\\nYou can automatically create a MultiIndexed frame by passing a tuples\\ndictionary.\\\\nIn [57]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n(\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n1\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n2\\\\n},\\\\n....:\\\\n(\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n3\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n4\\\\n},\\\\n....:\\\\n(\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n5\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n6\\\\n},\\\\n....:\\\\n(\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n7\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n8\\\\n},\\\\n....:\\\\n(\\\\n\"b\"\\\\n,\\\\n\"b\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"D\"\\\\n):\\\\n9\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n10\\\\n},\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nOut[57]:\\\\na              b\\\\nb    a    c    a     b\\\\nA B  1.0  4.0  5.0  8.0  10.0\\\\nC  2.0  3.0  6.0  7.0   NaN\\\\nD  NaN  NaN  NaN  NaN   9.0\\\\nFrom a Series\\\\n#\\\\nThe result will be a DataFrame with the same index as the input Series, and\\nwith one column whose name is the original name of the Series (only if no other\\ncolumn name provided).\\\\nIn [58]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nrange\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\n\"abc\"\\\\n),\\\\nname\\\\n=\\\\n\"ser\"\\\\n)\\\\nIn [59]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nser\\\\n)\\\\nOut[59]:\\\\nser\\\\na    0\\\\nb    1\\\\nc    2\\\\nFrom a list of namedtuples\\\\n#\\\\nThe field names of the first\\\\nnamedtuple\\\\nin the list determine the columns\\nof the\\\\nDataFrame\\\\n. The remaining namedtuples (or tuples) are simply unpacked\\nand their values are fed into the rows of the\\\\nDataFrame\\\\n. If any of those\\ntuples is shorter than the first\\\\nnamedtuple\\\\nthen the later columns in the\\ncorresponding row are marked as missing values. If any are longer than the\\nfirst\\\\nnamedtuple\\\\n, a\\\\nValueError\\\\nis raised.\\\\nIn [60]:\\\\nfrom\\\\ncollections\\\\nimport\\\\nnamedtuple\\\\nIn [61]:\\\\nPoint\\\\n=\\\\nnamedtuple\\\\n(\\\\n\"Point\"\\\\n,\\\\n\"x y\"\\\\n)\\\\nIn [62]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n0\\\\n),\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n3\\\\n),\\\\n(\\\\n2\\\\n,\\\\n3\\\\n)])\\\\nOut[62]:\\\\nx  y\\\\n0  0  0\\\\n1  0  3\\\\n2  2  3\\\\nIn [63]:\\\\nPoint3D\\\\n=\\\\nnamedtuple\\\\n(\\\\n\"Point3D\"\\\\n,\\\\n\"x y z\"\\\\n)\\\\nIn [64]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\nPoint3D\\\\n(\\\\n0\\\\n,\\\\n0\\\\n,\\\\n0\\\\n),\\\\nPoint3D\\\\n(\\\\n0\\\\n,\\\\n3\\\\n,\\\\n5\\\\n),\\\\nPoint\\\\n(\\\\n2\\\\n,\\\\n3\\\\n)])\\\\nOut[64]:\\\\nx  y    z\\\\n0  0  0  0.0\\\\n1  0  3  5.0\\\\n2  2  3  NaN\\\\nFrom a list of dataclasses\\\\n#\\\\nData Classes as introduced in\\\\nPEP557\\\\n,\\ncan be passed into the DataFrame constructor.\\nPassing a list of dataclasses is equivalent to passing a list of dictionaries.\\\\nPlease be aware, that all values in the list should be dataclasses, mixing\\ntypes in the list would result in a\\\\nTypeError\\\\n.\\\\nIn [65]:\\\\nfrom\\\\ndataclasses\\\\nimport\\\\nmake_dataclass\\\\nIn [66]:\\\\nPoint\\\\n=\\\\nmake_dataclass\\\\n(\\\\n\"Point\"\\\\n,\\\\n[(\\\\n\"x\"\\\\n,\\\\nint\\\\n),\\\\n(\\\\n\"y\"\\\\n,\\\\nint\\\\n)])\\\\nIn [67]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n0\\\\n),\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n3\\\\n),\\\\nPoint\\\\n(\\\\n2\\\\n,\\\\n3\\\\n)])\\\\nOut[67]:\\\\nx  y\\\\n0  0  0\\\\n1  0  3\\\\n2  2  3\\\\nMissing data\\\\nTo construct a DataFrame with missing data, we use\\\\nnp.nan\\\\nto\\nrepresent missing values. Alternatively, you may pass a\\\\nnumpy.MaskedArray\\\\nas the data argument to the DataFrame constructor, and its masked entries will\\nbe considered missing. See\\\\nMissing data\\\\nfor more.\\\\nAlternate constructors\\\\n#\\\\nDataFrame.from_dict\\\\nDataFrame.from_dict()\\\\ntakes a dict of dicts or a dict of array-like sequences\\nand returns a DataFrame. It operates like the\\\\nDataFrame\\\\nconstructor except\\nfor the\\\\norient\\\\nparameter which is\\\\n\\'columns\\'\\\\nby default, but which can be\\nset to\\\\n\\'index\\'\\\\nin order to use the dict keys as row labels.\\\\nIn [68]:\\\\npd\\\\n.\\\\nDataFrame\\\\n.\\\\nfrom_dict\\\\n(\\\\ndict\\\\n([(\\\\n\"A\"\\\\n,\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]),\\\\n(\\\\n\"B\"\\\\n,\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n])]))\\\\nOut[68]:\\\\nA  B\\\\n0  1  4\\\\n1  2  5\\\\n2  3  6\\\\nIf you pass\\\\norient=\\'index\\'\\\\n, the keys will be the row labels. In this\\ncase, you can also pass the desired column names:\\\\nIn [69]:\\\\npd\\\\n.\\\\nDataFrame\\\\n.\\\\nfrom_dict\\\\n(\\\\n....:\\\\ndict\\\\n([(\\\\n\"A\"\\\\n,\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]),\\\\n(\\\\n\"B\"\\\\n,\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n])]),\\\\n....:\\\\norient\\\\n=\\\\n\"index\"\\\\n,\\\\n....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n],\\\\n....:\\\\n)\\\\n....:\\\\nOut[69]:\\\\none  two  three\\\\nA    1    2      3\\\\nB    4    5      6\\\\nDataFrame.from_records\\\\nDataFrame.from_records()\\\\ntakes a list of tuples or an ndarray with structured\\ndtype. It works analogously to the normal\\\\nDataFrame\\\\nconstructor, except that\\nthe resulting DataFrame index may be a specific field of the structured\\ndtype.\\\\nIn [70]:\\\\ndata\\\\nOut[70]:\\\\narray([(1, 2., b\\'Hello\\'), (2, 3., b\\'World\\')],\\\\ndtype=[(\\'A\\', \\'<i4\\'), (\\'B\\', \\'<f4\\'), (\\'C\\', \\'S10\\')])\\\\nIn [71]:\\\\npd\\\\n.\\\\nDataFrame\\\\n.\\\\nfrom_records\\\\n(\\\\ndata\\\\n,\\\\nindex\\\\n=\\\\n\"C\"\\\\n)\\\\nOut[71]:\\\\nA    B\\\\nC\\\\nb\\'Hello\\'  1  2.0\\\\nb\\'World\\'  2  3.0\\\\nColumn selection, addition, deletion\\\\n#\\\\nYou can treat a\\\\nDataFrame\\\\nsemantically like a dict of like-indexed\\\\nSeries\\\\nobjects. Getting, setting, and deleting columns works with the same syntax as\\nthe analogous dict operations:\\\\nIn [72]:\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\nOut[72]:\\\\na    1.0\\\\nb    2.0\\\\nc    3.0\\\\nd    NaN\\\\nName: one, dtype: float64\\\\nIn [73]:\\\\ndf\\\\n[\\\\n\"three\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\n*\\\\ndf\\\\n[\\\\n\"two\"\\\\n]\\\\nIn [74]:\\\\ndf\\\\n[\\\\n\"flag\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\n>\\\\n2\\\\nIn [75]:\\\\ndf\\\\nOut[75]:\\\\none  two  three   flag\\\\na  1.0  1.0    1.0  False\\\\nb  2.0  2.0    4.0  False\\\\nc  3.0  3.0    9.0   True\\\\nd  NaN  4.0    NaN  False\\\\nColumns can be deleted or popped like with a dict:\\\\nIn [76]:\\\\ndel\\\\ndf\\\\n[\\\\n\"two\"\\\\n]\\\\nIn [77]:\\\\nthree\\\\n=\\\\ndf\\\\n.\\\\npop\\\\n(\\\\n\"three\"\\\\n)\\\\nIn [78]:\\\\ndf\\\\nOut[78]:\\\\none   flag\\\\na  1.0  False\\\\nb  2.0  False\\\\nc  3.0   True\\\\nd  NaN  False\\\\nWhen inserting a scalar value, it will naturally be propagated to fill the\\ncolumn:\\\\nIn [79]:\\\\ndf\\\\n[\\\\n\"foo\"\\\\n]\\\\n=\\\\n\"bar\"\\\\nIn [80]:\\\\ndf\\\\nOut[80]:\\\\none   flag  foo\\\\na  1.0  False  bar\\\\nb  2.0  False  bar\\\\nc  3.0   True  bar\\\\nd  NaN  False  bar\\\\nWhen inserting a\\\\nSeries\\\\nthat does not have the same index as the\\\\nDataFrame\\\\n, it\\nwill be conformed to the DataFrame’s index:\\\\nIn [81]:\\\\ndf\\\\n[\\\\n\"one_trunc\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"one\"\\\\n][:\\\\n2\\\\n]\\\\nIn [82]:\\\\ndf\\\\nOut[82]:\\\\none   flag  foo  one_trunc\\\\na  1.0  False  bar        1.0\\\\nb  2.0  False  bar        2.0\\\\nc  3.0   True  bar        NaN\\\\nd  NaN  False  bar        NaN\\\\nYou can insert raw ndarrays but their length must match the length of the\\nDataFrame’s index.\\\\nBy default, columns get inserted at the end.\\\\nDataFrame.insert()\\\\ninserts at a particular location in the columns:\\\\nIn [83]:\\\\ndf\\\\n.\\\\ninsert\\\\n(\\\\n1\\\\n,\\\\n\"bar\"\\\\n,\\\\ndf\\\\n[\\\\n\"one\"\\\\n])\\\\nIn [84]:\\\\ndf\\\\nOut[84]:\\\\none  bar   flag  foo  one_trunc\\\\na  1.0  1.0  False  bar        1.0\\\\nb  2.0  2.0  False  bar        2.0\\\\nc  3.0  3.0   True  bar        NaN\\\\nd  NaN  NaN  False  bar        NaN\\\\nAssigning new columns in method chains\\\\n#\\\\nInspired by\\\\ndplyr’s\\\\nmutate\\\\nverb, DataFrame has an\\\\nassign()\\\\nmethod that allows you to easily create new columns that are potentially\\nderived from existing columns.\\\\nIn [85]:\\\\niris\\\\n=\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"data/iris.data\"\\\\n)\\\\nIn [86]:\\\\niris\\\\n.\\\\nhead\\\\n()\\\\nOut[86]:\\\\nSepalLength  SepalWidth  PetalLength  PetalWidth         Name\\\\n0          5.1         3.5          1.4         0.2  Iris-setosa\\\\n1          4.9         3.0          1.4         0.2  Iris-setosa\\\\n2          4.7         3.2          1.3         0.2  Iris-setosa\\\\n3          4.6         3.1          1.5         0.2  Iris-setosa\\\\n4          5.0         3.6          1.4         0.2  Iris-setosa\\\\nIn [87]:\\\\niris\\\\n.\\\\nassign\\\\n(\\\\nsepal_ratio\\\\n=\\\\niris\\\\n[\\\\n\"SepalWidth\"\\\\n]\\\\n/\\\\niris\\\\n[\\\\n\"SepalLength\"\\\\n])\\\\n.\\\\nhead\\\\n()\\\\nOut[87]:\\\\nSepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio\\\\n0          5.1         3.5          1.4         0.2  Iris-setosa     0.686275\\\\n1          4.9         3.0          1.4         0.2  Iris-setosa     0.612245\\\\n2          4.7         3.2          1.3         0.2  Iris-setosa     0.680851\\\\n3          4.6         3.1          1.5         0.2  Iris-setosa     0.673913\\\\n4          5.0         3.6          1.4         0.2  Iris-setosa     0.720000\\\\nIn the example above, we inserted a precomputed value. We can also pass in\\na function of one argument to be evaluated on the DataFrame being assigned to.\\\\nIn [88]:\\\\niris\\\\n.\\\\nassign\\\\n(\\\\nsepal_ratio\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\n(\\\\nx\\\\n[\\\\n\"SepalWidth\"\\\\n]\\\\n/\\\\nx\\\\n[\\\\n\"SepalLength\"\\\\n]))\\\\n.\\\\nhead\\\\n()\\\\nOut[88]:\\\\nSepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio\\\\n0          5.1         3.5          1.4         0.2  Iris-setosa     0.686275\\\\n1          4.9         3.0          1.4         0.2  Iris-setosa     0.612245\\\\n2          4.7         3.2          1.3         0.2  Iris-setosa     0.680851\\\\n3          4.6         3.1          1.5         0.2  Iris-setosa     0.673913\\\\n4          5.0         3.6          1.4         0.2  Iris-setosa     0.720000\\\\nassign()\\\\nalways\\\\nreturns a copy of the data, leaving the original\\nDataFrame untouched.\\\\nPassing a callable, as opposed to an actual value to be inserted, is\\nuseful when you don’t have a reference to the DataFrame at hand. This is\\ncommon when using\\\\nassign()\\\\nin a chain of operations. For example,\\nwe can limit the DataFrame to just those observations with a Sepal Length\\ngreater than 5, calculate the ratio, and plot:\\\\nIn [89]:\\\\n(\\\\n....:\\\\niris\\\\n.\\\\nquery\\\\n(\\\\n\"SepalLength > 5\"\\\\n)\\\\n....:\\\\n.\\\\nassign\\\\n(\\\\n....:\\\\nSepalRatio\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nSepalWidth\\\\n/\\\\nx\\\\n.\\\\nSepalLength\\\\n,\\\\n....:\\\\nPetalRatio\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nPetalWidth\\\\n/\\\\nx\\\\n.\\\\nPetalLength\\\\n,\\\\n....:\\\\n)\\\\n....:\\\\n.\\\\nplot\\\\n(\\\\nkind\\\\n=\\\\n\"scatter\"\\\\n,\\\\nx\\\\n=\\\\n\"SepalRatio\"\\\\n,\\\\ny\\\\n=\\\\n\"PetalRatio\"\\\\n)\\\\n....:\\\\n)\\\\n....:\\\\nOut[89]:\\\\n<Axes: xlabel=\\'SepalRatio\\', ylabel=\\'PetalRatio\\'>\\\\nSince a function is passed in, the function is computed on the DataFrame\\nbeing assigned to. Importantly, this is the DataFrame that’s been filtered\\nto those rows with sepal length greater than 5. The filtering happens first,\\nand then the ratio calculations. This is an example where we didn’t\\nhave a reference to the\\\\nfiltered\\\\nDataFrame available.\\\\nThe function signature for\\\\nassign()\\\\nis simply\\\\n**kwargs\\\\n. The keys\\nare the column names for the new fields, and the values are either a value\\nto be inserted (for example, a\\\\nSeries\\\\nor NumPy array), or a function\\nof one argument to be called on the\\\\nDataFrame\\\\n. A\\\\ncopy\\\\nof the original\\\\nDataFrame\\\\nis returned, with the new values inserted.\\\\nThe order of\\\\n**kwargs\\\\nis preserved. This allows\\nfor\\\\ndependent\\\\nassignment, where an expression later in\\\\n**kwargs\\\\ncan refer\\nto a column created earlier in the same\\\\nassign()\\\\n.\\\\nIn [90]:\\\\ndfa\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"A\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"B\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n]})\\\\nIn [91]:\\\\ndfa\\\\n.\\\\nassign\\\\n(\\\\nC\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n[\\\\n\"A\"\\\\n]\\\\n+\\\\nx\\\\n[\\\\n\"B\"\\\\n],\\\\nD\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n[\\\\n\"A\"\\\\n]\\\\n+\\\\nx\\\\n[\\\\n\"C\"\\\\n])\\\\nOut[91]:\\\\nA  B  C   D\\\\n0  1  4  5   6\\\\n1  2  5  7   9\\\\n2  3  6  9  12\\\\nIn the second expression,\\\\nx[\\'C\\']\\\\nwill refer to the newly created column,\\nthat’s equal to\\\\ndfa[\\'A\\']\\\\n+\\\\ndfa[\\'B\\']\\\\n.\\\\nIndexing / selection\\\\n#\\\\nThe basics of indexing are as follows:\\\\nOperation\\\\nSyntax\\\\nResult\\\\nSelect column\\\\ndf[col]\\\\nSeries\\\\nSelect row by label\\\\ndf.loc[label]\\\\nSeries\\\\nSelect row by integer location\\\\ndf.iloc[loc]\\\\nSeries\\\\nSlice rows\\\\ndf[5:10]\\\\nDataFrame\\\\nSelect rows by boolean vector\\\\ndf[bool_vec]\\\\nDataFrame\\\\nRow selection, for example, returns a\\\\nSeries\\\\nwhose index is the columns of the\\\\nDataFrame\\\\n:\\\\nIn [92]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\n\"b\"\\\\n]\\\\nOut[92]:\\\\none            2.0\\\\nbar            2.0\\\\nflag         False\\\\nfoo            bar\\\\none_trunc      2.0\\\\nName: b, dtype: object\\\\nIn [93]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n2\\\\n]\\\\nOut[93]:\\\\none           3.0\\\\nbar           3.0\\\\nflag         True\\\\nfoo           bar\\\\none_trunc     NaN\\\\nName: c, dtype: object\\\\nFor a more exhaustive treatment of sophisticated label-based indexing and\\nslicing, see the\\\\nsection on indexing\\\\n. We will address the\\nfundamentals of reindexing / conforming to new sets of labels in the\\\\nsection on reindexing\\\\n.\\\\nData alignment and arithmetic\\\\n#\\\\nData alignment between\\\\nDataFrame\\\\nobjects automatically align on\\\\nboth the\\ncolumns and the index (row labels)\\\\n. Again, the resulting object will have the\\nunion of the column and row labels.\\\\nIn [94]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n4\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"D\"\\\\n])\\\\nIn [95]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n7\\\\n,\\\\n3\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n])\\\\nIn [96]:\\\\ndf\\\\n+\\\\ndf2\\\\nOut[96]:\\\\nA         B         C   D\\\\n0  0.045691 -0.014138  1.380871 NaN\\\\n1 -0.955398 -1.501007  0.037181 NaN\\\\n2 -0.662690  1.534833 -0.859691 NaN\\\\n3 -2.452949  1.237274 -0.133712 NaN\\\\n4  1.414490  1.951676 -2.320422 NaN\\\\n5 -0.494922 -1.649727 -1.084601 NaN\\\\n6 -1.047551 -0.748572 -0.805479 NaN\\\\n7       NaN       NaN       NaN NaN\\\\n8       NaN       NaN       NaN NaN\\\\n9       NaN       NaN       NaN NaN\\\\nWhen doing an operation between\\\\nDataFrame\\\\nand\\\\nSeries\\\\n, the default behavior is\\nto align the\\\\nSeries\\\\nindex\\\\non the\\\\nDataFrame\\\\ncolumns\\\\n, thus\\\\nbroadcasting\\\\nrow-wise. For example:\\\\nIn [97]:\\\\ndf\\\\n-\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n0\\\\n]\\\\nOut[97]:\\\\nA         B         C         D\\\\n0  0.000000  0.000000  0.000000  0.000000\\\\n1 -1.359261 -0.248717 -0.453372 -1.754659\\\\n2  0.253128  0.829678  0.010026 -1.991234\\\\n3 -1.311128  0.054325 -1.724913 -1.620544\\\\n4  0.573025  1.500742 -0.676070  1.367331\\\\n5 -1.741248  0.781993 -1.241620 -2.053136\\\\n6 -1.240774 -0.869551 -0.153282  0.000430\\\\n7 -0.743894  0.411013 -0.929563 -0.282386\\\\n8 -1.194921  1.320690  0.238224 -1.482644\\\\n9  2.293786  1.856228  0.773289 -1.446531\\\\nFor explicit control over the matching and broadcasting behavior, see the\\nsection on\\\\nflexible binary operations\\\\n.\\\\nArithmetic operations with scalars operate element-wise:\\\\nIn [98]:\\\\ndf\\\\n*\\\\n5\\\\n+\\\\n2\\\\nOut[98]:\\\\nA         B         C          D\\\\n0   3.359299 -0.124862  4.835102   3.381160\\\\n1  -3.437003 -1.368449  2.568242  -5.392133\\\\n2   4.624938  4.023526  4.885230  -6.575010\\\\n3  -3.196342  0.146766 -3.789461  -4.721559\\\\n4   6.224426  7.378849  1.454750  10.217815\\\\n5  -5.346940  3.785103 -1.373001  -6.884519\\\\n6  -2.844569 -4.472618  4.068691   3.383309\\\\n7  -0.360173  1.930201  0.187285   1.969232\\\\n8  -2.615303  6.478587  6.026220  -4.032059\\\\n9  14.828230  9.156280  8.701544  -3.851494\\\\nIn [99]:\\\\n1\\\\n/\\\\ndf\\\\nOut[99]:\\\\nA          B         C           D\\\\n0  3.678365  -2.353094  1.763605    3.620145\\\\n1 -0.919624  -1.484363  8.799067   -0.676395\\\\n2  1.904807   2.470934  1.732964   -0.583090\\\\n3 -0.962215  -2.697986 -0.863638   -0.743875\\\\n4  1.183593   0.929567 -9.170108    0.608434\\\\n5 -0.680555   2.800959 -1.482360   -0.562777\\\\n6 -1.032084  -0.772485  2.416988    3.614523\\\\n7 -2.118489 -71.634509 -2.758294 -162.507295\\\\n8 -1.083352   1.116424  1.241860   -0.828904\\\\n9  0.389765   0.698687  0.746097   -0.854483\\\\nIn [100]:\\\\ndf\\\\n**\\\\n4\\\\nOut[100]:\\\\nA             B         C             D\\\\n0   0.005462  3.261689e-02  0.103370  5.822320e-03\\\\n1   1.398165  2.059869e-01  0.000167  4.777482e+00\\\\n2   0.075962  2.682596e-02  0.110877  8.650845e+00\\\\n3   1.166571  1.887302e-02  1.797515  3.265879e+00\\\\n4   0.509555  1.339298e+00  0.000141  7.297019e+00\\\\n5   4.661717  1.624699e-02  0.207103  9.969092e+00\\\\n6   0.881334  2.808277e+00  0.029302  5.858632e-03\\\\n7   0.049647  3.797614e-08  0.017276  1.433866e-09\\\\n8   0.725974  6.437005e-01  0.420446  2.118275e+00\\\\n9  43.329821  4.196326e+00  3.227153  1.875802e+00\\\\nBoolean operators operate element-wise as well:\\\\nIn [101]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n0\\\\n,\\\\n1\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n0\\\\n,\\\\n1\\\\n,\\\\n1\\\\n]},\\\\ndtype\\\\n=\\\\nbool\\\\n)\\\\nIn [102]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n0\\\\n,\\\\n1\\\\n,\\\\n1\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n1\\\\n,\\\\n0\\\\n]},\\\\ndtype\\\\n=\\\\nbool\\\\n)\\\\nIn [103]:\\\\ndf1\\\\n&\\\\ndf2\\\\nOut[103]:\\\\na      b\\\\n0  False  False\\\\n1  False   True\\\\n2   True  False\\\\nIn [104]:\\\\ndf1\\\\n|\\\\ndf2\\\\nOut[104]:\\\\na     b\\\\n0  True  True\\\\n1  True  True\\\\n2  True  True\\\\nIn [105]:\\\\ndf1\\\\n^\\\\ndf2\\\\nOut[105]:\\\\na      b\\\\n0   True   True\\\\n1   True  False\\\\n2  False   True\\\\nIn [106]:\\\\n-\\\\ndf1\\\\nOut[106]:\\\\na      b\\\\n0  False   True\\\\n1   True  False\\\\n2  False  False\\\\nTransposing\\\\n#\\\\nTo transpose, access the\\\\nT\\\\nattribute or\\\\nDataFrame.transpose()\\\\n,\\nsimilar to an ndarray:\\\\n# only show the first 5 rows\\\\nIn [107]:\\\\ndf\\\\n[:\\\\n5\\\\n]\\\\n.\\\\nT\\\\nOut[107]:\\\\n0         1         2         3         4\\\\nA  0.271860 -1.087401  0.524988 -1.039268  0.844885\\\\nB -0.424972 -0.673690  0.404705 -0.370647  1.075770\\\\nC  0.567020  0.113648  0.577046 -1.157892 -0.109050\\\\nD  0.276232 -1.478427 -1.715002 -1.344312  1.643563\\\\nDataFrame interoperability with NumPy functions\\\\n#\\\\nMost NumPy functions can be called directly on\\\\nSeries\\\\nand\\\\nDataFrame\\\\n.\\\\nIn [108]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\ndf\\\\n)\\\\nOut[108]:\\\\nA         B         C         D\\\\n0   1.312403  0.653788  1.763006  1.318154\\\\n1   0.337092  0.509824  1.120358  0.227996\\\\n2   1.690438  1.498861  1.780770  0.179963\\\\n3   0.353713  0.690288  0.314148  0.260719\\\\n4   2.327710  2.932249  0.896686  5.173571\\\\n5   0.230066  1.429065  0.509360  0.169161\\\\n6   0.379495  0.274028  1.512461  1.318720\\\\n7   0.623732  0.986137  0.695904  0.993865\\\\n8   0.397301  2.449092  2.237242  0.299269\\\\n9  13.009059  4.183951  3.820223  0.310274\\\\nIn [109]:\\\\nnp\\\\n.\\\\nasarray\\\\n(\\\\ndf\\\\n)\\\\nOut[109]:\\\\narray([[ 0.2719, -0.425 ,  0.567 ,  0.2762],\\\\n[-1.0874, -0.6737,  0.1136, -1.4784],\\\\n[ 0.525 ,  0.4047,  0.577 , -1.715 ],\\\\n[-1.0393, -0.3706, -1.1579, -1.3443],\\\\n[ 0.8449,  1.0758, -0.109 ,  1.6436],\\\\n[-1.4694,  0.357 , -0.6746, -1.7769],\\\\n[-0.9689, -1.2945,  0.4137,  0.2767],\\\\n[-0.472 , -0.014 , -0.3625, -0.0062],\\\\n[-0.9231,  0.8957,  0.8052, -1.2064],\\\\n[ 2.5656,  1.4313,  1.3403, -1.1703]])\\\\nDataFrame\\\\nis not intended to be a drop-in replacement for ndarray as its\\nindexing semantics and data model are quite different in places from an n-dimensional\\narray.\\\\nSeries\\\\nimplements\\\\n__array_ufunc__\\\\n, which allows it to work with NumPy’s\\\\nuniversal functions\\\\n.\\\\nThe ufunc is applied to the underlying array in a\\\\nSeries\\\\n.\\\\nIn [110]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n])\\\\nIn [111]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\nser\\\\n)\\\\nOut[111]:\\\\n0     2.718282\\\\n1     7.389056\\\\n2    20.085537\\\\n3    54.598150\\\\ndtype: float64\\\\nWhen multiple\\\\nSeries\\\\nare passed to a ufunc, they are aligned before\\nperforming the operation.\\\\nLike other parts of the library, pandas will automatically align labeled inputs\\nas part of a ufunc with multiple inputs. For example, using\\\\nnumpy.remainder()\\\\non two\\\\nSeries\\\\nwith differently ordered labels will align before the operation.\\\\nIn [112]:\\\\nser1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n])\\\\nIn [113]:\\\\nser2\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n3\\\\n,\\\\n5\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n])\\\\nIn [114]:\\\\nser1\\\\nOut[114]:\\\\na    1\\\\nb    2\\\\nc    3\\\\ndtype: int64\\\\nIn [115]:\\\\nser2\\\\nOut[115]:\\\\nb    1\\\\na    3\\\\nc    5\\\\ndtype: int64\\\\nIn [116]:\\\\nnp\\\\n.\\\\nremainder\\\\n(\\\\nser1\\\\n,\\\\nser2\\\\n)\\\\nOut[116]:\\\\na    1\\\\nb    0\\\\nc    3\\\\ndtype: int64\\\\nAs usual, the union of the two indices is taken, and non-overlapping values are filled\\nwith missing values.\\\\nIn [117]:\\\\nser3\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n2\\\\n,\\\\n4\\\\n,\\\\n6\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n])\\\\nIn [118]:\\\\nser3\\\\nOut[118]:\\\\nb    2\\\\nc    4\\\\nd    6\\\\ndtype: int64\\\\nIn [119]:\\\\nnp\\\\n.\\\\nremainder\\\\n(\\\\nser1\\\\n,\\\\nser3\\\\n)\\\\nOut[119]:\\\\na    NaN\\\\nb    0.0\\\\nc    3.0\\\\nd    NaN\\\\ndtype: float64\\\\nWhen a binary ufunc is applied to a\\\\nSeries\\\\nand\\\\nIndex\\\\n, the\\\\nSeries\\\\nimplementation takes precedence and a\\\\nSeries\\\\nis returned.\\\\nIn [120]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n])\\\\nIn [121]:\\\\nidx\\\\n=\\\\npd\\\\n.\\\\nIndex\\\\n([\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n])\\\\nIn [122]:\\\\nnp\\\\n.\\\\nmaximum\\\\n(\\\\nser\\\\n,\\\\nidx\\\\n)\\\\nOut[122]:\\\\n0    4\\\\n1    5\\\\n2    6\\\\ndtype: int64\\\\nNumPy ufuncs are safe to apply to\\\\nSeries\\\\nbacked by non-ndarray arrays,\\nfor example\\\\narrays.SparseArray\\\\n(see\\\\nSparse calculation\\\\n). If possible,\\nthe ufunc is applied without converting the underlying data to an ndarray.\\\\nConsole display\\\\n#\\\\nA very large\\\\nDataFrame\\\\nwill be truncated to display them in the console.\\nYou can also get a summary using\\\\ninfo()\\\\n.\\n(The\\\\nbaseball\\\\ndataset is from the\\\\nplyr\\\\nR package):\\\\nIn [123]:\\\\nbaseball\\\\n=\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"data/baseball.csv\"\\\\n)\\\\nIn [124]:\\\\nprint\\\\n(\\\\nbaseball\\\\n)\\\\nid     player  year  stint team  lg  ...    so  ibb  hbp   sh   sf  gidp\\\\n0   88641  womacto01  2006      2  CHN  NL  ...   4.0  0.0  0.0  3.0  0.0   0.0\\\\n1   88643  schilcu01  2006      1  BOS  AL  ...   1.0  0.0  0.0  0.0  0.0   0.0\\\\n..    ...        ...   ...    ...  ...  ..  ...   ...  ...  ...  ...  ...   ...\\\\n98  89533   aloumo01  2007      1  NYN  NL  ...  30.0  5.0  2.0  0.0  3.0  13.0\\\\n99  89534  alomasa02  2007      1  NYN  NL  ...   3.0  0.0  0.0  0.0  0.0   0.0\\\\n[100 rows x 23 columns]\\\\nIn [125]:\\\\nbaseball\\\\n.\\\\ninfo\\\\n()\\\\n<class \\'pandas.core.frame.DataFrame\\'>\\\\nRangeIndex: 100 entries, 0 to 99\\\\nData columns (total 23 columns):\\\\n#   Column  Non-Null Count  Dtype\\\\n---  ------  --------------  -----\\\\n0   id      100 non-null    int64\\\\n1   player  100 non-null    object\\\\n2   year    100 non-null    int64\\\\n3   stint   100 non-null    int64\\\\n4   team    100 non-null    object\\\\n5   lg      100 non-null    object\\\\n6   g       100 non-null    int64\\\\n7   ab      100 non-null    int64\\\\n8   r       100 non-null    int64\\\\n9   h       100 non-null    int64\\\\n10  X2b     100 non-null    int64\\\\n11  X3b     100 non-null    int64\\\\n12  hr      100 non-null    int64\\\\n13  rbi     100 non-null    float64\\\\n14  sb      100 non-null    float64\\\\n15  cs      100 non-null    float64\\\\n16  bb      100 non-null    int64\\\\n17  so      100 non-null    float64\\\\n18  ibb     100 non-null    float64\\\\n19  hbp     100 non-null    float64\\\\n20  sh      100 non-null    float64\\\\n21  sf      100 non-null    float64\\\\n22  gidp    100 non-null    float64\\\\ndtypes: float64(9), int64(11), object(3)\\\\nmemory usage: 18.1+ KB\\\\nHowever, using\\\\nDataFrame.to_string()\\\\nwill return a string representation of the\\\\nDataFrame\\\\nin tabular form, though it won’t always fit the console width:\\\\nIn [126]:\\\\nprint\\\\n(\\\\nbaseball\\\\n.\\\\niloc\\\\n[\\\\n-\\\\n20\\\\n:,\\\\n:\\\\n12\\\\n]\\\\n.\\\\nto_string\\\\n())\\\\nid     player  year  stint team  lg    g   ab   r    h  X2b  X3b\\\\n80  89474  finlest01  2007      1  COL  NL   43   94   9   17    3    0\\\\n81  89480  embreal01  2007      1  OAK  AL    4    0   0    0    0    0\\\\n82  89481  edmonji01  2007      1  SLN  NL  117  365  39   92   15    2\\\\n83  89482  easleda01  2007      1  NYN  NL   76  193  24   54    6    0\\\\n84  89489  delgaca01  2007      1  NYN  NL  139  538  71  139   30    0\\\\n85  89493  cormirh01  2007      1  CIN  NL    6    0   0    0    0    0\\\\n86  89494  coninje01  2007      2  NYN  NL   21   41   2    8    2    0\\\\n87  89495  coninje01  2007      1  CIN  NL   80  215  23   57   11    1\\\\n88  89497  clemero02  2007      1  NYA  AL    2    2   0    1    0    0\\\\n89  89498  claytro01  2007      2  BOS  AL    8    6   1    0    0    0\\\\n90  89499  claytro01  2007      1  TOR  AL   69  189  23   48   14    0\\\\n91  89501  cirilje01  2007      2  ARI  NL   28   40   6    8    4    0\\\\n92  89502  cirilje01  2007      1  MIN  AL   50  153  18   40    9    2\\\\n93  89521  bondsba01  2007      1  SFN  NL  126  340  75   94   14    0\\\\n94  89523  biggicr01  2007      1  HOU  NL  141  517  68  130   31    3\\\\n95  89525  benitar01  2007      2  FLO  NL   34    0   0    0    0    0\\\\n96  89526  benitar01  2007      1  SFN  NL   19    0   0    0    0    0\\\\n97  89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3\\\\n98  89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1\\\\n99  89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0\\\\nWide DataFrames will be printed across multiple rows by\\ndefault:\\\\nIn [127]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n,\\\\n12\\\\n))\\\\nOut[127]:\\\\n0         1         2   ...        9         10        11\\\\n0 -1.226825  0.769804 -1.281247  ... -1.110336 -0.619976  0.149748\\\\n1 -0.732339  0.687738  0.176444  ...  1.462696 -1.743161 -0.826591\\\\n2 -0.345352  1.314232  0.690579  ...  0.896171 -0.487602 -0.082240\\\\n[3 rows x 12 columns]\\\\nYou can change how much to print on a single row by setting the\\\\ndisplay.width\\\\noption:\\\\nIn [128]:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"display.width\"\\\\n,\\\\n40\\\\n)\\\\n# default is 80\\\\nIn [129]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n,\\\\n12\\\\n))\\\\nOut[129]:\\\\n0         1         2   ...        9         10        11\\\\n0 -2.182937  0.380396  0.084844  ... -0.023688  2.410179  1.450520\\\\n1  0.206053 -0.251905 -2.213588  ... -0.025747 -0.988387  0.094055\\\\n2  1.262731  1.289997  0.082423  ... -0.281461  0.030711  0.109121\\\\n[3 rows x 12 columns]\\\\nYou can adjust the max width of the individual columns by setting\\\\ndisplay.max_colwidth\\\\nIn [130]:\\\\ndatafile\\\\n=\\\\n{\\\\n.....:\\\\n\"filename\"\\\\n:\\\\n[\\\\n\"filename_01\"\\\\n,\\\\n\"filename_02\"\\\\n],\\\\n.....:\\\\n\"path\"\\\\n:\\\\n[\\\\n.....:\\\\n\"media/user_name/storage/folder_01/filename_01\"\\\\n,\\\\n.....:\\\\n\"media/user_name/storage/folder_02/filename_02\"\\\\n,\\\\n.....:\\\\n],\\\\n.....:\\\\n}\\\\n.....:\\\\nIn [131]:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"display.max_colwidth\"\\\\n,\\\\n30\\\\n)\\\\nIn [132]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndatafile\\\\n)\\\\nOut[132]:\\\\nfilename                           path\\\\n0  filename_01  media/user_name/storage/fo...\\\\n1  filename_02  media/user_name/storage/fo...\\\\nIn [133]:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"display.max_colwidth\"\\\\n,\\\\n100\\\\n)\\\\nIn [134]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndatafile\\\\n)\\\\nOut[134]:\\\\nfilename                                           path\\\\n0  filename_01  media/user_name/storage/folder_01/filename_01\\\\n1  filename_02  media/user_name/storage/folder_02/filename_02\\\\nYou can also disable this feature via the\\\\nexpand_frame_repr\\\\noption.\\nThis will print the table in one block.\\\\nDataFrame column attribute access and IPython completion\\\\n#\\\\nIf a\\\\nDataFrame\\\\ncolumn label is a valid Python variable name, the column can be\\naccessed like an attribute:\\\\nIn [135]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"foo1\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\n\"foo2\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n)})\\\\nIn [136]:\\\\ndf\\\\nOut[136]:\\\\nfoo1      foo2\\\\n0  1.126203  0.781836\\\\n1 -0.977349 -1.071357\\\\n2  1.474071  0.441153\\\\n3 -0.064034  2.353925\\\\n4 -1.282782  0.583787\\\\nIn [137]:\\\\ndf\\\\n.\\\\nfoo1\\\\nOut[137]:\\\\n0    1.126203\\\\n1   -0.977349\\\\n2    1.474071\\\\n3   -0.064034\\\\n4   -1.282782\\\\nName: foo1, dtype: float64\\\\nThe columns are also connected to the\\\\nIPython\\\\ncompletion mechanism so they can be tab-completed:\\\\nIn [5]:\\\\ndf\\\\n.\\\\nfoo\\\\n<\\\\nTAB\\\\n>\\\\n# noqa: E225, E999\\\\ndf.foo1  df.foo2\\\\nprevious\\\\n10 minutes to pandas\\\\nnext\\\\nEssential basic functionality\\\\nOn this page\\\\nSeries\\\\nSeries is ndarray-like\\\\nSeries is dict-like\\\\nVectorized operations and label alignment with Series\\\\nName attribute\\\\nDataFrame\\\\nFrom dict of Series or dicts\\\\nFrom dict of ndarrays / lists\\\\nFrom structured or record array\\\\nFrom a list of dicts\\\\nFrom a dict of tuples\\\\nFrom a Series\\\\nFrom a list of namedtuples\\\\nFrom a list of dataclasses\\\\nAlternate constructors\\\\nColumn selection, addition, deletion\\\\nAssigning new columns in method chains\\\\nIndexing / selection\\\\nData alignment and arithmetic\\\\nTransposing\\\\nDataFrame interoperability with NumPy functions\\\\nConsole display\\\\nDataFrame column attribute access and IPython completion\\\\nShow Source\\\\n\\\\n--- Page Break ---\\\\n\\\\nUser Guide\\\\nEssential...\\\\nEssential basic functionality\\\\n#\\\\nHere we discuss a lot of the essential functionality common to the pandas data\\nstructures. To begin, let’s create some example objects like we did in\\nthe\\\\n10 minutes to pandas\\\\nsection:\\\\nIn [1]:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n8\\\\n)\\\\nIn [2]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [3]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n,\\\\n3\\\\n),\\\\nindex\\\\n=\\\\nindex\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n])\\\\nHead and tail\\\\n#\\\\nTo view a small sample of a Series or DataFrame object, use the\\\\nhead()\\\\nand\\\\ntail()\\\\nmethods. The default number\\nof elements to display is five, but you may pass a custom number.\\\\nIn [4]:\\\\nlong_series\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n))\\\\nIn [5]:\\\\nlong_series\\\\n.\\\\nhead\\\\n()\\\\nOut[5]:\\\\n0   -1.157892\\\\n1   -1.344312\\\\n2    0.844885\\\\n3    1.075770\\\\n4   -0.109050\\\\ndtype: float64\\\\nIn [6]:\\\\nlong_series\\\\n.\\\\ntail\\\\n(\\\\n3\\\\n)\\\\nOut[6]:\\\\n997   -0.289388\\\\n998   -1.020544\\\\n999    0.589993\\\\ndtype: float64\\\\nAttributes and underlying data\\\\n#\\\\npandas objects have a number of attributes enabling you to access the metadata\\\\nshape\\\\n: gives the axis dimensions of the object, consistent with ndarray\\\\nAxis labels\\\\nSeries\\\\n:\\\\nindex\\\\n(only axis)\\\\nDataFrame\\\\n:\\\\nindex\\\\n(rows) and\\\\ncolumns\\\\nNote,\\\\nthese attributes can be safely assigned to\\\\n!\\\\nIn [7]:\\\\ndf\\\\n[:\\\\n2\\\\n]\\\\nOut[7]:\\\\nA         B         C\\\\n2000-01-01 -0.173215  0.119209 -1.044236\\\\n2000-01-02 -0.861849 -2.104569 -0.494929\\\\nIn [8]:\\\\ndf\\\\n.\\\\ncolumns\\\\n=\\\\n[\\\\nx\\\\n.\\\\nlower\\\\n()\\\\nfor\\\\nx\\\\nin\\\\ndf\\\\n.\\\\ncolumns\\\\n]\\\\nIn [9]:\\\\ndf\\\\nOut[9]:\\\\na         b         c\\\\n2000-01-01 -0.173215  0.119209 -1.044236\\\\n2000-01-02 -0.861849 -2.104569 -0.494929\\\\n2000-01-03  1.071804  0.721555 -0.706771\\\\n2000-01-04 -1.039575  0.271860 -0.424972\\\\n2000-01-05  0.567020  0.276232 -1.087401\\\\n2000-01-06 -0.673690  0.113648 -1.478427\\\\n2000-01-07  0.524988  0.404705  0.577046\\\\n2000-01-08 -1.715002 -1.039268 -0.370647\\\\npandas objects (\\\\nIndex\\\\n,\\\\nSeries\\\\n,\\\\nDataFrame\\\\n) can be\\nthought of as containers for arrays, which hold the actual data and do the\\nactual computation. For many types, the underlying array is a\\\\nnumpy.ndarray\\\\n. However, pandas and 3rd party libraries may\\\\nextend\\\\nNumPy’s type system to add support for custom arrays\\n(see\\\\ndtypes\\\\n).\\\\nTo get the actual data inside a\\\\nIndex\\\\nor\\\\nSeries\\\\n, use\\nthe\\\\n.array\\\\nproperty\\\\nIn [10]:\\\\ns\\\\n.\\\\narray\\\\nOut[10]:\\\\n<NumpyExtensionArray>\\\\n[ 0.4691122999071863, -0.2828633443286633, -1.5090585031735124,\\\\n-1.1356323710171934,  1.2121120250208506]\\\\nLength: 5, dtype: float64\\\\nIn [11]:\\\\ns\\\\n.\\\\nindex\\\\n.\\\\narray\\\\nOut[11]:\\\\n<NumpyExtensionArray>\\\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\']\\\\nLength: 5, dtype: object\\\\narray\\\\nwill always be an\\\\nExtensionArray\\\\n.\\nThe exact details of what an\\\\nExtensionArray\\\\nis and why pandas uses them are a bit\\nbeyond the scope of this introduction. See\\\\ndtypes\\\\nfor more.\\\\nIf you know you need a NumPy array, use\\\\nto_numpy()\\\\nor\\\\nnumpy.asarray()\\\\n.\\\\nIn [12]:\\\\ns\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[12]:\\\\narray([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])\\\\nIn [13]:\\\\nnp\\\\n.\\\\nasarray\\\\n(\\\\ns\\\\n)\\\\nOut[13]:\\\\narray([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])\\\\nWhen the Series or Index is backed by\\nan\\\\nExtensionArray\\\\n,\\\\nto_numpy()\\\\nmay involve copying data and coercing values. See\\\\ndtypes\\\\nfor more.\\\\nto_numpy()\\\\ngives some control over the\\\\ndtype\\\\nof the\\nresulting\\\\nnumpy.ndarray\\\\n. For example, consider datetimes with timezones.\\nNumPy doesn’t have a dtype to represent timezone-aware datetimes, so there\\nare two possibly useful representations:\\\\nAn object-dtype\\\\nnumpy.ndarray\\\\nwith\\\\nTimestamp\\\\nobjects, each\\nwith the correct\\\\ntz\\\\nA\\\\ndatetime64[ns]\\\\n-dtype\\\\nnumpy.ndarray\\\\n, where the values have\\nbeen converted to UTC and the timezone discarded\\\\nTimezones may be preserved with\\\\ndtype=object\\\\nIn [14]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"2000\"\\\\n,\\\\nperiods\\\\n=\\\\n2\\\\n,\\\\ntz\\\\n=\\\\n\"CET\"\\\\n))\\\\nIn [15]:\\\\nser\\\\n.\\\\nto_numpy\\\\n(\\\\ndtype\\\\n=\\\\nobject\\\\n)\\\\nOut[15]:\\\\narray([Timestamp(\\'2000-01-01 00:00:00+0100\\', tz=\\'CET\\'),\\\\nTimestamp(\\'2000-01-02 00:00:00+0100\\', tz=\\'CET\\')], dtype=object)\\\\nOr thrown away with\\\\ndtype=\\'datetime64[ns]\\'\\\\nIn [16]:\\\\nser\\\\n.\\\\nto_numpy\\\\n(\\\\ndtype\\\\n=\\\\n\"datetime64[ns]\"\\\\n)\\\\nOut[16]:\\\\narray([\\'1999-12-31T23:00:00.000000000\\', \\'2000-01-01T23:00:00.000000000\\'],\\\\ndtype=\\'datetime64[ns]\\')\\\\nGetting the “raw data” inside a\\\\nDataFrame\\\\nis possibly a bit more\\ncomplex. When your\\\\nDataFrame\\\\nonly has a single data type for all the\\ncolumns,\\\\nDataFrame.to_numpy()\\\\nwill return the underlying data:\\\\nIn [17]:\\\\ndf\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[17]:\\\\narray([[-0.1732,  0.1192, -1.0442],\\\\n[-0.8618, -2.1046, -0.4949],\\\\n[ 1.0718,  0.7216, -0.7068],\\\\n[-1.0396,  0.2719, -0.425 ],\\\\n[ 0.567 ,  0.2762, -1.0874],\\\\n[-0.6737,  0.1136, -1.4784],\\\\n[ 0.525 ,  0.4047,  0.577 ],\\\\n[-1.715 , -1.0393, -0.3706]])\\\\nIf a DataFrame contains homogeneously-typed data, the ndarray can\\nactually be modified in-place, and the changes will be reflected in the data\\nstructure. For heterogeneous data (e.g. some of the DataFrame’s columns are not\\nall the same dtype), this will not be the case. The values attribute itself,\\nunlike the axis labels, cannot be assigned to.\\\\nNote\\\\nWhen working with heterogeneous data, the dtype of the resulting ndarray\\nwill be chosen to accommodate all of the data involved. For example, if\\nstrings are involved, the result will be of object dtype. If there are only\\nfloats and integers, the resulting array will be of float dtype.\\\\nIn the past, pandas recommended\\\\nSeries.values\\\\nor\\\\nDataFrame.values\\\\nfor extracting the data from a Series or DataFrame. You’ll still find references\\nto these in old code bases and online. Going forward, we recommend avoiding\\\\n.values\\\\nand using\\\\n.array\\\\nor\\\\n.to_numpy()\\\\n.\\\\n.values\\\\nhas the following\\ndrawbacks:\\\\nWhen your Series contains an\\\\nextension type\\\\n, it’s\\nunclear whether\\\\nSeries.values\\\\nreturns a NumPy array or the extension array.\\\\nSeries.array\\\\nwill always return an\\\\nExtensionArray\\\\n, and will never\\ncopy data.\\\\nSeries.to_numpy()\\\\nwill always return a NumPy array,\\npotentially at the cost of copying / coercing values.\\\\nWhen your DataFrame contains a mixture of data types,\\\\nDataFrame.values\\\\nmay\\ninvolve copying data and coercing values to a common dtype, a relatively expensive\\noperation.\\\\nDataFrame.to_numpy()\\\\n, being a method, makes it clearer that the\\nreturned NumPy array may not be a view on the same data in the DataFrame.\\\\nAccelerated operations\\\\n#\\\\npandas has support for accelerating certain types of binary numerical and boolean operations using\\nthe\\\\nnumexpr\\\\nlibrary and the\\\\nbottleneck\\\\nlibraries.\\\\nThese libraries are especially useful when dealing with large data sets, and provide large\\nspeedups.\\\\nnumexpr\\\\nuses smart chunking, caching, and multiple cores.\\\\nbottleneck\\\\nis\\na set of specialized cython routines that are especially fast when dealing with arrays that have\\\\nnans\\\\n.\\\\nHere is a sample (using 100 column x 100,000 row\\\\nDataFrames\\\\n):\\\\nOperation\\\\n0.11.0 (ms)\\\\nPrior Version (ms)\\\\nRatio to Prior\\\\ndf1\\\\n>\\\\ndf2\\\\n13.32\\\\n125.35\\\\n0.1063\\\\ndf1\\\\n*\\\\ndf2\\\\n21.71\\\\n36.63\\\\n0.5928\\\\ndf1\\\\n+\\\\ndf2\\\\n22.04\\\\n36.50\\\\n0.6039\\\\nYou are highly encouraged to install both libraries. See the section\\\\nRecommended Dependencies\\\\nfor more installation info.\\\\nThese are both enabled to be used by default, you can control this by setting the options:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"compute.use_bottleneck\"\\\\n,\\\\nFalse\\\\n)\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"compute.use_numexpr\"\\\\n,\\\\nFalse\\\\n)\\\\nFlexible binary operations\\\\n#\\\\nWith binary operations between pandas data structures, there are two key points\\nof interest:\\\\nBroadcasting behavior between higher- (e.g. DataFrame) and\\nlower-dimensional (e.g. Series) objects.\\\\nMissing data in computations.\\\\nWe will demonstrate how to manage these issues independently, though they can\\nbe handled simultaneously.\\\\nMatching / broadcasting behavior\\\\n#\\\\nDataFrame has the methods\\\\nadd()\\\\n,\\\\nsub()\\\\n,\\\\nmul()\\\\n,\\\\ndiv()\\\\nand related functions\\\\nradd()\\\\n,\\\\nrsub()\\\\n, …\\nfor carrying out binary operations. For broadcasting behavior,\\nSeries input is of primary interest. Using these functions, you can use to\\neither match on the\\\\nindex\\\\nor\\\\ncolumns\\\\nvia the\\\\naxis\\\\nkeyword:\\\\nIn [18]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n\"one\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]),\\\\n....:\\\\n\"two\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n4\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n....:\\\\n\"three\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nIn [19]:\\\\ndf\\\\nOut[19]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [20]:\\\\nrow\\\\n=\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n]\\\\nIn [21]:\\\\ncolumn\\\\n=\\\\ndf\\\\n[\\\\n\"two\"\\\\n]\\\\nIn [22]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\nrow\\\\n,\\\\naxis\\\\n=\\\\n\"columns\"\\\\n)\\\\nOut[22]:\\\\none       two     three\\\\na  1.051928 -0.139606       NaN\\\\nb  0.000000  0.000000  0.000000\\\\nc  0.352192 -0.433754  1.277825\\\\nd       NaN -1.632779 -0.562782\\\\nIn [23]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\nrow\\\\n,\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[23]:\\\\none       two     three\\\\na  1.051928 -0.139606       NaN\\\\nb  0.000000  0.000000  0.000000\\\\nc  0.352192 -0.433754  1.277825\\\\nd       NaN -1.632779 -0.562782\\\\nIn [24]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ncolumn\\\\n,\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[24]:\\\\none  two     three\\\\na -0.377535  0.0       NaN\\\\nb -1.569069  0.0 -1.962513\\\\nc -0.783123  0.0 -0.250933\\\\nd       NaN  0.0 -0.892516\\\\nIn [25]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ncolumn\\\\n,\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[25]:\\\\none  two     three\\\\na -0.377535  0.0       NaN\\\\nb -1.569069  0.0 -1.962513\\\\nc -0.783123  0.0 -0.250933\\\\nd       NaN  0.0 -0.892516\\\\nFurthermore you can align a level of a MultiIndexed DataFrame with a Series.\\\\nIn [26]:\\\\ndfmi\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [27]:\\\\ndfmi\\\\n.\\\\nindex\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_tuples\\\\n(\\\\n....:\\\\n[(\\\\n1\\\\n,\\\\n\"a\"\\\\n),\\\\n(\\\\n1\\\\n,\\\\n\"b\"\\\\n),\\\\n(\\\\n1\\\\n,\\\\n\"c\"\\\\n),\\\\n(\\\\n2\\\\n,\\\\n\"a\"\\\\n)],\\\\nnames\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n]\\\\n....:\\\\n)\\\\n....:\\\\nIn [28]:\\\\ndfmi\\\\n.\\\\nsub\\\\n(\\\\ncolumn\\\\n,\\\\naxis\\\\n=\\\\n0\\\\n,\\\\nlevel\\\\n=\\\\n\"second\"\\\\n)\\\\nOut[28]:\\\\none       two     three\\\\nfirst second\\\\n1     a      -0.377535  0.000000       NaN\\\\nb      -1.569069  0.000000 -1.962513\\\\nc      -0.783123  0.000000 -0.250933\\\\n2     a            NaN -1.493173 -2.385688\\\\nSeries and Index also support the\\\\ndivmod()\\\\nbuiltin. This function takes\\nthe floor division and modulo operation at the same time returning a two-tuple\\nof the same type as the left hand side. For example:\\\\nIn [29]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n10\\\\n))\\\\nIn [30]:\\\\ns\\\\nOut[30]:\\\\n0    0\\\\n1    1\\\\n2    2\\\\n3    3\\\\n4    4\\\\n5    5\\\\n6    6\\\\n7    7\\\\n8    8\\\\n9    9\\\\ndtype: int64\\\\nIn [31]:\\\\ndiv\\\\n,\\\\nrem\\\\n=\\\\ndivmod\\\\n(\\\\ns\\\\n,\\\\n3\\\\n)\\\\nIn [32]:\\\\ndiv\\\\nOut[32]:\\\\n0    0\\\\n1    0\\\\n2    0\\\\n3    1\\\\n4    1\\\\n5    1\\\\n6    2\\\\n7    2\\\\n8    2\\\\n9    3\\\\ndtype: int64\\\\nIn [33]:\\\\nrem\\\\nOut[33]:\\\\n0    0\\\\n1    1\\\\n2    2\\\\n3    0\\\\n4    1\\\\n5    2\\\\n6    0\\\\n7    1\\\\n8    2\\\\n9    0\\\\ndtype: int64\\\\nIn [34]:\\\\nidx\\\\n=\\\\npd\\\\n.\\\\nIndex\\\\n(\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n10\\\\n))\\\\nIn [35]:\\\\nidx\\\\nOut[35]:\\\\nIndex([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=\\'int64\\')\\\\nIn [36]:\\\\ndiv\\\\n,\\\\nrem\\\\n=\\\\ndivmod\\\\n(\\\\nidx\\\\n,\\\\n3\\\\n)\\\\nIn [37]:\\\\ndiv\\\\nOut[37]:\\\\nIndex([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype=\\'int64\\')\\\\nIn [38]:\\\\nrem\\\\nOut[38]:\\\\nIndex([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype=\\'int64\\')\\\\nWe can also do elementwise\\\\ndivmod()\\\\n:\\\\nIn [39]:\\\\ndiv\\\\n,\\\\nrem\\\\n=\\\\ndivmod\\\\n(\\\\ns\\\\n,\\\\n[\\\\n2\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n5\\\\n,\\\\n6\\\\n,\\\\n6\\\\n])\\\\nIn [40]:\\\\ndiv\\\\nOut[40]:\\\\n0    0\\\\n1    0\\\\n2    0\\\\n3    1\\\\n4    1\\\\n5    1\\\\n6    1\\\\n7    1\\\\n8    1\\\\n9    1\\\\ndtype: int64\\\\nIn [41]:\\\\nrem\\\\nOut[41]:\\\\n0    0\\\\n1    1\\\\n2    2\\\\n3    0\\\\n4    0\\\\n5    1\\\\n6    1\\\\n7    2\\\\n8    2\\\\n9    3\\\\ndtype: int64\\\\nMissing data / operations with fill values\\\\n#\\\\nIn Series and DataFrame, the arithmetic functions have the option of inputting\\na\\\\nfill_value\\\\n, namely a value to substitute when at most one of the values at\\na location are missing. For example, when adding two DataFrame objects, you may\\nwish to treat NaN as 0 unless both DataFrames are missing that value, in which\\ncase the result will be NaN (you can later replace NaN with some other value\\nusing\\\\nfillna\\\\nif you wish).\\\\nIn [42]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [43]:\\\\ndf2\\\\n.\\\\nloc\\\\n[\\\\n\"a\"\\\\n,\\\\n\"three\"\\\\n]\\\\n=\\\\n1.0\\\\nIn [44]:\\\\ndf\\\\nOut[44]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [45]:\\\\ndf2\\\\nOut[45]:\\\\none       two     three\\\\na  1.394981  1.772517  1.000000\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [46]:\\\\ndf\\\\n+\\\\ndf2\\\\nOut[46]:\\\\none       two     three\\\\na  2.789963  3.545034       NaN\\\\nb  0.686107  3.824246 -0.100780\\\\nc  1.390491  2.956737  2.454870\\\\nd       NaN  0.558688 -1.226343\\\\nIn [47]:\\\\ndf\\\\n.\\\\nadd\\\\n(\\\\ndf2\\\\n,\\\\nfill_value\\\\n=\\\\n0\\\\n)\\\\nOut[47]:\\\\none       two     three\\\\na  2.789963  3.545034  1.000000\\\\nb  0.686107  3.824246 -0.100780\\\\nc  1.390491  2.956737  2.454870\\\\nd       NaN  0.558688 -1.226343\\\\nFlexible comparisons\\\\n#\\\\nSeries and DataFrame have the binary comparison methods\\\\neq\\\\n,\\\\nne\\\\n,\\\\nlt\\\\n,\\\\ngt\\\\n,\\\\nle\\\\n, and\\\\nge\\\\nwhose behavior is analogous to the binary\\narithmetic operations described above:\\\\nIn [48]:\\\\ndf\\\\n.\\\\ngt\\\\n(\\\\ndf2\\\\n)\\\\nOut[48]:\\\\none    two  three\\\\na  False  False  False\\\\nb  False  False  False\\\\nc  False  False  False\\\\nd  False  False  False\\\\nIn [49]:\\\\ndf2\\\\n.\\\\nne\\\\n(\\\\ndf\\\\n)\\\\nOut[49]:\\\\none    two  three\\\\na  False  False   True\\\\nb  False  False  False\\\\nc  False  False  False\\\\nd   True  False  False\\\\nThese operations produce a pandas object of the same type as the left-hand-side\\ninput that is of dtype\\\\nbool\\\\n. These\\\\nboolean\\\\nobjects can be used in\\nindexing operations, see the section on\\\\nBoolean indexing\\\\n.\\\\nBoolean reductions\\\\n#\\\\nYou can apply the reductions:\\\\nempty\\\\n,\\\\nany()\\\\n,\\\\nall()\\\\n, and\\\\nbool()\\\\nto provide a\\nway to summarize a boolean result.\\\\nIn [50]:\\\\n(\\\\ndf\\\\n>\\\\n0\\\\n)\\\\n.\\\\nall\\\\n()\\\\nOut[50]:\\\\none      False\\\\ntwo       True\\\\nthree    False\\\\ndtype: bool\\\\nIn [51]:\\\\n(\\\\ndf\\\\n>\\\\n0\\\\n)\\\\n.\\\\nany\\\\n()\\\\nOut[51]:\\\\none      True\\\\ntwo      True\\\\nthree    True\\\\ndtype: bool\\\\nYou can reduce to a final boolean value.\\\\nIn [52]:\\\\n(\\\\ndf\\\\n>\\\\n0\\\\n)\\\\n.\\\\nany\\\\n()\\\\n.\\\\nany\\\\n()\\\\nOut[52]:\\\\nTrue\\\\nYou can test if a pandas object is empty, via the\\\\nempty\\\\nproperty.\\\\nIn [53]:\\\\ndf\\\\n.\\\\nempty\\\\nOut[53]:\\\\nFalse\\\\nIn [54]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ncolumns\\\\n=\\\\nlist\\\\n(\\\\n\"ABC\"\\\\n))\\\\n.\\\\nempty\\\\nOut[54]:\\\\nTrue\\\\nWarning\\\\nAsserting the truthiness of a pandas object will raise an error, as the testing of the emptiness\\nor values is ambiguous.\\\\nIn [55]:\\\\nif\\\\ndf\\\\n:\\\\n....:\\\\nprint\\\\n(\\\\nTrue\\\\n)\\\\n....:\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\n<ipython-input-55-318d08b2571a>\\\\nin\\\\n?\\\\n()\\\\n---->\\\\n1\\\\nif\\\\ndf\\\\n:\\\\n2\\\\nprint\\\\n(\\\\nTrue\\\\n)\\\\n~/work/pandas/pandas/pandas/core/generic.py\\\\nin\\\\n?\\\\n(self)\\\\n1575\\\\n@final\\\\n1576\\\\ndef\\\\n__nonzero__\\\\n(\\\\nself\\\\n)\\\\n->\\\\nNoReturn\\\\n:\\\\n->\\\\n1577\\\\nraise\\\\nValueError\\\\n(\\\\n1578\\\\nf\\\\n\"The truth value of a\\\\n{\\\\ntype\\\\n(\\\\nself\\\\n)\\\\n.\\\\n__name__\\\\n}\\\\nis ambiguous. \"\\\\n1579\\\\n\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\\\\n1580\\\\n)\\\\nValueError\\\\n: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\\nIn [56]:\\\\ndf\\\\nand\\\\ndf2\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\n<ipython-input-56-b241b64bb471>\\\\nin\\\\n?\\\\n()\\\\n---->\\\\n1\\\\ndf\\\\nand\\\\ndf2\\\\n~/work/pandas/pandas/pandas/core/generic.py\\\\nin\\\\n?\\\\n(self)\\\\n1575\\\\n@final\\\\n1576\\\\ndef\\\\n__nonzero__\\\\n(\\\\nself\\\\n)\\\\n->\\\\nNoReturn\\\\n:\\\\n->\\\\n1577\\\\nraise\\\\nValueError\\\\n(\\\\n1578\\\\nf\\\\n\"The truth value of a\\\\n{\\\\ntype\\\\n(\\\\nself\\\\n)\\\\n.\\\\n__name__\\\\n}\\\\nis ambiguous. \"\\\\n1579\\\\n\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\\\\n1580\\\\n)\\\\nValueError\\\\n: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\\nSee\\\\ngotchas\\\\nfor a more detailed discussion.\\\\nComparing if objects are equivalent\\\\n#\\\\nOften you may find that there is more than one way to compute the same\\nresult.  As a simple example, consider\\\\ndf\\\\n+\\\\ndf\\\\nand\\\\ndf\\\\n*\\\\n2\\\\n. To test\\nthat these two computations produce the same result, given the tools\\nshown above, you might imagine using\\\\n(df\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2).all()\\\\n. But in\\nfact, this expression is False:\\\\nIn [57]:\\\\ndf\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2\\\\nOut[57]:\\\\none   two  three\\\\na   True  True  False\\\\nb   True  True   True\\\\nc   True  True   True\\\\nd  False  True   True\\\\nIn [58]:\\\\n(\\\\ndf\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2\\\\n)\\\\n.\\\\nall\\\\n()\\\\nOut[58]:\\\\none      False\\\\ntwo       True\\\\nthree    False\\\\ndtype: bool\\\\nNotice that the boolean DataFrame\\\\ndf\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2\\\\ncontains some False values!\\nThis is because NaNs do not compare as equals:\\\\nIn [59]:\\\\nnp\\\\n.\\\\nnan\\\\n==\\\\nnp\\\\n.\\\\nnan\\\\nOut[59]:\\\\nFalse\\\\nSo, NDFrames (such as Series and DataFrames)\\nhave an\\\\nequals()\\\\nmethod for testing equality, with NaNs in\\ncorresponding locations treated as equal.\\\\nIn [60]:\\\\n(\\\\ndf\\\\n+\\\\ndf\\\\n)\\\\n.\\\\nequals\\\\n(\\\\ndf\\\\n*\\\\n2\\\\n)\\\\nOut[60]:\\\\nTrue\\\\nNote that the Series or DataFrame index needs to be in the same order for\\nequality to be True:\\\\nIn [61]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"col\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n]})\\\\nIn [62]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"col\"\\\\n:\\\\n[\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n0\\\\n,\\\\n\"foo\"\\\\n]},\\\\nindex\\\\n=\\\\n[\\\\n2\\\\n,\\\\n1\\\\n,\\\\n0\\\\n])\\\\nIn [63]:\\\\ndf1\\\\n.\\\\nequals\\\\n(\\\\ndf2\\\\n)\\\\nOut[63]:\\\\nFalse\\\\nIn [64]:\\\\ndf1\\\\n.\\\\nequals\\\\n(\\\\ndf2\\\\n.\\\\nsort_index\\\\n())\\\\nOut[64]:\\\\nTrue\\\\nComparing array-like objects\\\\n#\\\\nYou can conveniently perform element-wise comparisons when comparing a pandas\\ndata structure with a scalar value:\\\\nIn [65]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\n\"foo\"\\\\nOut[65]:\\\\n0     True\\\\n1    False\\\\n2    False\\\\ndtype: bool\\\\nIn [66]:\\\\npd\\\\n.\\\\nIndex\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\n\"foo\"\\\\nOut[66]:\\\\narray([ True, False, False])\\\\npandas also handles element-wise comparisons between different array-like\\nobjects of the same length:\\\\nIn [67]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\npd\\\\n.\\\\nIndex\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"qux\"\\\\n])\\\\nOut[67]:\\\\n0     True\\\\n1     True\\\\n2    False\\\\ndtype: bool\\\\nIn [68]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"qux\"\\\\n])\\\\nOut[68]:\\\\n0     True\\\\n1     True\\\\n2    False\\\\ndtype: bool\\\\nTrying to compare\\\\nIndex\\\\nor\\\\nSeries\\\\nobjects of different lengths will\\nraise a ValueError:\\\\nIn [69]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n])\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\nCell\\\\nIn\\\\n[\\\\n69\\\\n],\\\\nline\\\\n1\\\\n---->\\\\n1\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n])\\\\nFile ~/work/pandas/pandas/pandas/core/ops/common.py:76,\\\\nin\\\\n_unpack_zerodim_and_defer.<locals>.new_method\\\\n(self, other)\\\\n72\\\\nreturn\\\\nNotImplemented\\\\n74\\\\nother\\\\n=\\\\nitem_from_zerodim\\\\n(\\\\nother\\\\n)\\\\n--->\\\\n76\\\\nreturn\\\\nmethod\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/arraylike.py:40,\\\\nin\\\\nOpsMixin.__eq__\\\\n(self, other)\\\\n38\\\\n@unpack_zerodim_and_defer\\\\n(\\\\n\"__eq__\"\\\\n)\\\\n39\\\\ndef\\\\n__eq__\\\\n(\\\\nself\\\\n,\\\\nother\\\\n):\\\\n--->\\\\n40\\\\nreturn\\\\nself\\\\n.\\\\n_cmp_method\\\\n(\\\\nother\\\\n,\\\\noperator\\\\n.\\\\neq\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:6125,\\\\nin\\\\nSeries._cmp_method\\\\n(self, other, op)\\\\n6122\\\\nres_name\\\\n=\\\\nops\\\\n.\\\\nget_op_result_name\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\n6124\\\\nif\\\\nisinstance\\\\n(\\\\nother\\\\n,\\\\nSeries\\\\n)\\\\nand\\\\nnot\\\\nself\\\\n.\\\\n_indexed_same\\\\n(\\\\nother\\\\n):\\\\n->\\\\n6125\\\\nraise\\\\nValueError\\\\n(\\\\n\"Can only compare identically-labeled Series objects\"\\\\n)\\\\n6127\\\\nlvalues\\\\n=\\\\nself\\\\n.\\\\n_values\\\\n6128\\\\nrvalues\\\\n=\\\\nextract_array\\\\n(\\\\nother\\\\n,\\\\nextract_numpy\\\\n=\\\\nTrue\\\\n,\\\\nextract_range\\\\n=\\\\nTrue\\\\n)\\\\nValueError\\\\n: Can only compare identically-labeled Series objects\\\\nIn [70]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n])\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\nCell\\\\nIn\\\\n[\\\\n70\\\\n],\\\\nline\\\\n1\\\\n---->\\\\n1\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n])\\\\nFile ~/work/pandas/pandas/pandas/core/ops/common.py:76,\\\\nin\\\\n_unpack_zerodim_and_defer.<locals>.new_method\\\\n(self, other)\\\\n72\\\\nreturn\\\\nNotImplemented\\\\n74\\\\nother\\\\n=\\\\nitem_from_zerodim\\\\n(\\\\nother\\\\n)\\\\n--->\\\\n76\\\\nreturn\\\\nmethod\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/arraylike.py:40,\\\\nin\\\\nOpsMixin.__eq__\\\\n(self, other)\\\\n38\\\\n@unpack_zerodim_and_defer\\\\n(\\\\n\"__eq__\"\\\\n)\\\\n39\\\\ndef\\\\n__eq__\\\\n(\\\\nself\\\\n,\\\\nother\\\\n):\\\\n--->\\\\n40\\\\nreturn\\\\nself\\\\n.\\\\n_cmp_method\\\\n(\\\\nother\\\\n,\\\\noperator\\\\n.\\\\neq\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:6125,\\\\nin\\\\nSeries._cmp_method\\\\n(self, other, op)\\\\n6122\\\\nres_name\\\\n=\\\\nops\\\\n.\\\\nget_op_result_name\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\n6124\\\\nif\\\\nisinstance\\\\n(\\\\nother\\\\n,\\\\nSeries\\\\n)\\\\nand\\\\nnot\\\\nself\\\\n.\\\\n_indexed_same\\\\n(\\\\nother\\\\n):\\\\n->\\\\n6125\\\\nraise\\\\nValueError\\\\n(\\\\n\"Can only compare identically-labeled Series objects\"\\\\n)\\\\n6127\\\\nlvalues\\\\n=\\\\nself\\\\n.\\\\n_values\\\\n6128\\\\nrvalues\\\\n=\\\\nextract_array\\\\n(\\\\nother\\\\n,\\\\nextract_numpy\\\\n=\\\\nTrue\\\\n,\\\\nextract_range\\\\n=\\\\nTrue\\\\n)\\\\nValueError\\\\n: Can only compare identically-labeled Series objects\\\\nCombining overlapping data sets\\\\n#\\\\nA problem occasionally arising is the combination of two similar data sets\\nwhere values in one are preferred over the other. An example would be two data\\nseries representing a particular economic indicator where one is considered to\\nbe of “higher quality”. However, the lower quality series might extend further\\nback in history or have more complete data coverage. As such, we would like to\\ncombine two DataFrame objects where missing values in one DataFrame are\\nconditionally filled with like-labeled values from the other DataFrame. The\\nfunction implementing this operation is\\\\ncombine_first()\\\\n,\\nwhich we illustrate:\\\\nIn [71]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n\"A\"\\\\n:\\\\n[\\\\n1.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n5.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n],\\\\n\"B\"\\\\n:\\\\n[\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n6.0\\\\n]}\\\\n....:\\\\n)\\\\n....:\\\\nIn [72]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n\"A\"\\\\n:\\\\n[\\\\n5.0\\\\n,\\\\n2.0\\\\n,\\\\n4.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n7.0\\\\n],\\\\n....:\\\\n\"B\"\\\\n:\\\\n[\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n,\\\\n6.0\\\\n,\\\\n8.0\\\\n],\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nIn [73]:\\\\ndf1\\\\nOut[73]:\\\\nA    B\\\\n0  1.0  NaN\\\\n1  NaN  2.0\\\\n2  3.0  3.0\\\\n3  5.0  NaN\\\\n4  NaN  6.0\\\\nIn [74]:\\\\ndf2\\\\nOut[74]:\\\\nA    B\\\\n0  5.0  NaN\\\\n1  2.0  NaN\\\\n2  4.0  3.0\\\\n3  NaN  4.0\\\\n4  3.0  6.0\\\\n5  7.0  8.0\\\\nIn [75]:\\\\ndf1\\\\n.\\\\ncombine_first\\\\n(\\\\ndf2\\\\n)\\\\nOut[75]:\\\\nA    B\\\\n0  1.0  NaN\\\\n1  2.0  2.0\\\\n2  3.0  3.0\\\\n3  5.0  4.0\\\\n4  3.0  6.0\\\\n5  7.0  8.0\\\\nGeneral DataFrame combine\\\\n#\\\\nThe\\\\ncombine_first()\\\\nmethod above calls the more general\\\\nDataFrame.combine()\\\\n. This method takes another DataFrame\\nand a combiner function, aligns the input DataFrame and then passes the combiner\\nfunction pairs of Series (i.e., columns whose names are the same).\\\\nSo, for instance, to reproduce\\\\ncombine_first()\\\\nas above:\\\\nIn [76]:\\\\ndef\\\\ncombiner\\\\n(\\\\nx\\\\n,\\\\ny\\\\n):\\\\n....:\\\\nreturn\\\\nnp\\\\n.\\\\nwhere\\\\n(\\\\npd\\\\n.\\\\nisna\\\\n(\\\\nx\\\\n),\\\\ny\\\\n,\\\\nx\\\\n)\\\\n....:\\\\nIn [77]:\\\\ndf1\\\\n.\\\\ncombine\\\\n(\\\\ndf2\\\\n,\\\\ncombiner\\\\n)\\\\nOut[77]:\\\\nA    B\\\\n0  1.0  NaN\\\\n1  2.0  2.0\\\\n2  3.0  3.0\\\\n3  5.0  4.0\\\\n4  3.0  6.0\\\\n5  7.0  8.0\\\\nDescriptive statistics\\\\n#\\\\nThere exists a large number of methods for computing descriptive statistics and\\nother related operations on\\\\nSeries\\\\n,\\\\nDataFrame\\\\n. Most of these\\nare aggregations (hence producing a lower-dimensional result) like\\\\nsum()\\\\n,\\\\nmean()\\\\n, and\\\\nquantile()\\\\n,\\nbut some of them, like\\\\ncumsum()\\\\nand\\\\ncumprod()\\\\n,\\nproduce an object of the same size. Generally speaking, these methods take an\\\\naxis\\\\nargument, just like\\\\nndarray.{sum, std, …}\\\\n, but the axis can be\\nspecified by name or integer:\\\\nSeries\\\\n: no axis argument needed\\\\nDataFrame\\\\n: “index” (axis=0, default), “columns” (axis=1)\\\\nFor example:\\\\nIn [78]:\\\\ndf\\\\nOut[78]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [79]:\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\n0\\\\n)\\\\nOut[79]:\\\\none      0.811094\\\\ntwo      1.360588\\\\nthree    0.187958\\\\ndtype: float64\\\\nIn [80]:\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\n1\\\\n)\\\\nOut[80]:\\\\na    1.583749\\\\nb    0.734929\\\\nc    1.133683\\\\nd   -0.166914\\\\ndtype: float64\\\\nAll such methods have a\\\\nskipna\\\\noption signaling whether to exclude missing\\ndata (\\\\nTrue\\\\nby default):\\\\nIn [81]:\\\\ndf\\\\n.\\\\nsum\\\\n(\\\\n0\\\\n,\\\\nskipna\\\\n=\\\\nFalse\\\\n)\\\\nOut[81]:\\\\none           NaN\\\\ntwo      5.442353\\\\nthree         NaN\\\\ndtype: float64\\\\nIn [82]:\\\\ndf\\\\n.\\\\nsum\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n,\\\\nskipna\\\\n=\\\\nTrue\\\\n)\\\\nOut[82]:\\\\na    3.167498\\\\nb    2.204786\\\\nc    3.401050\\\\nd   -0.333828\\\\ndtype: float64\\\\nCombined with the broadcasting / arithmetic behavior, one can describe various\\nstatistical procedures, like standardization (rendering data zero mean and\\nstandard deviation of 1), very concisely:\\\\nIn [83]:\\\\nts_stand\\\\n=\\\\n(\\\\ndf\\\\n-\\\\ndf\\\\n.\\\\nmean\\\\n())\\\\n/\\\\ndf\\\\n.\\\\nstd\\\\n()\\\\nIn [84]:\\\\nts_stand\\\\n.\\\\nstd\\\\n()\\\\nOut[84]:\\\\none      1.0\\\\ntwo      1.0\\\\nthree    1.0\\\\ndtype: float64\\\\nIn [85]:\\\\nxs_stand\\\\n=\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\n1\\\\n),\\\\naxis\\\\n=\\\\n0\\\\n)\\\\n.\\\\ndiv\\\\n(\\\\ndf\\\\n.\\\\nstd\\\\n(\\\\n1\\\\n),\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nIn [86]:\\\\nxs_stand\\\\n.\\\\nstd\\\\n(\\\\n1\\\\n)\\\\nOut[86]:\\\\na    1.0\\\\nb    1.0\\\\nc    1.0\\\\nd    1.0\\\\ndtype: float64\\\\nNote that methods like\\\\ncumsum()\\\\nand\\\\ncumprod()\\\\npreserve the location of\\\\nNaN\\\\nvalues. This is somewhat different from\\\\nexpanding()\\\\nand\\\\nrolling()\\\\nsince\\\\nNaN\\\\nbehavior\\nis furthermore dictated by a\\\\nmin_periods\\\\nparameter.\\\\nIn [87]:\\\\ndf\\\\n.\\\\ncumsum\\\\n()\\\\nOut[87]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  1.738035  3.684640 -0.050390\\\\nc  2.433281  5.163008  1.177045\\\\nd       NaN  5.442353  0.563873\\\\nHere is a quick reference summary table of common functions. Each also takes an\\noptional\\\\nlevel\\\\nparameter which applies only if the object has a\\\\nhierarchical index\\\\n.\\\\nFunction\\\\nDescription\\\\ncount\\\\nNumber of non-NA observations\\\\nsum\\\\nSum of values\\\\nmean\\\\nMean of values\\\\nmedian\\\\nArithmetic median of values\\\\nmin\\\\nMinimum\\\\nmax\\\\nMaximum\\\\nmode\\\\nMode\\\\nabs\\\\nAbsolute Value\\\\nprod\\\\nProduct of values\\\\nstd\\\\nBessel-corrected sample standard deviation\\\\nvar\\\\nUnbiased variance\\\\nsem\\\\nStandard error of the mean\\\\nskew\\\\nSample skewness (3rd moment)\\\\nkurt\\\\nSample kurtosis (4th moment)\\\\nquantile\\\\nSample quantile (value at %)\\\\ncumsum\\\\nCumulative sum\\\\ncumprod\\\\nCumulative product\\\\ncummax\\\\nCumulative maximum\\\\ncummin\\\\nCumulative minimum\\\\nNote that by chance some NumPy methods, like\\\\nmean\\\\n,\\\\nstd\\\\n, and\\\\nsum\\\\n,\\nwill exclude NAs on Series input by default:\\\\nIn [88]:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\ndf\\\\n[\\\\n\"one\"\\\\n])\\\\nOut[88]:\\\\n0.8110935116651192\\\\nIn [89]:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\n.\\\\nto_numpy\\\\n())\\\\nOut[89]:\\\\nnan\\\\nSeries.nunique()\\\\nwill return the number of unique non-NA values in a\\nSeries:\\\\nIn [90]:\\\\nseries\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n500\\\\n))\\\\nIn [91]:\\\\nseries\\\\n[\\\\n20\\\\n:\\\\n500\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [92]:\\\\nseries\\\\n[\\\\n10\\\\n:\\\\n20\\\\n]\\\\n=\\\\n5\\\\nIn [93]:\\\\nseries\\\\n.\\\\nnunique\\\\n()\\\\nOut[93]:\\\\n11\\\\nSummarizing data: describe\\\\n#\\\\nThere is a convenient\\\\ndescribe()\\\\nfunction which computes a variety of summary\\nstatistics about a Series or the columns of a DataFrame (excluding NAs of\\ncourse):\\\\nIn [94]:\\\\nseries\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n))\\\\nIn [95]:\\\\nseries\\\\n[::\\\\n2\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [96]:\\\\nseries\\\\n.\\\\ndescribe\\\\n()\\\\nOut[96]:\\\\ncount    500.000000\\\\nmean      -0.021292\\\\nstd        1.015906\\\\nmin       -2.683763\\\\n25%       -0.699070\\\\n50%       -0.069718\\\\n75%        0.714483\\\\nmax        3.160915\\\\ndtype: float64\\\\nIn [97]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n,\\\\n5\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [98]:\\\\nframe\\\\n.\\\\niloc\\\\n[::\\\\n2\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [99]:\\\\nframe\\\\n.\\\\ndescribe\\\\n()\\\\nOut[99]:\\\\na           b           c           d           e\\\\ncount  500.000000  500.000000  500.000000  500.000000  500.000000\\\\nmean     0.033387    0.030045   -0.043719   -0.051686    0.005979\\\\nstd      1.017152    0.978743    1.025270    1.015988    1.006695\\\\nmin     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821\\\\n25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115\\\\n50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363\\\\n75%      0.729907    0.775880    0.618896    0.670047    0.649748\\\\nmax      2.740139    2.752332    3.004229    2.728702    3.240991\\\\nYou can select specific percentiles to include in the output:\\\\nIn [100]:\\\\nseries\\\\n.\\\\ndescribe\\\\n(\\\\npercentiles\\\\n=\\\\n[\\\\n0.05\\\\n,\\\\n0.25\\\\n,\\\\n0.75\\\\n,\\\\n0.95\\\\n])\\\\nOut[100]:\\\\ncount    500.000000\\\\nmean      -0.021292\\\\nstd        1.015906\\\\nmin       -2.683763\\\\n5%        -1.645423\\\\n25%       -0.699070\\\\n50%       -0.069718\\\\n75%        0.714483\\\\n95%        1.711409\\\\nmax        3.160915\\\\ndtype: float64\\\\nBy default, the median is always included.\\\\nFor a non-numerical Series object,\\\\ndescribe()\\\\nwill give a simple\\nsummary of the number of unique values and most frequently occurring values:\\\\nIn [101]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"a\"\\\\n])\\\\nIn [102]:\\\\ns\\\\n.\\\\ndescribe\\\\n()\\\\nOut[102]:\\\\ncount     9\\\\nunique    4\\\\ntop       a\\\\nfreq      5\\\\ndtype: object\\\\nNote that on a mixed-type DataFrame object,\\\\ndescribe()\\\\nwill\\nrestrict the summary to include only numerical columns or, if none are, only\\ncategorical columns:\\\\nIn [103]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n\"Yes\"\\\\n,\\\\n\"Yes\"\\\\n,\\\\n\"No\"\\\\n,\\\\n\"No\"\\\\n],\\\\n\"b\"\\\\n:\\\\nrange\\\\n(\\\\n4\\\\n)})\\\\nIn [104]:\\\\nframe\\\\n.\\\\ndescribe\\\\n()\\\\nOut[104]:\\\\nb\\\\ncount  4.000000\\\\nmean   1.500000\\\\nstd    1.290994\\\\nmin    0.000000\\\\n25%    0.750000\\\\n50%    1.500000\\\\n75%    2.250000\\\\nmax    3.000000\\\\nThis behavior can be controlled by providing a list of types as\\\\ninclude\\\\n/\\\\nexclude\\\\narguments. The special value\\\\nall\\\\ncan also be used:\\\\nIn [105]:\\\\nframe\\\\n.\\\\ndescribe\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"object\"\\\\n])\\\\nOut[105]:\\\\na\\\\ncount     4\\\\nunique    2\\\\ntop     Yes\\\\nfreq      2\\\\nIn [106]:\\\\nframe\\\\n.\\\\ndescribe\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"number\"\\\\n])\\\\nOut[106]:\\\\nb\\\\ncount  4.000000\\\\nmean   1.500000\\\\nstd    1.290994\\\\nmin    0.000000\\\\n25%    0.750000\\\\n50%    1.500000\\\\n75%    2.250000\\\\nmax    3.000000\\\\nIn [107]:\\\\nframe\\\\n.\\\\ndescribe\\\\n(\\\\ninclude\\\\n=\\\\n\"all\"\\\\n)\\\\nOut[107]:\\\\na         b\\\\ncount     4  4.000000\\\\nunique    2       NaN\\\\ntop     Yes       NaN\\\\nfreq      2       NaN\\\\nmean    NaN  1.500000\\\\nstd     NaN  1.290994\\\\nmin     NaN  0.000000\\\\n25%     NaN  0.750000\\\\n50%     NaN  1.500000\\\\n75%     NaN  2.250000\\\\nmax     NaN  3.000000\\\\nThat feature relies on\\\\nselect_dtypes\\\\n. Refer to\\nthere for details about accepted inputs.\\\\nIndex of min/max values\\\\n#\\\\nThe\\\\nidxmin()\\\\nand\\\\nidxmax()\\\\nfunctions on Series\\nand DataFrame compute the index labels with the minimum and maximum\\ncorresponding values:\\\\nIn [108]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n))\\\\nIn [109]:\\\\ns1\\\\nOut[109]:\\\\n0    1.118076\\\\n1   -0.352051\\\\n2   -1.242883\\\\n3   -1.277155\\\\n4   -0.641184\\\\ndtype: float64\\\\nIn [110]:\\\\ns1\\\\n.\\\\nidxmin\\\\n(),\\\\ns1\\\\n.\\\\nidxmax\\\\n()\\\\nOut[110]:\\\\n(3, 0)\\\\nIn [111]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n,\\\\n3\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n])\\\\nIn [112]:\\\\ndf1\\\\nOut[112]:\\\\nA         B         C\\\\n0 -0.327863 -0.946180 -0.137570\\\\n1 -0.186235 -0.257213 -0.486567\\\\n2 -0.507027 -0.871259 -0.111110\\\\n3  2.000339 -2.430505  0.089759\\\\n4 -0.321434 -0.033695  0.096271\\\\nIn [113]:\\\\ndf1\\\\n.\\\\nidxmin\\\\n(\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[113]:\\\\nA    2\\\\nB    3\\\\nC    1\\\\ndtype: int64\\\\nIn [114]:\\\\ndf1\\\\n.\\\\nidxmax\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[114]:\\\\n0    C\\\\n1    A\\\\n2    C\\\\n3    A\\\\n4    C\\\\ndtype: object\\\\nWhen there are multiple rows (or columns) matching the minimum or maximum\\nvalue,\\\\nidxmin()\\\\nand\\\\nidxmax()\\\\nreturn the first\\nmatching index:\\\\nIn [115]:\\\\ndf3\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\n2\\\\n,\\\\n1\\\\n,\\\\n1\\\\n,\\\\n3\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n],\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\n\"edcba\"\\\\n))\\\\nIn [116]:\\\\ndf3\\\\nOut[116]:\\\\nA\\\\ne  2.0\\\\nd  1.0\\\\nc  1.0\\\\nb  3.0\\\\na  NaN\\\\nIn [117]:\\\\ndf3\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nidxmin\\\\n()\\\\nOut[117]:\\\\n\\'d\\'\\\\nNote\\\\nidxmin\\\\nand\\\\nidxmax\\\\nare called\\\\nargmin\\\\nand\\\\nargmax\\\\nin NumPy.\\\\nValue counts (histogramming) / mode\\\\n#\\\\nThe\\\\nvalue_counts()\\\\nSeries method computes a histogram\\nof a 1D array of values. It can also be used as a function on regular arrays:\\\\nIn [118]:\\\\ndata\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n7\\\\n,\\\\nsize\\\\n=\\\\n50\\\\n)\\\\nIn [119]:\\\\ndata\\\\nOut[119]:\\\\narray([6, 6, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 4, 5, 0, 2, 0, 4, 2, 0, 3, 2,\\\\n2, 5, 6, 5, 3, 4, 6, 4, 3, 5, 6, 4, 3, 6, 2, 6, 6, 2, 3, 4, 2, 1,\\\\n6, 2, 6, 1, 5, 4])\\\\nIn [120]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\ndata\\\\n)\\\\nIn [121]:\\\\ns\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[121]:\\\\n6    10\\\\n2    10\\\\n4     9\\\\n3     8\\\\n5     8\\\\n0     3\\\\n1     2\\\\nName: count, dtype: int64\\\\nThe\\\\nvalue_counts()\\\\nmethod can be used to count combinations across multiple columns.\\nBy default all columns are used but a subset can be selected using the\\\\nsubset\\\\nargument.\\\\nIn [122]:\\\\ndata\\\\n=\\\\n{\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n\"x\"\\\\n,\\\\n\"x\"\\\\n,\\\\n\"y\"\\\\n,\\\\n\"y\"\\\\n]}\\\\nIn [123]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n)\\\\nIn [124]:\\\\nframe\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[124]:\\\\na  b\\\\n1  x    1\\\\n2  x    1\\\\n3  y    1\\\\n4  y    1\\\\nName: count, dtype: int64\\\\nSimilarly, you can get the most frequently occurring value(s), i.e. the mode, of the values in a Series or DataFrame:\\\\nIn [125]:\\\\ns5\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n1\\\\n,\\\\n3\\\\n,\\\\n3\\\\n,\\\\n3\\\\n,\\\\n5\\\\n,\\\\n5\\\\n,\\\\n7\\\\n,\\\\n7\\\\n,\\\\n7\\\\n])\\\\nIn [126]:\\\\ns5\\\\n.\\\\nmode\\\\n()\\\\nOut[126]:\\\\n0    3\\\\n1    7\\\\ndtype: int64\\\\nIn [127]:\\\\ndf5\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n7\\\\n,\\\\nsize\\\\n=\\\\n50\\\\n),\\\\n.....:\\\\n\"B\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n-\\\\n10\\\\n,\\\\n15\\\\n,\\\\nsize\\\\n=\\\\n50\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [128]:\\\\ndf5\\\\n.\\\\nmode\\\\n()\\\\nOut[128]:\\\\nA   B\\\\n0  1.0  -9\\\\n1  NaN  10\\\\n2  NaN  13\\\\nDiscretization and quantiling\\\\n#\\\\nContinuous values can be discretized using the\\\\ncut()\\\\n(bins based on values)\\nand\\\\nqcut()\\\\n(bins based on sample quantiles) functions:\\\\nIn [129]:\\\\narr\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n20\\\\n)\\\\nIn [130]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\ncut\\\\n(\\\\narr\\\\n,\\\\n4\\\\n)\\\\nIn [131]:\\\\nfactor\\\\nOut[131]:\\\\n[(-0.251, 0.464], (-0.968, -0.251], (0.464, 1.179], (-0.251, 0.464], (-0.968, -0.251], ..., (-0.251, 0.464], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251]]\\\\nLength: 20\\\\nCategories (4, interval[float64, right]): [(-0.968, -0.251] < (-0.251, 0.464] < (0.464, 1.179] <\\\\n(1.179, 1.893]]\\\\nIn [132]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\ncut\\\\n(\\\\narr\\\\n,\\\\n[\\\\n-\\\\n5\\\\n,\\\\n-\\\\n1\\\\n,\\\\n0\\\\n,\\\\n1\\\\n,\\\\n5\\\\n])\\\\nIn [133]:\\\\nfactor\\\\nOut[133]:\\\\n[(0, 1], (-1, 0], (0, 1], (0, 1], (-1, 0], ..., (-1, 0], (-1, 0], (-1, 0], (-1, 0], (-1, 0]]\\\\nLength: 20\\\\nCategories (4, interval[int64, right]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]\\\\nqcut()\\\\ncomputes sample quantiles. For example, we could slice up some\\nnormally distributed data into equal-size quartiles like so:\\\\nIn [134]:\\\\narr\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n30\\\\n)\\\\nIn [135]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\nqcut\\\\n(\\\\narr\\\\n,\\\\n[\\\\n0\\\\n,\\\\n0.25\\\\n,\\\\n0.5\\\\n,\\\\n0.75\\\\n,\\\\n1\\\\n])\\\\nIn [136]:\\\\nfactor\\\\nOut[136]:\\\\n[(0.569, 1.184], (-2.278, -0.301], (-2.278, -0.301], (0.569, 1.184], (0.569, 1.184], ..., (-0.301, 0.569], (1.184, 2.346], (1.184, 2.346], (-0.301, 0.569], (-2.278, -0.301]]\\\\nLength: 30\\\\nCategories (4, interval[float64, right]): [(-2.278, -0.301] < (-0.301, 0.569] < (0.569, 1.184] <\\\\n(1.184, 2.346]]\\\\nWe can also pass infinite values to define the bins:\\\\nIn [137]:\\\\narr\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n20\\\\n)\\\\nIn [138]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\ncut\\\\n(\\\\narr\\\\n,\\\\n[\\\\n-\\\\nnp\\\\n.\\\\ninf\\\\n,\\\\n0\\\\n,\\\\nnp\\\\n.\\\\ninf\\\\n])\\\\nIn [139]:\\\\nfactor\\\\nOut[139]:\\\\n[(-inf, 0.0], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (-inf, 0.0], (0.0, inf], (0.0, inf]]\\\\nLength: 20\\\\nCategories (2, interval[float64, right]): [(-inf, 0.0] < (0.0, inf]]\\\\nFunction application\\\\n#\\\\nTo apply your own or another library’s functions to pandas objects,\\nyou should be aware of the three methods below. The appropriate\\nmethod to use depends on whether your function expects to operate\\non an entire\\\\nDataFrame\\\\nor\\\\nSeries\\\\n, row- or column-wise, or elementwise.\\\\nTablewise Function Application\\\\n:\\\\npipe()\\\\nRow or Column-wise Function Application\\\\n:\\\\napply()\\\\nAggregation API\\\\n:\\\\nagg()\\\\nand\\\\ntransform()\\\\nApplying Elementwise Functions\\\\n:\\\\nmap()\\\\nTablewise function application\\\\n#\\\\nDataFrames\\\\nand\\\\nSeries\\\\ncan be passed into functions.\\nHowever, if the function needs to be called in a chain, consider using the\\\\npipe()\\\\nmethod.\\\\nFirst some setup:\\\\nIn [140]:\\\\ndef\\\\nextract_city_name\\\\n(\\\\ndf\\\\n):\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\nChicago, IL -> Chicago for city_name column\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\ndf\\\\n[\\\\n\"city_name\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"city_and_code\"\\\\n]\\\\n.\\\\nstr\\\\n.\\\\nsplit\\\\n(\\\\n\",\"\\\\n)\\\\n.\\\\nstr\\\\n.\\\\nget\\\\n(\\\\n0\\\\n)\\\\n.....:\\\\nreturn\\\\ndf\\\\n.....:\\\\nIn [141]:\\\\ndef\\\\nadd_country_name\\\\n(\\\\ndf\\\\n,\\\\ncountry_name\\\\n=\\\\nNone\\\\n):\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\nChicago -> Chicago-US for city_name column\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\ncol\\\\n=\\\\n\"city_name\"\\\\n.....:\\\\ndf\\\\n[\\\\n\"city_and_country\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\ncol\\\\n]\\\\n+\\\\ncountry_name\\\\n.....:\\\\nreturn\\\\ndf\\\\n.....:\\\\nIn [142]:\\\\ndf_p\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"city_and_code\"\\\\n:\\\\n[\\\\n\"Chicago, IL\"\\\\n]})\\\\nextract_city_name\\\\nand\\\\nadd_country_name\\\\nare functions taking and returning\\\\nDataFrames\\\\n.\\\\nNow compare the following:\\\\nIn [143]:\\\\nadd_country_name\\\\n(\\\\nextract_city_name\\\\n(\\\\ndf_p\\\\n),\\\\ncountry_name\\\\n=\\\\n\"US\"\\\\n)\\\\nOut[143]:\\\\ncity_and_code city_name city_and_country\\\\n0   Chicago, IL   Chicago        ChicagoUS\\\\nIs equivalent to:\\\\nIn [144]:\\\\ndf_p\\\\n.\\\\npipe\\\\n(\\\\nextract_city_name\\\\n)\\\\n.\\\\npipe\\\\n(\\\\nadd_country_name\\\\n,\\\\ncountry_name\\\\n=\\\\n\"US\"\\\\n)\\\\nOut[144]:\\\\ncity_and_code city_name city_and_country\\\\n0   Chicago, IL   Chicago        ChicagoUS\\\\npandas encourages the second style, which is known as method chaining.\\\\npipe\\\\nmakes it easy to use your own or another library’s functions\\nin method chains, alongside pandas’ methods.\\\\nIn the example above, the functions\\\\nextract_city_name\\\\nand\\\\nadd_country_name\\\\neach expected a\\\\nDataFrame\\\\nas the first positional argument.\\nWhat if the function you wish to apply takes its data as, say, the second argument?\\nIn this case, provide\\\\npipe\\\\nwith a tuple of\\\\n(callable,\\\\ndata_keyword)\\\\n.\\\\n.pipe\\\\nwill route the\\\\nDataFrame\\\\nto the argument specified in the tuple.\\\\nFor example, we can fit a regression using statsmodels. Their API expects a formula first and a\\\\nDataFrame\\\\nas the second argument,\\\\ndata\\\\n. We pass in the function, keyword pair\\\\n(sm.ols,\\\\n\\'data\\')\\\\nto\\\\npipe\\\\n:\\\\nIn [147]:\\\\nimport\\\\nstatsmodels.formula.api\\\\nas\\\\nsm\\\\nIn [148]:\\\\nbb\\\\n=\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"data/baseball.csv\"\\\\n,\\\\nindex_col\\\\n=\\\\n\"id\"\\\\n)\\\\nIn [149]:\\\\n(\\\\n.....:\\\\nbb\\\\n.\\\\nquery\\\\n(\\\\n\"h > 0\"\\\\n)\\\\n.....:\\\\n.\\\\nassign\\\\n(\\\\nln_h\\\\n=\\\\nlambda\\\\ndf\\\\n:\\\\nnp\\\\n.\\\\nlog\\\\n(\\\\ndf\\\\n.\\\\nh\\\\n))\\\\n.....:\\\\n.\\\\npipe\\\\n((\\\\nsm\\\\n.\\\\nols\\\\n,\\\\n\"data\"\\\\n),\\\\n\"hr ~ ln_h + year + g + C(lg)\"\\\\n)\\\\n.....:\\\\n.\\\\nfit\\\\n()\\\\n.....:\\\\n.\\\\nsummary\\\\n()\\\\n.....:\\\\n)\\\\n.....:\\\\nOut[149]:\\\\n<class \\'statsmodels.iolib.summary.Summary\\'>\\\\n\"\"\"\\\\nOLS Regression Results\\\\n==============================================================================\\\\nDep. Variable:                     hr   R-squared:                       0.685\\\\nModel:                            OLS   Adj. R-squared:                  0.665\\\\nMethod:                 Least Squares   F-statistic:                     34.28\\\\nDate:                Tue, 22 Nov 2022   Prob (F-statistic):           3.48e-15\\\\nTime:                        05:34:17   Log-Likelihood:                -205.92\\\\nNo. Observations:                  68   AIC:                             421.8\\\\nDf Residuals:                      63   BIC:                             432.9\\\\nDf Model:                           4\\\\nCovariance Type:            nonrobust\\\\n===============================================================================\\\\ncoef    std err          t      P>|t|      [0.025      0.975]\\\\n-------------------------------------------------------------------------------\\\\nIntercept\\\\n-\\\\n8484.7720\\\\n4664.146\\\\n-\\\\n1.819\\\\n0.074\\\\n-\\\\n1.78e+04\\\\n835.780\\\\nC\\\\n(\\\\nlg\\\\n)[\\\\nT\\\\n.\\\\nNL\\\\n]\\\\n-\\\\n2.2736\\\\n1.325\\\\n-\\\\n1.716\\\\n0.091\\\\n-\\\\n4.922\\\\n0.375\\\\nln_h\\\\n-\\\\n1.3542\\\\n0.875\\\\n-\\\\n1.547\\\\n0.127\\\\n-\\\\n3.103\\\\n0.395\\\\nyear\\\\n4.2277\\\\n2.324\\\\n1.819\\\\n0.074\\\\n-\\\\n0.417\\\\n8.872\\\\ng\\\\n0.1841\\\\n0.029\\\\n6.258\\\\n0.000\\\\n0.125\\\\n0.243\\\\n==============================================================================\\\\nOmnibus\\\\n:                       10.875   Durbin-Watson:                   1.999\\\\nProb\\\\n(\\\\nOmnibus\\\\n):\\\\n0.004\\\\nJarque\\\\n-\\\\nBera\\\\n(\\\\nJB\\\\n):\\\\n17.298\\\\nSkew\\\\n:                           0.537   Prob(JB):                     0.000175\\\\nKurtosis\\\\n:                       5.225   Cond. No.                     1.49e+07\\\\n==============================================================================\\\\nNotes\\\\n:\\\\n[\\\\n1\\\\n]\\\\nStandard\\\\nErrors\\\\nassume\\\\nthat\\\\nthe\\\\ncovariance\\\\nmatrix\\\\nof\\\\nthe\\\\nerrors\\\\nis\\\\ncorrectly\\\\nspecified\\\\n.\\\\n[\\\\n2\\\\n]\\\\nThe\\\\ncondition\\\\nnumber\\\\nis\\\\nlarge\\\\n,\\\\n1.49e+07\\\\n.\\\\nThis\\\\nmight\\\\nindicate\\\\nthat\\\\nthere\\\\nare\\\\nstrong\\\\nmulticollinearity\\\\nor\\\\nother\\\\nnumerical\\\\nproblems\\\\n.\\\\n\"\"\"\\\\nThe pipe method is inspired by unix pipes and more recently\\\\ndplyr\\\\nand\\\\nmagrittr\\\\n, which\\nhave introduced the popular\\\\n(%>%)\\\\n(read pipe) operator for\\\\nR\\\\n.\\nThe implementation of\\\\npipe\\\\nhere is quite clean and feels right at home in Python.\\nWe encourage you to view the source code of\\\\npipe()\\\\n.\\\\nRow or column-wise function application\\\\n#\\\\nArbitrary functions can be applied along the axes of a DataFrame\\nusing the\\\\napply()\\\\nmethod, which, like the descriptive\\nstatistics methods, takes an optional\\\\naxis\\\\nargument:\\\\nIn [145]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\nx\\\\n))\\\\nOut[145]:\\\\none      0.811094\\\\ntwo      1.360588\\\\nthree    0.187958\\\\ndtype: float64\\\\nIn [146]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\nx\\\\n),\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[146]:\\\\na    1.583749\\\\nb    0.734929\\\\nc    1.133683\\\\nd   -0.166914\\\\ndtype: float64\\\\nIn [147]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nmax\\\\n()\\\\n-\\\\nx\\\\n.\\\\nmin\\\\n())\\\\nOut[147]:\\\\none      1.051928\\\\ntwo      1.632779\\\\nthree    1.840607\\\\ndtype: float64\\\\nIn [148]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nnp\\\\n.\\\\ncumsum\\\\n)\\\\nOut[148]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  1.738035  3.684640 -0.050390\\\\nc  2.433281  5.163008  1.177045\\\\nd       NaN  5.442353  0.563873\\\\nIn [149]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nnp\\\\n.\\\\nexp\\\\n)\\\\nOut[149]:\\\\none       two     three\\\\na  4.034899  5.885648       NaN\\\\nb  1.409244  6.767440  0.950858\\\\nc  2.004201  4.385785  3.412466\\\\nd       NaN  1.322262  0.541630\\\\nThe\\\\napply()\\\\nmethod will also dispatch on a string method name.\\\\nIn [150]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\n\"mean\"\\\\n)\\\\nOut[150]:\\\\none      0.811094\\\\ntwo      1.360588\\\\nthree    0.187958\\\\ndtype: float64\\\\nIn [151]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\n\"mean\"\\\\n,\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[151]:\\\\na    1.583749\\\\nb    0.734929\\\\nc    1.133683\\\\nd   -0.166914\\\\ndtype: float64\\\\nThe return type of the function passed to\\\\napply()\\\\naffects the\\ntype of the final output from\\\\nDataFrame.apply\\\\nfor the default behaviour:\\\\nIf the applied function returns a\\\\nSeries\\\\n, the final output is a\\\\nDataFrame\\\\n.\\nThe columns match the index of the\\\\nSeries\\\\nreturned by the applied function.\\\\nIf the applied function returns any other type, the final output is a\\\\nSeries\\\\n.\\\\nThis default behaviour can be overridden using the\\\\nresult_type\\\\n, which\\naccepts three options:\\\\nreduce\\\\n,\\\\nbroadcast\\\\n, and\\\\nexpand\\\\n.\\nThese will determine how list-likes return values expand (or not) to a\\\\nDataFrame\\\\n.\\\\napply()\\\\ncombined with some cleverness can be used to answer many questions\\nabout a data set. For example, suppose we wanted to extract the date where the\\nmaximum value for each column occurred:\\\\nIn [152]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n1000\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [153]:\\\\ntsdf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nidxmax\\\\n())\\\\nOut[153]:\\\\nA   2000-08-06\\\\nB   2001-01-18\\\\nC   2001-07-18\\\\ndtype: datetime64[ns]\\\\nYou may also pass additional arguments and keyword arguments to the\\\\napply()\\\\nmethod.\\\\nIn [154]:\\\\ndef\\\\nsubtract_and_divide\\\\n(\\\\nx\\\\n,\\\\nsub\\\\n,\\\\ndivide\\\\n=\\\\n1\\\\n):\\\\n.....:\\\\nreturn\\\\n(\\\\nx\\\\n-\\\\nsub\\\\n)\\\\n/\\\\ndivide\\\\n.....:\\\\nIn [155]:\\\\ndf_udf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nones\\\\n((\\\\n2\\\\n,\\\\n2\\\\n)))\\\\nIn [156]:\\\\ndf_udf\\\\n.\\\\napply\\\\n(\\\\nsubtract_and_divide\\\\n,\\\\nargs\\\\n=\\\\n(\\\\n5\\\\n,),\\\\ndivide\\\\n=\\\\n3\\\\n)\\\\nOut[156]:\\\\n0         1\\\\n0 -1.333333 -1.333333\\\\n1 -1.333333 -1.333333\\\\nAnother useful feature is the ability to pass Series methods to carry out some\\nSeries operation on each column or row:\\\\nIn [157]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n10\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [158]:\\\\ntsdf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n7\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [159]:\\\\ntsdf\\\\nOut[159]:\\\\nA         B         C\\\\n2000-01-01 -0.158131 -0.232466  0.321604\\\\n2000-01-02 -1.810340 -3.105758  0.433834\\\\n2000-01-03 -1.209847 -1.156793 -0.136794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08 -0.653602  0.178875  1.008298\\\\n2000-01-09  1.007996  0.462824  0.254472\\\\n2000-01-10  0.307473  0.600337  1.643950\\\\nIn [160]:\\\\ntsdf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nSeries\\\\n.\\\\ninterpolate\\\\n)\\\\nOut[160]:\\\\nA         B         C\\\\n2000-01-01 -0.158131 -0.232466  0.321604\\\\n2000-01-02 -1.810340 -3.105758  0.433834\\\\n2000-01-03 -1.209847 -1.156793 -0.136794\\\\n2000-01-04 -1.098598 -0.889659  0.092225\\\\n2000-01-05 -0.987349 -0.622526  0.321243\\\\n2000-01-06 -0.876100 -0.355392  0.550262\\\\n2000-01-07 -0.764851 -0.088259  0.779280\\\\n2000-01-08 -0.653602  0.178875  1.008298\\\\n2000-01-09  1.007996  0.462824  0.254472\\\\n2000-01-10  0.307473  0.600337  1.643950\\\\nFinally,\\\\napply()\\\\ntakes an argument\\\\nraw\\\\nwhich is False by default, which\\nconverts each row or column into a Series before applying the function. When\\nset to True, the passed function will instead receive an ndarray object, which\\nhas positive performance implications if you do not need the indexing\\nfunctionality.\\\\nAggregation API\\\\n#\\\\nThe aggregation API allows one to express possibly multiple aggregation operations in a single concise way.\\nThis API is similar across pandas objects, see\\\\ngroupby API\\\\n, the\\\\nwindow API\\\\n, and the\\\\nresample API\\\\n.\\nThe entry point for aggregation is\\\\nDataFrame.aggregate()\\\\n, or the alias\\\\nDataFrame.agg()\\\\n.\\\\nWe will use a similar starting frame from above:\\\\nIn [161]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n10\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [162]:\\\\ntsdf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n7\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [163]:\\\\ntsdf\\\\nOut[163]:\\\\nA         B         C\\\\n2000-01-01  1.257606  1.004194  0.167574\\\\n2000-01-02 -0.749892  0.288112 -0.757304\\\\n2000-01-03 -0.207550 -0.298599  0.116018\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.814347 -0.257623  0.869226\\\\n2000-01-09 -0.250663 -1.206601  0.896839\\\\n2000-01-10  2.169758 -1.333363  0.283157\\\\nUsing a single function is equivalent to\\\\napply()\\\\n. You can also\\npass named methods as strings. These will return a\\\\nSeries\\\\nof the aggregated\\noutput:\\\\nIn [164]:\\\\ntsdf\\\\n.\\\\nagg\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nsum\\\\n(\\\\nx\\\\n))\\\\nOut[164]:\\\\nA    3.033606\\\\nB   -1.803879\\\\nC    1.575510\\\\ndtype: float64\\\\nIn [165]:\\\\ntsdf\\\\n.\\\\nagg\\\\n(\\\\n\"sum\"\\\\n)\\\\nOut[165]:\\\\nA    3.033606\\\\nB   -1.803879\\\\nC    1.575510\\\\ndtype: float64\\\\n# these are equivalent to a ``.sum()`` because we are aggregating\\\\n# on a single function\\\\nIn [166]:\\\\ntsdf\\\\n.\\\\nsum\\\\n()\\\\nOut[166]:\\\\nA    3.033606\\\\nB   -1.803879\\\\nC    1.575510\\\\ndtype: float64\\\\nSingle aggregations on a\\\\nSeries\\\\nthis will return a scalar value:\\\\nIn [167]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n(\\\\n\"sum\"\\\\n)\\\\nOut[167]:\\\\n3.033606102414146\\\\nAggregating with multiple functions\\\\n#\\\\nYou can pass multiple aggregation arguments as a list.\\nThe results of each of the passed functions will be a row in the resulting\\\\nDataFrame\\\\n.\\nThese are naturally named from the aggregation function.\\\\nIn [168]:\\\\ntsdf\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n])\\\\nOut[168]:\\\\nA         B        C\\\\nsum  3.033606 -1.803879  1.57551\\\\nMultiple functions yield multiple rows:\\\\nIn [169]:\\\\ntsdf\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\n\"mean\"\\\\n])\\\\nOut[169]:\\\\nA         B         C\\\\nsum   3.033606 -1.803879  1.575510\\\\nmean  0.505601 -0.300647  0.262585\\\\nOn a\\\\nSeries\\\\n, multiple functions return a\\\\nSeries\\\\n, indexed by the function names:\\\\nIn [170]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\n\"mean\"\\\\n])\\\\nOut[170]:\\\\nsum     3.033606\\\\nmean    0.505601\\\\nName: A, dtype: float64\\\\nPassing a\\\\nlambda\\\\nfunction will yield a\\\\n<lambda>\\\\nnamed row:\\\\nIn [171]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nmean\\\\n()])\\\\nOut[171]:\\\\nsum         3.033606\\\\n<lambda>    0.505601\\\\nName: A, dtype: float64\\\\nPassing a named function will yield that name for the row:\\\\nIn [172]:\\\\ndef\\\\nmymean\\\\n(\\\\nx\\\\n):\\\\n.....:\\\\nreturn\\\\nx\\\\n.\\\\nmean\\\\n()\\\\n.....:\\\\nIn [173]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\nmymean\\\\n])\\\\nOut[173]:\\\\nsum       3.033606\\\\nmymean    0.505601\\\\nName: A, dtype: float64\\\\nAggregating with a dict\\\\n#\\\\nPassing a dictionary of column names to a scalar or a list of scalars, to\\\\nDataFrame.agg\\\\nallows you to customize which functions are applied to which columns. Note that the results\\nare not in any particular order, you can use an\\\\nOrderedDict\\\\ninstead to guarantee ordering.\\\\nIn [174]:\\\\ntsdf\\\\n.\\\\nagg\\\\n({\\\\n\"A\"\\\\n:\\\\n\"mean\"\\\\n,\\\\n\"B\"\\\\n:\\\\n\"sum\"\\\\n})\\\\nOut[174]:\\\\nA    0.505601\\\\nB   -1.803879\\\\ndtype: float64\\\\nPassing a list-like will generate a\\\\nDataFrame\\\\noutput. You will get a matrix-like output\\nof all of the aggregators. The output will consist of all unique functions. Those that are\\nnot noted for a particular column will be\\\\nNaN\\\\n:\\\\nIn [175]:\\\\ntsdf\\\\n.\\\\nagg\\\\n({\\\\n\"A\"\\\\n:\\\\n[\\\\n\"mean\"\\\\n,\\\\n\"min\"\\\\n],\\\\n\"B\"\\\\n:\\\\n\"sum\"\\\\n})\\\\nOut[175]:\\\\nA         B\\\\nmean  0.505601       NaN\\\\nmin  -0.749892       NaN\\\\nsum        NaN -1.803879\\\\nCustom describe\\\\n#\\\\nWith\\\\n.agg()\\\\nit is possible to easily create a custom describe function, similar\\nto the built in\\\\ndescribe function\\\\n.\\\\nIn [176]:\\\\nfrom\\\\nfunctools\\\\nimport\\\\npartial\\\\nIn [177]:\\\\nq_25\\\\n=\\\\npartial\\\\n(\\\\npd\\\\n.\\\\nSeries\\\\n.\\\\nquantile\\\\n,\\\\nq\\\\n=\\\\n0.25\\\\n)\\\\nIn [178]:\\\\nq_25\\\\n.\\\\n__name__\\\\n=\\\\n\"25%\"\\\\nIn [179]:\\\\nq_75\\\\n=\\\\npartial\\\\n(\\\\npd\\\\n.\\\\nSeries\\\\n.\\\\nquantile\\\\n,\\\\nq\\\\n=\\\\n0.75\\\\n)\\\\nIn [180]:\\\\nq_75\\\\n.\\\\n__name__\\\\n=\\\\n\"75%\"\\\\nIn [181]:\\\\ntsdf\\\\n.\\\\nagg\\\\n([\\\\n\"count\"\\\\n,\\\\n\"mean\"\\\\n,\\\\n\"std\"\\\\n,\\\\n\"min\"\\\\n,\\\\nq_25\\\\n,\\\\n\"median\"\\\\n,\\\\nq_75\\\\n,\\\\n\"max\"\\\\n])\\\\nOut[181]:\\\\nA         B         C\\\\ncount   6.000000  6.000000  6.000000\\\\nmean    0.505601 -0.300647  0.262585\\\\nstd     1.103362  0.887508  0.606860\\\\nmin    -0.749892 -1.333363 -0.757304\\\\n25%    -0.239885 -0.979600  0.128907\\\\nmedian  0.303398 -0.278111  0.225365\\\\n75%     1.146791  0.151678  0.722709\\\\nmax     2.169758  1.004194  0.896839\\\\nTransform API\\\\n#\\\\nThe\\\\ntransform()\\\\nmethod returns an object that is indexed the same (same size)\\nas the original. This API allows you to provide\\\\nmultiple\\\\noperations at the same\\ntime rather than one-by-one. Its API is quite similar to the\\\\n.agg\\\\nAPI.\\\\nWe create a frame similar to the one used in the above sections.\\\\nIn [182]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n10\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [183]:\\\\ntsdf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n7\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [184]:\\\\ntsdf\\\\nOut[184]:\\\\nA         B         C\\\\n2000-01-01 -0.428759 -0.864890 -0.675341\\\\n2000-01-02 -0.168731  1.338144 -1.279321\\\\n2000-01-03 -1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374 -1.240447 -0.201052\\\\n2000-01-09 -0.157795  0.791197 -1.144209\\\\n2000-01-10 -0.030876  0.371900  0.061932\\\\nTransform the entire frame.\\\\n.transform()\\\\nallows input functions as: a NumPy function, a string\\nfunction name or a user defined function.\\\\nIn [185]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n(\\\\nnp\\\\n.\\\\nabs\\\\n)\\\\nOut[185]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nIn [186]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n(\\\\n\"abs\"\\\\n)\\\\nOut[186]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nIn [187]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nabs\\\\n())\\\\nOut[187]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nHere\\\\ntransform()\\\\nreceived a single function; this is equivalent to a\\\\nufunc\\\\napplication.\\\\nIn [188]:\\\\nnp\\\\n.\\\\nabs\\\\n(\\\\ntsdf\\\\n)\\\\nOut[188]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nPassing a single function to\\\\n.transform()\\\\nwith a\\\\nSeries\\\\nwill yield a single\\\\nSeries\\\\nin return.\\\\nIn [189]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\ntransform\\\\n(\\\\nnp\\\\n.\\\\nabs\\\\n)\\\\nOut[189]:\\\\n2000-01-01    0.428759\\\\n2000-01-02    0.168731\\\\n2000-01-03    1.621034\\\\n2000-01-04         NaN\\\\n2000-01-05         NaN\\\\n2000-01-06         NaN\\\\n2000-01-07         NaN\\\\n2000-01-08    0.254374\\\\n2000-01-09    0.157795\\\\n2000-01-10    0.030876\\\\nFreq: D, Name: A, dtype: float64\\\\nTransform with multiple functions\\\\n#\\\\nPassing multiple functions will yield a column MultiIndexed DataFrame.\\nThe first level will be the original frame column names; the second level\\nwill be the names of the transforming functions.\\\\nIn [190]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n([\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n])\\\\nOut[190]:\\\\nA                   B                   C\\\\nabsolute  <lambda>  absolute  <lambda>  absolute  <lambda>\\\\n2000-01-01  0.428759  0.571241  0.864890  0.135110  0.675341  0.324659\\\\n2000-01-02  0.168731  0.831269  1.338144  2.338144  1.279321 -0.279321\\\\n2000-01-03  1.621034 -0.621034  0.438107  1.438107  0.903794  1.903794\\\\n2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.254374  1.240447 -0.240447  0.201052  0.798948\\\\n2000-01-09  0.157795  0.842205  0.791197  1.791197  1.144209 -0.144209\\\\n2000-01-10  0.030876  0.969124  0.371900  1.371900  0.061932  1.061932\\\\nPassing multiple functions to a Series will yield a DataFrame. The\\nresulting column names will be the transforming functions.\\\\nIn [191]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\ntransform\\\\n([\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n])\\\\nOut[191]:\\\\nabsolute  <lambda>\\\\n2000-01-01  0.428759  0.571241\\\\n2000-01-02  0.168731  0.831269\\\\n2000-01-03  1.621034 -0.621034\\\\n2000-01-04       NaN       NaN\\\\n2000-01-05       NaN       NaN\\\\n2000-01-06       NaN       NaN\\\\n2000-01-07       NaN       NaN\\\\n2000-01-08  0.254374  1.254374\\\\n2000-01-09  0.157795  0.842205\\\\n2000-01-10  0.030876  0.969124\\\\nTransforming with a dict\\\\n#\\\\nPassing a dict of functions will allow selective transforming per column.\\\\nIn [192]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n({\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\n\"B\"\\\\n:\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n})\\\\nOut[192]:\\\\nA         B\\\\n2000-01-01  0.428759  0.135110\\\\n2000-01-02  0.168731  2.338144\\\\n2000-01-03  1.621034  1.438107\\\\n2000-01-04       NaN       NaN\\\\n2000-01-05       NaN       NaN\\\\n2000-01-06       NaN       NaN\\\\n2000-01-07       NaN       NaN\\\\n2000-01-08  0.254374 -0.240447\\\\n2000-01-09  0.157795  1.791197\\\\n2000-01-10  0.030876  1.371900\\\\nPassing a dict of lists will generate a MultiIndexed DataFrame with these\\nselective transforms.\\\\nIn [193]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n({\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\n\"B\"\\\\n:\\\\n[\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n,\\\\n\"sqrt\"\\\\n]})\\\\nOut[193]:\\\\nA         B\\\\nabsolute  <lambda>      sqrt\\\\n2000-01-01  0.428759  0.135110       NaN\\\\n2000-01-02  0.168731  2.338144  1.156782\\\\n2000-01-03  1.621034  1.438107  0.661897\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374 -0.240447       NaN\\\\n2000-01-09  0.157795  1.791197  0.889493\\\\n2000-01-10  0.030876  1.371900  0.609836\\\\nApplying elementwise functions\\\\n#\\\\nSince not all functions can be vectorized (accept NumPy arrays and return\\nanother array or value), the methods\\\\nmap()\\\\non DataFrame\\nand analogously\\\\nmap()\\\\non Series accept any Python function taking\\na single value and returning a single value. For example:\\\\nIn [194]:\\\\ndf4\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [195]:\\\\ndf4\\\\nOut[195]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [196]:\\\\ndef\\\\nf\\\\n(\\\\nx\\\\n):\\\\n.....:\\\\nreturn\\\\nlen\\\\n(\\\\nstr\\\\n(\\\\nx\\\\n))\\\\n.....:\\\\nIn [197]:\\\\ndf4\\\\n[\\\\n\"one\"\\\\n]\\\\n.\\\\nmap\\\\n(\\\\nf\\\\n)\\\\nOut[197]:\\\\na    18\\\\nb    19\\\\nc    18\\\\nd     3\\\\nName: one, dtype: int64\\\\nIn [198]:\\\\ndf4\\\\n.\\\\nmap\\\\n(\\\\nf\\\\n)\\\\nOut[198]:\\\\none  two  three\\\\na   18   17      3\\\\nb   19   18     20\\\\nc   18   18     16\\\\nd    3   19     19\\\\nSeries.map()\\\\nhas an additional feature; it can be used to easily\\n“link” or “map” values defined by a secondary series. This is closely related\\nto\\\\nmerging/joining functionality\\\\n:\\\\nIn [199]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n.....:\\\\n[\\\\n\"six\"\\\\n,\\\\n\"seven\"\\\\n,\\\\n\"six\"\\\\n,\\\\n\"seven\"\\\\n,\\\\n\"six\"\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [200]:\\\\nt\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n({\\\\n\"six\"\\\\n:\\\\n6.0\\\\n,\\\\n\"seven\"\\\\n:\\\\n7.0\\\\n})\\\\nIn [201]:\\\\ns\\\\nOut[201]:\\\\na      six\\\\nb    seven\\\\nc      six\\\\nd    seven\\\\ne      six\\\\ndtype: object\\\\nIn [202]:\\\\ns\\\\n.\\\\nmap\\\\n(\\\\nt\\\\n)\\\\nOut[202]:\\\\na    6.0\\\\nb    7.0\\\\nc    6.0\\\\nd    7.0\\\\ne    6.0\\\\ndtype: float64\\\\nReindexing and altering labels\\\\n#\\\\nreindex()\\\\nis the fundamental data alignment method in pandas.\\nIt is used to implement nearly all other features relying on label-alignment\\nfunctionality. To\\\\nreindex\\\\nmeans to conform the data to match a given set of\\nlabels along a particular axis. This accomplishes several things:\\\\nReorders the existing data to match a new set of labels\\\\nInserts missing value (NA) markers in label locations where no data for\\nthat label existed\\\\nIf specified,\\\\nfill\\\\ndata for missing labels using logic (highly relevant\\nto working with time series data)\\\\nHere is a simple example:\\\\nIn [203]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [204]:\\\\ns\\\\nOut[204]:\\\\na    1.695148\\\\nb    1.328614\\\\nc    1.234686\\\\nd   -0.385845\\\\ne   -1.326508\\\\ndtype: float64\\\\nIn [205]:\\\\ns\\\\n.\\\\nreindex\\\\n([\\\\n\"e\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"f\"\\\\n,\\\\n\"d\"\\\\n])\\\\nOut[205]:\\\\ne   -1.326508\\\\nb    1.328614\\\\nf         NaN\\\\nd   -0.385845\\\\ndtype: float64\\\\nHere, the\\\\nf\\\\nlabel was not contained in the Series and hence appears as\\\\nNaN\\\\nin the result.\\\\nWith a DataFrame, you can simultaneously reindex the index and columns:\\\\nIn [206]:\\\\ndf\\\\nOut[206]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [207]:\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\nindex\\\\n=\\\\n[\\\\n\"c\"\\\\n,\\\\n\"f\"\\\\n,\\\\n\"b\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n])\\\\nOut[207]:\\\\nthree       two       one\\\\nc  1.227435  1.478369  0.695246\\\\nf       NaN       NaN       NaN\\\\nb -0.050390  1.912123  0.343054\\\\nNote that the\\\\nIndex\\\\nobjects containing the actual axis labels can be\\\\nshared\\\\nbetween objects. So if we have a Series and a DataFrame, the\\nfollowing can be done:\\\\nIn [208]:\\\\nrs\\\\n=\\\\ns\\\\n.\\\\nreindex\\\\n(\\\\ndf\\\\n.\\\\nindex\\\\n)\\\\nIn [209]:\\\\nrs\\\\nOut[209]:\\\\na    1.695148\\\\nb    1.328614\\\\nc    1.234686\\\\nd   -0.385845\\\\ndtype: float64\\\\nIn [210]:\\\\nrs\\\\n.\\\\nindex\\\\nis\\\\ndf\\\\n.\\\\nindex\\\\nOut[210]:\\\\nTrue\\\\nThis means that the reindexed Series’s index is the same Python object as the\\nDataFrame’s index.\\\\nDataFrame.reindex()\\\\nalso supports an “axis-style” calling convention,\\nwhere you specify a single\\\\nlabels\\\\nargument and the\\\\naxis\\\\nit applies to.\\\\nIn [211]:\\\\ndf\\\\n.\\\\nreindex\\\\n([\\\\n\"c\"\\\\n,\\\\n\"f\"\\\\n,\\\\n\"b\"\\\\n],\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[211]:\\\\none       two     three\\\\nc  0.695246  1.478369  1.227435\\\\nf       NaN       NaN       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nIn [212]:\\\\ndf\\\\n.\\\\nreindex\\\\n([\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n],\\\\naxis\\\\n=\\\\n\"columns\"\\\\n)\\\\nOut[212]:\\\\nthree       two       one\\\\na       NaN  1.772517  1.394981\\\\nb -0.050390  1.912123  0.343054\\\\nc  1.227435  1.478369  0.695246\\\\nd -0.613172  0.279344       NaN\\\\nSee also\\\\nMultiIndex / Advanced Indexing\\\\nis an even more concise way of\\ndoing reindexing.\\\\nNote\\\\nWhen writing performance-sensitive code, there is a good reason to spend\\nsome time becoming a reindexing ninja:\\\\nmany operations are faster on\\npre-aligned data\\\\n. Adding two unaligned DataFrames internally triggers a\\nreindexing step. For exploratory analysis you will hardly notice the\\ndifference (because\\\\nreindex\\\\nhas been heavily optimized), but when CPU\\ncycles matter sprinkling a few explicit\\\\nreindex\\\\ncalls here and there can\\nhave an impact.\\\\nReindexing to align with another object\\\\n#\\\\nYou may wish to take an object and reindex its axes to be labeled the same as\\nanother object. While the syntax for this is straightforward albeit verbose, it\\nis a common enough operation that the\\\\nreindex_like()\\\\nmethod is\\navailable to make this simpler:\\\\nIn [213]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\nreindex\\\\n([\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n])\\\\nIn [214]:\\\\ndf3\\\\n=\\\\ndf2\\\\n-\\\\ndf2\\\\n.\\\\nmean\\\\n()\\\\nIn [215]:\\\\ndf2\\\\nOut[215]:\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369\\\\nIn [216]:\\\\ndf3\\\\nOut[216]:\\\\none       two\\\\na  0.583888  0.051514\\\\nb -0.468040  0.191120\\\\nc -0.115848 -0.242634\\\\nIn [217]:\\\\ndf\\\\n.\\\\nreindex_like\\\\n(\\\\ndf2\\\\n)\\\\nOut[217]:\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369\\\\nAligning objects with each other with\\\\nalign\\\\n#\\\\nThe\\\\nalign()\\\\nmethod is the fastest way to simultaneously align two objects. It\\nsupports a\\\\njoin\\\\nargument (related to\\\\njoining and merging\\\\n):\\\\njoin=\\'outer\\'\\\\n: take the union of the indexes (default)\\\\njoin=\\'left\\'\\\\n: use the calling object’s index\\\\njoin=\\'right\\'\\\\n: use the passed object’s index\\\\njoin=\\'inner\\'\\\\n: intersect the indexes\\\\nIt returns a tuple with both of the reindexed Series:\\\\nIn [218]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [219]:\\\\ns1\\\\n=\\\\ns\\\\n[:\\\\n4\\\\n]\\\\nIn [220]:\\\\ns2\\\\n=\\\\ns\\\\n[\\\\n1\\\\n:]\\\\nIn [221]:\\\\ns1\\\\n.\\\\nalign\\\\n(\\\\ns2\\\\n)\\\\nOut[221]:\\\\n(a   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne         NaN\\\\ndtype: float64,\\\\na         NaN\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne    1.114285\\\\ndtype: float64)\\\\nIn [222]:\\\\ns1\\\\n.\\\\nalign\\\\n(\\\\ns2\\\\n,\\\\njoin\\\\n=\\\\n\"inner\"\\\\n)\\\\nOut[222]:\\\\n(b   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64,\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64)\\\\nIn [223]:\\\\ns1\\\\n.\\\\nalign\\\\n(\\\\ns2\\\\n,\\\\njoin\\\\n=\\\\n\"left\"\\\\n)\\\\nOut[223]:\\\\n(a   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64,\\\\na         NaN\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64)\\\\nFor DataFrames, the join method will be applied to both the index and the\\ncolumns by default:\\\\nIn [224]:\\\\ndf\\\\n.\\\\nalign\\\\n(\\\\ndf2\\\\n,\\\\njoin\\\\n=\\\\n\"inner\"\\\\n)\\\\nOut[224]:\\\\n(        one       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369,\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369)\\\\nYou can also pass an\\\\naxis\\\\noption to only align on the specified axis:\\\\nIn [225]:\\\\ndf\\\\n.\\\\nalign\\\\n(\\\\ndf2\\\\n,\\\\njoin\\\\n=\\\\n\"inner\"\\\\n,\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[225]:\\\\n(        one       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435,\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369)\\\\nIf you pass a Series to\\\\nDataFrame.align()\\\\n, you can choose to align both\\nobjects either on the DataFrame’s index or columns using the\\\\naxis\\\\nargument:\\\\nIn [226]:\\\\ndf\\\\n.\\\\nalign\\\\n(\\\\ndf2\\\\n.\\\\niloc\\\\n[\\\\n0\\\\n],\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[226]:\\\\n(        one     three       two\\\\na  1.394981       NaN  1.772517\\\\nb  0.343054 -0.050390  1.912123\\\\nc  0.695246  1.227435  1.478369\\\\nd       NaN -0.613172  0.279344,\\\\none      1.394981\\\\nthree         NaN\\\\ntwo      1.772517\\\\nName: a, dtype: float64)\\\\nFilling while reindexing\\\\n#\\\\nreindex()\\\\ntakes an optional parameter\\\\nmethod\\\\nwhich is a\\nfilling method chosen from the following table:\\\\nMethod\\\\nAction\\\\npad / ffill\\\\nFill values forward\\\\nbfill / backfill\\\\nFill values backward\\\\nnearest\\\\nFill from the nearest index value\\\\nWe illustrate these fill methods on a simple Series:\\\\nIn [227]:\\\\nrng\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/3/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n8\\\\n)\\\\nIn [228]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\nindex\\\\n=\\\\nrng\\\\n)\\\\nIn [229]:\\\\nts2\\\\n=\\\\nts\\\\n.\\\\niloc\\\\n[[\\\\n0\\\\n,\\\\n3\\\\n,\\\\n6\\\\n]]\\\\nIn [230]:\\\\nts\\\\nOut[230]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.400528\\\\n2000-01-05   -0.015083\\\\n2000-01-06    2.395489\\\\n2000-01-07    1.414806\\\\n2000-01-08    0.118428\\\\n2000-01-09    0.733639\\\\n2000-01-10   -0.936077\\\\nFreq: D, dtype: float64\\\\nIn [231]:\\\\nts2\\\\nOut[231]:\\\\n2000-01-03    0.183051\\\\n2000-01-06    2.395489\\\\n2000-01-09    0.733639\\\\nFreq: 3D, dtype: float64\\\\nIn [232]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n)\\\\nOut[232]:\\\\n2000-01-03    0.183051\\\\n2000-01-04         NaN\\\\n2000-01-05         NaN\\\\n2000-01-06    2.395489\\\\n2000-01-07         NaN\\\\n2000-01-08         NaN\\\\n2000-01-09    0.733639\\\\n2000-01-10         NaN\\\\nFreq: D, dtype: float64\\\\nIn [233]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"ffill\"\\\\n)\\\\nOut[233]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05    0.183051\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08    2.395489\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nIn [234]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"bfill\"\\\\n)\\\\nOut[234]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    2.395489\\\\n2000-01-05    2.395489\\\\n2000-01-06    2.395489\\\\n2000-01-07    0.733639\\\\n2000-01-08    0.733639\\\\n2000-01-09    0.733639\\\\n2000-01-10         NaN\\\\nFreq: D, dtype: float64\\\\nIn [235]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"nearest\"\\\\n)\\\\nOut[235]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05    2.395489\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08    0.733639\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nThese methods require that the indexes are\\\\nordered\\\\nincreasing or\\ndecreasing.\\\\nNote that the same result could have been achieved using\\\\nffill\\\\n(except for\\\\nmethod=\\'nearest\\'\\\\n) or\\\\ninterpolate\\\\n:\\\\nIn [236]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n)\\\\n.\\\\nffill\\\\n()\\\\nOut[236]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05    0.183051\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08    2.395489\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nreindex()\\\\nwill raise a ValueError if the index is not monotonically\\nincreasing or decreasing.\\\\nfillna()\\\\nand\\\\ninterpolate()\\\\nwill not perform any checks on the order of the index.\\\\nLimits on filling while reindexing\\\\n#\\\\nThe\\\\nlimit\\\\nand\\\\ntolerance\\\\narguments provide additional control over\\nfilling while reindexing. Limit specifies the maximum count of consecutive\\nmatches:\\\\nIn [237]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"ffill\"\\\\n,\\\\nlimit\\\\n=\\\\n1\\\\n)\\\\nOut[237]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05         NaN\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08         NaN\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nIn contrast, tolerance specifies the maximum distance between the index and\\nindexer values:\\\\nIn [238]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"ffill\"\\\\n,\\\\ntolerance\\\\n=\\\\n\"1 day\"\\\\n)\\\\nOut[238]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05         NaN\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08         NaN\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nNotice that when used on a\\\\nDatetimeIndex\\\\n,\\\\nTimedeltaIndex\\\\nor\\\\nPeriodIndex\\\\n,\\\\ntolerance\\\\nwill coerced into a\\\\nTimedelta\\\\nif possible.\\nThis allows you to specify tolerance with appropriate strings.\\\\nDropping labels from an axis\\\\n#\\\\nA method closely related to\\\\nreindex\\\\nis the\\\\ndrop()\\\\nfunction.\\nIt removes a set of labels from an axis:\\\\nIn [239]:\\\\ndf\\\\nOut[239]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [240]:\\\\ndf\\\\n.\\\\ndrop\\\\n([\\\\n\"a\"\\\\n,\\\\n\"d\"\\\\n],\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[240]:\\\\none       two     three\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nIn [241]:\\\\ndf\\\\n.\\\\ndrop\\\\n([\\\\n\"one\"\\\\n],\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[241]:\\\\ntwo     three\\\\na  1.772517       NaN\\\\nb  1.912123 -0.050390\\\\nc  1.478369  1.227435\\\\nd  0.279344 -0.613172\\\\nNote that the following also works, but is a bit less obvious / clean:\\\\nIn [242]:\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\ndf\\\\n.\\\\nindex\\\\n.\\\\ndifference\\\\n([\\\\n\"a\"\\\\n,\\\\n\"d\"\\\\n]))\\\\nOut[242]:\\\\none       two     three\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nRenaming / mapping labels\\\\n#\\\\nThe\\\\nrename()\\\\nmethod allows you to relabel an axis based on some\\nmapping (a dict or Series) or an arbitrary function.\\\\nIn [243]:\\\\ns\\\\nOut[243]:\\\\na   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne    1.114285\\\\ndtype: float64\\\\nIn [244]:\\\\ns\\\\n.\\\\nrename\\\\n(\\\\nstr\\\\n.\\\\nupper\\\\n)\\\\nOut[244]:\\\\nA   -0.186646\\\\nB   -1.692424\\\\nC   -0.303893\\\\nD   -1.425662\\\\nE    1.114285\\\\ndtype: float64\\\\nIf you pass a function, it must return a value when called with any of the\\nlabels (and must produce a set of unique values). A dict or\\nSeries can also be used:\\\\nIn [245]:\\\\ndf\\\\n.\\\\nrename\\\\n(\\\\n.....:\\\\ncolumns\\\\n=\\\\n{\\\\n\"one\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n\"two\"\\\\n:\\\\n\"bar\"\\\\n},\\\\n.....:\\\\nindex\\\\n=\\\\n{\\\\n\"a\"\\\\n:\\\\n\"apple\"\\\\n,\\\\n\"b\"\\\\n:\\\\n\"banana\"\\\\n,\\\\n\"d\"\\\\n:\\\\n\"durian\"\\\\n},\\\\n.....:\\\\n)\\\\n.....:\\\\nOut[245]:\\\\nfoo       bar     three\\\\napple   1.394981  1.772517       NaN\\\\nbanana  0.343054  1.912123 -0.050390\\\\nc       0.695246  1.478369  1.227435\\\\ndurian       NaN  0.279344 -0.613172\\\\nIf the mapping doesn’t include a column/index label, it isn’t renamed. Note that\\nextra labels in the mapping don’t throw an error.\\\\nDataFrame.rename()\\\\nalso supports an “axis-style” calling convention, where\\nyou specify a single\\\\nmapper\\\\nand the\\\\naxis\\\\nto apply that mapping to.\\\\nIn [246]:\\\\ndf\\\\n.\\\\nrename\\\\n({\\\\n\"one\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n\"two\"\\\\n:\\\\n\"bar\"\\\\n},\\\\naxis\\\\n=\\\\n\"columns\"\\\\n)\\\\nOut[246]:\\\\nfoo       bar     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [247]:\\\\ndf\\\\n.\\\\nrename\\\\n({\\\\n\"a\"\\\\n:\\\\n\"apple\"\\\\n,\\\\n\"b\"\\\\n:\\\\n\"banana\"\\\\n,\\\\n\"d\"\\\\n:\\\\n\"durian\"\\\\n},\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[247]:\\\\none       two     three\\\\napple   1.394981  1.772517       NaN\\\\nbanana  0.343054  1.912123 -0.050390\\\\nc       0.695246  1.478369  1.227435\\\\ndurian       NaN  0.279344 -0.613172\\\\nFinally,\\\\nrename()\\\\nalso accepts a scalar or list-like\\nfor altering the\\\\nSeries.name\\\\nattribute.\\\\nIn [248]:\\\\ns\\\\n.\\\\nrename\\\\n(\\\\n\"scalar-name\"\\\\n)\\\\nOut[248]:\\\\na   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne    1.114285\\\\nName: scalar-name, dtype: float64\\\\nThe methods\\\\nDataFrame.rename_axis()\\\\nand\\\\nSeries.rename_axis()\\\\nallow specific names of a\\\\nMultiIndex\\\\nto be changed (as opposed to the\\nlabels).\\\\nIn [249]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"x\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"y\"\\\\n:\\\\n[\\\\n10\\\\n,\\\\n20\\\\n,\\\\n30\\\\n,\\\\n40\\\\n,\\\\n50\\\\n,\\\\n60\\\\n]},\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_product\\\\n(\\\\n.....:\\\\n[[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n],\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]],\\\\nnames\\\\n=\\\\n[\\\\n\"let\"\\\\n,\\\\n\"num\"\\\\n]\\\\n.....:\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [250]:\\\\ndf\\\\nOut[250]:\\\\nx   y\\\\nlet num\\\\na   1    1  10\\\\n2    2  20\\\\nb   1    3  30\\\\n2    4  40\\\\nc   1    5  50\\\\n2    6  60\\\\nIn [251]:\\\\ndf\\\\n.\\\\nrename_axis\\\\n(\\\\nindex\\\\n=\\\\n{\\\\n\"let\"\\\\n:\\\\n\"abc\"\\\\n})\\\\nOut[251]:\\\\nx   y\\\\nabc num\\\\na   1    1  10\\\\n2    2  20\\\\nb   1    3  30\\\\n2    4  40\\\\nc   1    5  50\\\\n2    6  60\\\\nIn [252]:\\\\ndf\\\\n.\\\\nrename_axis\\\\n(\\\\nindex\\\\n=\\\\nstr\\\\n.\\\\nupper\\\\n)\\\\nOut[252]:\\\\nx   y\\\\nLET NUM\\\\na   1    1  10\\\\n2    2  20\\\\nb   1    3  30\\\\n2    4  40\\\\nc   1    5  50\\\\n2    6  60\\\\nIteration\\\\n#\\\\nThe behavior of basic iteration over pandas objects depends on the type.\\nWhen iterating over a Series, it is regarded as array-like, and basic iteration\\nproduces the values. DataFrames follow the dict-like convention of iterating\\nover the “keys” of the objects.\\\\nIn short, basic iteration (\\\\nfor\\\\ni\\\\nin\\\\nobject\\\\n) produces:\\\\nSeries\\\\n: values\\\\nDataFrame\\\\n: column labels\\\\nThus, for example, iterating over a DataFrame gives you the column names:\\\\nIn [253]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"col1\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\n\"col2\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n)},\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [254]:\\\\nfor\\\\ncol\\\\nin\\\\ndf\\\\n:\\\\n.....:\\\\nprint\\\\n(\\\\ncol\\\\n)\\\\n.....:\\\\ncol1\\\\ncol2\\\\npandas objects also have the dict-like\\\\nitems()\\\\nmethod to\\niterate over the (key, value) pairs.\\\\nTo iterate over the rows of a DataFrame, you can use the following methods:\\\\niterrows()\\\\n: Iterate over the rows of a DataFrame as (index, Series) pairs.\\nThis converts the rows to Series objects, which can change the dtypes and has some\\nperformance implications.\\\\nitertuples()\\\\n: Iterate over the rows of a DataFrame\\nas namedtuples of the values.  This is a lot faster than\\\\niterrows()\\\\n, and is in most cases preferable to use\\nto iterate over the values of a DataFrame.\\\\nWarning\\\\nIterating through pandas objects is generally\\\\nslow\\\\n. In many cases,\\niterating manually over the rows is not needed and can be avoided with\\none of the following approaches:\\\\nLook for a\\\\nvectorized\\\\nsolution: many operations can be performed using\\nbuilt-in methods or NumPy functions, (boolean) indexing, …\\\\nWhen you have a function that cannot work on the full DataFrame/Series\\nat once, it is better to use\\\\napply()\\\\ninstead of iterating\\nover the values. See the docs on\\\\nfunction application\\\\n.\\\\nIf you need to do iterative manipulations on the values but performance is\\nimportant, consider writing the inner loop with cython or numba.\\nSee the\\\\nenhancing performance\\\\nsection for some\\nexamples of this approach.\\\\nWarning\\\\nYou should\\\\nnever modify\\\\nsomething you are iterating over.\\nThis is not guaranteed to work in all cases. Depending on the\\ndata types, the iterator returns a copy and not a view, and writing\\nto it will have no effect!\\\\nFor example, in the following case setting the value has no effect:\\\\nIn [255]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]})\\\\nIn [256]:\\\\nfor\\\\nindex\\\\n,\\\\nrow\\\\nin\\\\ndf\\\\n.\\\\niterrows\\\\n():\\\\n.....:\\\\nrow\\\\n[\\\\n\"a\"\\\\n]\\\\n=\\\\n10\\\\n.....:\\\\nIn [257]:\\\\ndf\\\\nOut[257]:\\\\na  b\\\\n0  1  a\\\\n1  2  b\\\\n2  3  c\\\\nitems\\\\n#\\\\nConsistent with the dict-like interface,\\\\nitems()\\\\niterates\\nthrough key-value pairs:\\\\nSeries\\\\n: (index, scalar value) pairs\\\\nDataFrame\\\\n: (column, Series) pairs\\\\nFor example:\\\\nIn [258]:\\\\nfor\\\\nlabel\\\\n,\\\\nser\\\\nin\\\\ndf\\\\n.\\\\nitems\\\\n():\\\\n.....:\\\\nprint\\\\n(\\\\nlabel\\\\n)\\\\n.....:\\\\nprint\\\\n(\\\\nser\\\\n)\\\\n.....:\\\\na\\\\n0    1\\\\n1    2\\\\n2    3\\\\nName: a, dtype: int64\\\\nb\\\\n0    a\\\\n1    b\\\\n2    c\\\\nName: b, dtype: object\\\\niterrows\\\\n#\\\\niterrows()\\\\nallows you to iterate through the rows of a\\nDataFrame as Series objects. It returns an iterator yielding each\\nindex value along with a Series containing the data in each row:\\\\nIn [259]:\\\\nfor\\\\nrow_index\\\\n,\\\\nrow\\\\nin\\\\ndf\\\\n.\\\\niterrows\\\\n():\\\\n.....:\\\\nprint\\\\n(\\\\nrow_index\\\\n,\\\\nrow\\\\n,\\\\nsep\\\\n=\\\\n\"\\\\n\\\\n\\\\n\"\\\\n)\\\\n.....:\\\\n0\\\\na    1\\\\nb    a\\\\nName: 0, dtype: object\\\\n1\\\\na    2\\\\nb    b\\\\nName: 1, dtype: object\\\\n2\\\\na    3\\\\nb    c\\\\nName: 2, dtype: object\\\\nNote\\\\nBecause\\\\niterrows()\\\\nreturns a Series for each row,\\nit does\\\\nnot\\\\npreserve dtypes across the rows (dtypes are\\npreserved across columns for DataFrames). For example,\\\\nIn [260]:\\\\ndf_orig\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n1\\\\n,\\\\n1.5\\\\n]],\\\\ncolumns\\\\n=\\\\n[\\\\n\"int\"\\\\n,\\\\n\"float\"\\\\n])\\\\nIn [261]:\\\\ndf_orig\\\\n.\\\\ndtypes\\\\nOut[261]:\\\\nint        int64\\\\nfloat    float64\\\\ndtype: object\\\\nIn [262]:\\\\nrow\\\\n=\\\\nnext\\\\n(\\\\ndf_orig\\\\n.\\\\niterrows\\\\n())[\\\\n1\\\\n]\\\\nIn [263]:\\\\nrow\\\\nOut[263]:\\\\nint      1.0\\\\nfloat    1.5\\\\nName: 0, dtype: float64\\\\nAll values in\\\\nrow\\\\n, returned as a Series, are now upcasted\\nto floats, also the original integer value in column\\\\nx\\\\n:\\\\nIn [264]:\\\\nrow\\\\n[\\\\n\"int\"\\\\n]\\\\n.\\\\ndtype\\\\nOut[264]:\\\\ndtype(\\'float64\\')\\\\nIn [265]:\\\\ndf_orig\\\\n[\\\\n\"int\"\\\\n]\\\\n.\\\\ndtype\\\\nOut[265]:\\\\ndtype(\\'int64\\')\\\\nTo preserve dtypes while iterating over the rows, it is better\\nto use\\\\nitertuples()\\\\nwhich returns namedtuples of the values\\nand which is generally much faster than\\\\niterrows()\\\\n.\\\\nFor instance, a contrived way to transpose the DataFrame would be:\\\\nIn [266]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"x\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"y\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n]})\\\\nIn [267]:\\\\nprint\\\\n(\\\\ndf2\\\\n)\\\\nx  y\\\\n0  1  4\\\\n1  2  5\\\\n2  3  6\\\\nIn [268]:\\\\nprint\\\\n(\\\\ndf2\\\\n.\\\\nT\\\\n)\\\\n0  1  2\\\\nx  1  2  3\\\\ny  4  5  6\\\\nIn [269]:\\\\ndf2_t\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\nidx\\\\n:\\\\nvalues\\\\nfor\\\\nidx\\\\n,\\\\nvalues\\\\nin\\\\ndf2\\\\n.\\\\niterrows\\\\n()})\\\\nIn [270]:\\\\nprint\\\\n(\\\\ndf2_t\\\\n)\\\\n0  1  2\\\\nx  1  2  3\\\\ny  4  5  6\\\\nitertuples\\\\n#\\\\nThe\\\\nitertuples()\\\\nmethod will return an iterator\\nyielding a namedtuple for each row in the DataFrame. The first element\\nof the tuple will be the row’s corresponding index value, while the\\nremaining values are the row values.\\\\nFor instance:\\\\nIn [271]:\\\\nfor\\\\nrow\\\\nin\\\\ndf\\\\n.\\\\nitertuples\\\\n():\\\\n.....:\\\\nprint\\\\n(\\\\nrow\\\\n)\\\\n.....:\\\\nPandas(Index=0, a=1, b=\\'a\\')\\\\nPandas(Index=1, a=2, b=\\'b\\')\\\\nPandas(Index=2, a=3, b=\\'c\\')\\\\nThis method does not convert the row to a Series object; it merely\\nreturns the values inside a namedtuple. Therefore,\\\\nitertuples()\\\\npreserves the data type of the values\\nand is generally faster as\\\\niterrows()\\\\n.\\\\nNote\\\\nThe column names will be renamed to positional names if they are\\ninvalid Python identifiers, repeated, or start with an underscore.\\nWith a large number of columns (>255), regular tuples are returned.\\\\n.dt accessor\\\\n#\\\\nSeries\\\\nhas an accessor to succinctly return datetime like properties for the\\\\nvalues\\\\nof the Series, if it is a datetime/period like Series.\\nThis will return a Series, indexed like the existing Series.\\\\n# datetime\\\\nIn [272]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101 09:10:12\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n))\\\\nIn [273]:\\\\ns\\\\nOut[273]:\\\\n0   2013-01-01 09:10:12\\\\n1   2013-01-02 09:10:12\\\\n2   2013-01-03 09:10:12\\\\n3   2013-01-04 09:10:12\\\\ndtype: datetime64[ns]\\\\nIn [274]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nhour\\\\nOut[274]:\\\\n0    9\\\\n1    9\\\\n2    9\\\\n3    9\\\\ndtype: int32\\\\nIn [275]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nsecond\\\\nOut[275]:\\\\n0    12\\\\n1    12\\\\n2    12\\\\n3    12\\\\ndtype: int32\\\\nIn [276]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nday\\\\nOut[276]:\\\\n0    1\\\\n1    2\\\\n2    3\\\\n3    4\\\\ndtype: int32\\\\nThis enables nice expressions like this:\\\\nIn [277]:\\\\ns\\\\n[\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nday\\\\n==\\\\n2\\\\n]\\\\nOut[277]:\\\\n1   2013-01-02 09:10:12\\\\ndtype: datetime64[ns]\\\\nYou can easily produces tz aware transformations:\\\\nIn [278]:\\\\nstz\\\\n=\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ntz_localize\\\\n(\\\\n\"US/Eastern\"\\\\n)\\\\nIn [279]:\\\\nstz\\\\nOut[279]:\\\\n0   2013-01-01 09:10:12-05:00\\\\n1   2013-01-02 09:10:12-05:00\\\\n2   2013-01-03 09:10:12-05:00\\\\n3   2013-01-04 09:10:12-05:00\\\\ndtype: datetime64[ns, US/Eastern]\\\\nIn [280]:\\\\nstz\\\\n.\\\\ndt\\\\n.\\\\ntz\\\\nOut[280]:\\\\n<DstTzInfo \\'US/Eastern\\' LMT-1 day, 19:04:00 STD>\\\\nYou can also chain these types of operations:\\\\nIn [281]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ntz_localize\\\\n(\\\\n\"UTC\"\\\\n)\\\\n.\\\\ndt\\\\n.\\\\ntz_convert\\\\n(\\\\n\"US/Eastern\"\\\\n)\\\\nOut[281]:\\\\n0   2013-01-01 04:10:12-05:00\\\\n1   2013-01-02 04:10:12-05:00\\\\n2   2013-01-03 04:10:12-05:00\\\\n3   2013-01-04 04:10:12-05:00\\\\ndtype: datetime64[ns, US/Eastern]\\\\nYou can also format datetime values as strings with\\\\nSeries.dt.strftime()\\\\nwhich\\nsupports the same format as the standard\\\\nstrftime()\\\\n.\\\\n# DatetimeIndex\\\\nIn [282]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n))\\\\nIn [283]:\\\\ns\\\\nOut[283]:\\\\n0   2013-01-01\\\\n1   2013-01-02\\\\n2   2013-01-03\\\\n3   2013-01-04\\\\ndtype: datetime64[ns]\\\\nIn [284]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nstrftime\\\\n(\\\\n\"%Y/%m/\\\\n%d\\\\n\"\\\\n)\\\\nOut[284]:\\\\n0    2013/01/01\\\\n1    2013/01/02\\\\n2    2013/01/03\\\\n3    2013/01/04\\\\ndtype: object\\\\n# PeriodIndex\\\\nIn [285]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\nperiod_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n))\\\\nIn [286]:\\\\ns\\\\nOut[286]:\\\\n0    2013-01-01\\\\n1    2013-01-02\\\\n2    2013-01-03\\\\n3    2013-01-04\\\\ndtype: period[D]\\\\nIn [287]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nstrftime\\\\n(\\\\n\"%Y/%m/\\\\n%d\\\\n\"\\\\n)\\\\nOut[287]:\\\\n0    2013/01/01\\\\n1    2013/01/02\\\\n2    2013/01/03\\\\n3    2013/01/04\\\\ndtype: object\\\\nThe\\\\n.dt\\\\naccessor works for period and timedelta dtypes.\\\\n# period\\\\nIn [288]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\nperiod_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n,\\\\nfreq\\\\n=\\\\n\"D\"\\\\n))\\\\nIn [289]:\\\\ns\\\\nOut[289]:\\\\n0    2013-01-01\\\\n1    2013-01-02\\\\n2    2013-01-03\\\\n3    2013-01-04\\\\ndtype: period[D]\\\\nIn [290]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nyear\\\\nOut[290]:\\\\n0    2013\\\\n1    2013\\\\n2    2013\\\\n3    2013\\\\ndtype: int64\\\\nIn [291]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nday\\\\nOut[291]:\\\\n0    1\\\\n1    2\\\\n2    3\\\\n3    4\\\\ndtype: int64\\\\n# timedelta\\\\nIn [292]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ntimedelta_range\\\\n(\\\\n\"1 day 00:00:05\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n,\\\\nfreq\\\\n=\\\\n\"s\"\\\\n))\\\\nIn [293]:\\\\ns\\\\nOut[293]:\\\\n0   1 days 00:00:05\\\\n1   1 days 00:00:06\\\\n2   1 days 00:00:07\\\\n3   1 days 00:00:08\\\\ndtype: timedelta64[ns]\\\\nIn [294]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ndays\\\\nOut[294]:\\\\n0    1\\\\n1    1\\\\n2    1\\\\n3    1\\\\ndtype: int64\\\\nIn [295]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nseconds\\\\nOut[295]:\\\\n0    5\\\\n1    6\\\\n2    7\\\\n3    8\\\\ndtype: int32\\\\nIn [296]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ncomponents\\\\nOut[296]:\\\\ndays  hours  minutes  seconds  milliseconds  microseconds  nanoseconds\\\\n0     1      0        0        5             0             0            0\\\\n1     1      0        0        6             0             0            0\\\\n2     1      0        0        7             0             0            0\\\\n3     1      0        0        8             0             0            0\\\\nNote\\\\nSeries.dt\\\\nwill raise a\\\\nTypeError\\\\nif you access with a non-datetime-like values.\\\\nVectorized string methods\\\\n#\\\\nSeries is equipped with a set of string processing methods that make it easy to\\noperate on each element of the array. Perhaps most importantly, these methods\\nexclude missing/NA values automatically. These are accessed via the Series’s\\\\nstr\\\\nattribute and generally have names matching the equivalent (scalar)\\nbuilt-in string methods. For example:\\\\nIn [297]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n.....:\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"Aaba\"\\\\n,\\\\n\"Baca\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n\"CABA\"\\\\n,\\\\n\"dog\"\\\\n,\\\\n\"cat\"\\\\n],\\\\ndtype\\\\n=\\\\n\"string\"\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [298]:\\\\ns\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n()\\\\nOut[298]:\\\\n0       a\\\\n1       b\\\\n2       c\\\\n3    aaba\\\\n4    baca\\\\n5    <NA>\\\\n6    caba\\\\n7     dog\\\\n8     cat\\\\ndtype: string\\\\nPowerful pattern-matching methods are provided as well, but note that\\npattern-matching generally uses\\\\nregular expressions\\\\nby default (and in some cases\\nalways uses them).\\\\nNote\\\\nPrior to pandas 1.0, string methods were only available on\\\\nobject\\\\n-dtype\\\\nSeries\\\\n. pandas 1.0 added the\\\\nStringDtype\\\\nwhich is dedicated\\nto strings. See\\\\nText data types\\\\nfor more.\\\\nPlease see\\\\nVectorized String Methods\\\\nfor a complete\\ndescription.\\\\nSorting\\\\n#\\\\npandas supports three kinds of sorting: sorting by index labels,\\nsorting by column values, and sorting by a combination of both.\\\\nBy index\\\\n#\\\\nThe\\\\nSeries.sort_index()\\\\nand\\\\nDataFrame.sort_index()\\\\nmethods are\\nused to sort a pandas object by its index levels.\\\\nIn [299]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"one\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]),\\\\n.....:\\\\n\"two\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n4\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n.....:\\\\n\"three\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [300]:\\\\nunsorted_df\\\\n=\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\n.....:\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"b\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [301]:\\\\nunsorted_df\\\\nOut[301]:\\\\nthree       two       one\\\\na       NaN -1.152244  0.562973\\\\nd -0.252916 -0.109597       NaN\\\\nc  1.273388 -0.167123  0.640382\\\\nb -0.098217  0.009797 -1.299504\\\\n# DataFrame\\\\nIn [302]:\\\\nunsorted_df\\\\n.\\\\nsort_index\\\\n()\\\\nOut[302]:\\\\nthree       two       one\\\\na       NaN -1.152244  0.562973\\\\nb -0.098217  0.009797 -1.299504\\\\nc  1.273388 -0.167123  0.640382\\\\nd -0.252916 -0.109597       NaN\\\\nIn [303]:\\\\nunsorted_df\\\\n.\\\\nsort_index\\\\n(\\\\nascending\\\\n=\\\\nFalse\\\\n)\\\\nOut[303]:\\\\nthree       two       one\\\\nd -0.252916 -0.109597       NaN\\\\nc  1.273388 -0.167123  0.640382\\\\nb -0.098217  0.009797 -1.299504\\\\na       NaN -1.152244  0.562973\\\\nIn [304]:\\\\nunsorted_df\\\\n.\\\\nsort_index\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[304]:\\\\none     three       two\\\\na  0.562973       NaN -1.152244\\\\nd       NaN -0.252916 -0.109597\\\\nc  0.640382  1.273388 -0.167123\\\\nb -1.299504 -0.098217  0.009797\\\\n# Series\\\\nIn [305]:\\\\nunsorted_df\\\\n[\\\\n\"three\"\\\\n]\\\\n.\\\\nsort_index\\\\n()\\\\nOut[305]:\\\\na         NaN\\\\nb   -0.098217\\\\nc    1.273388\\\\nd   -0.252916\\\\nName: three, dtype: float64\\\\nSorting by index also supports a\\\\nkey\\\\nparameter that takes a callable\\nfunction to apply to the index being sorted. For\\\\nMultiIndex\\\\nobjects,\\nthe key is applied per-level to the levels specified by\\\\nlevel\\\\n.\\\\nIn [306]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n\"B\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"C\"\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n]})\\\\n.\\\\nset_index\\\\n(\\\\n.....:\\\\nlist\\\\n(\\\\n\"ab\"\\\\n)\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [307]:\\\\ns1\\\\nOut[307]:\\\\nc\\\\na b\\\\nB 1  2\\\\na 2  3\\\\nC 3  4\\\\nIn [308]:\\\\ns1\\\\n.\\\\nsort_index\\\\n(\\\\nlevel\\\\n=\\\\n\"a\"\\\\n)\\\\nOut[308]:\\\\nc\\\\na b\\\\nB 1  2\\\\nC 3  4\\\\na 2  3\\\\nIn [309]:\\\\ns1\\\\n.\\\\nsort_index\\\\n(\\\\nlevel\\\\n=\\\\n\"a\"\\\\n,\\\\nkey\\\\n=\\\\nlambda\\\\nidx\\\\n:\\\\nidx\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n())\\\\nOut[309]:\\\\nc\\\\na b\\\\na 2  3\\\\nB 1  2\\\\nC 3  4\\\\nFor information on key sorting by value, see\\\\nvalue sorting\\\\n.\\\\nBy values\\\\n#\\\\nThe\\\\nSeries.sort_values()\\\\nmethod is used to sort a\\\\nSeries\\\\nby its values. The\\\\nDataFrame.sort_values()\\\\nmethod is used to sort a\\\\nDataFrame\\\\nby its column or row values.\\nThe optional\\\\nby\\\\nparameter to\\\\nDataFrame.sort_values()\\\\nmay used to specify one or more columns\\nto use to determine the sorted order.\\\\nIn [310]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"one\"\\\\n:\\\\n[\\\\n2\\\\n,\\\\n1\\\\n,\\\\n1\\\\n,\\\\n1\\\\n],\\\\n\"two\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n3\\\\n,\\\\n2\\\\n,\\\\n4\\\\n],\\\\n\"three\"\\\\n:\\\\n[\\\\n5\\\\n,\\\\n4\\\\n,\\\\n3\\\\n,\\\\n2\\\\n]}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [311]:\\\\ndf1\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"two\"\\\\n)\\\\nOut[311]:\\\\none  two  three\\\\n0    2    1      5\\\\n2    1    2      3\\\\n1    1    3      4\\\\n3    1    4      2\\\\nThe\\\\nby\\\\nparameter can take a list of column names, e.g.:\\\\nIn [312]:\\\\ndf1\\\\n[[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n]]\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n])\\\\nOut[312]:\\\\none  two  three\\\\n2    1    2      3\\\\n1    1    3      4\\\\n3    1    4      2\\\\n0    2    1      5\\\\nThese methods have special treatment of NA values via the\\\\nna_position\\\\nargument:\\\\nIn [313]:\\\\ns\\\\n[\\\\n2\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [314]:\\\\ns\\\\n.\\\\nsort_values\\\\n()\\\\nOut[314]:\\\\n0       A\\\\n3    Aaba\\\\n1       B\\\\n4    Baca\\\\n6    CABA\\\\n8     cat\\\\n7     dog\\\\n2    <NA>\\\\n5    <NA>\\\\ndtype: string\\\\nIn [315]:\\\\ns\\\\n.\\\\nsort_values\\\\n(\\\\nna_position\\\\n=\\\\n\"first\"\\\\n)\\\\nOut[315]:\\\\n2    <NA>\\\\n5    <NA>\\\\n0       A\\\\n3    Aaba\\\\n1       B\\\\n4    Baca\\\\n6    CABA\\\\n8     cat\\\\n7     dog\\\\ndtype: string\\\\nSorting also supports a\\\\nkey\\\\nparameter that takes a callable function\\nto apply to the values being sorted.\\\\nIn [316]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"B\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"C\"\\\\n])\\\\nIn [317]:\\\\ns1\\\\n.\\\\nsort_values\\\\n()\\\\nOut[317]:\\\\n0    B\\\\n2    C\\\\n1    a\\\\ndtype: object\\\\nIn [318]:\\\\ns1\\\\n.\\\\nsort_values\\\\n(\\\\nkey\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n())\\\\nOut[318]:\\\\n1    a\\\\n0    B\\\\n2    C\\\\ndtype: object\\\\nkey\\\\nwill be given the\\\\nSeries\\\\nof values and should return a\\\\nSeries\\\\nor array of the same shape with the transformed values. For\\\\nDataFrame\\\\nobjects,\\nthe key is applied per column, so the key should still expect a Series and return\\na Series, e.g.\\\\nIn [319]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n\"B\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"C\"\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]})\\\\nIn [320]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"a\"\\\\n)\\\\nOut[320]:\\\\na  b\\\\n0  B  1\\\\n2  C  3\\\\n1  a  2\\\\nIn [321]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"a\"\\\\n,\\\\nkey\\\\n=\\\\nlambda\\\\ncol\\\\n:\\\\ncol\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n())\\\\nOut[321]:\\\\na  b\\\\n1  a  2\\\\n0  B  1\\\\n2  C  3\\\\nThe name or type of each column can be used to apply different functions to\\ndifferent columns.\\\\nBy indexes and values\\\\n#\\\\nStrings passed as the\\\\nby\\\\nparameter to\\\\nDataFrame.sort_values()\\\\nmay\\nrefer to either columns or index level names.\\\\n# Build MultiIndex\\\\nIn [322]:\\\\nidx\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_tuples\\\\n(\\\\n.....:\\\\n[(\\\\n\"a\"\\\\n,\\\\n1\\\\n),\\\\n(\\\\n\"a\"\\\\n,\\\\n2\\\\n),\\\\n(\\\\n\"a\"\\\\n,\\\\n2\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n2\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n1\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n1\\\\n)]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [323]:\\\\nidx\\\\n.\\\\nnames\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n]\\\\n# Build DataFrame\\\\nIn [324]:\\\\ndf_multi\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n6\\\\n,\\\\n0\\\\n,\\\\n-\\\\n1\\\\n)},\\\\nindex\\\\n=\\\\nidx\\\\n)\\\\nIn [325]:\\\\ndf_multi\\\\nOut[325]:\\\\nA\\\\nfirst second\\\\na     1       6\\\\n2       5\\\\n2       4\\\\nb     2       3\\\\n1       2\\\\n1       1\\\\nSort by ‘second’ (index) and ‘A’ (column)\\\\nIn [326]:\\\\ndf_multi\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n[\\\\n\"second\"\\\\n,\\\\n\"A\"\\\\n])\\\\nOut[326]:\\\\nA\\\\nfirst second\\\\nb     1       1\\\\n1       2\\\\na     1       6\\\\nb     2       3\\\\na     2       4\\\\n2       5\\\\nNote\\\\nIf a string matches both a column name and an index level name then a\\nwarning is issued and the column takes precedence. This will result in an\\nambiguity error in a future version.\\\\nsearchsorted\\\\n#\\\\nSeries has the\\\\nsearchsorted()\\\\nmethod, which works similarly to\\\\nnumpy.ndarray.searchsorted()\\\\n.\\\\nIn [327]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n])\\\\nIn [328]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n0\\\\n,\\\\n3\\\\n])\\\\nOut[328]:\\\\narray([0, 2])\\\\nIn [329]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n0\\\\n,\\\\n4\\\\n])\\\\nOut[329]:\\\\narray([0, 3])\\\\nIn [330]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n1\\\\n,\\\\n3\\\\n],\\\\nside\\\\n=\\\\n\"right\"\\\\n)\\\\nOut[330]:\\\\narray([1, 3])\\\\nIn [331]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n1\\\\n,\\\\n3\\\\n],\\\\nside\\\\n=\\\\n\"left\"\\\\n)\\\\nOut[331]:\\\\narray([0, 2])\\\\nIn [332]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n3\\\\n,\\\\n1\\\\n,\\\\n2\\\\n])\\\\nIn [333]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n0\\\\n,\\\\n3\\\\n],\\\\nsorter\\\\n=\\\\nnp\\\\n.\\\\nargsort\\\\n(\\\\nser\\\\n))\\\\nOut[333]:\\\\narray([0, 2])\\\\nsmallest / largest values\\\\n#\\\\nSeries\\\\nhas the\\\\nnsmallest()\\\\nand\\\\nnlargest()\\\\nmethods which return the\\nsmallest or largest\\\\n\\\\(n\\\\)\\\\nvalues. For a large\\\\nSeries\\\\nthis can be much\\nfaster than sorting the entire Series and calling\\\\nhead(n)\\\\non the result.\\\\nIn [334]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\npermutation\\\\n(\\\\n10\\\\n))\\\\nIn [335]:\\\\ns\\\\nOut[335]:\\\\n0    2\\\\n1    0\\\\n2    3\\\\n3    7\\\\n4    1\\\\n5    5\\\\n6    9\\\\n7    6\\\\n8    8\\\\n9    4\\\\ndtype: int64\\\\nIn [336]:\\\\ns\\\\n.\\\\nsort_values\\\\n()\\\\nOut[336]:\\\\n1    0\\\\n4    1\\\\n0    2\\\\n2    3\\\\n9    4\\\\n5    5\\\\n7    6\\\\n3    7\\\\n8    8\\\\n6    9\\\\ndtype: int64\\\\nIn [337]:\\\\ns\\\\n.\\\\nnsmallest\\\\n(\\\\n3\\\\n)\\\\nOut[337]:\\\\n1    0\\\\n4    1\\\\n0    2\\\\ndtype: int64\\\\nIn [338]:\\\\ns\\\\n.\\\\nnlargest\\\\n(\\\\n3\\\\n)\\\\nOut[338]:\\\\n6    9\\\\n8    8\\\\n3    7\\\\ndtype: int64\\\\nDataFrame\\\\nalso has the\\\\nnlargest\\\\nand\\\\nnsmallest\\\\nmethods.\\\\nIn [339]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"a\"\\\\n:\\\\n[\\\\n-\\\\n2\\\\n,\\\\n-\\\\n1\\\\n,\\\\n1\\\\n,\\\\n10\\\\n,\\\\n8\\\\n,\\\\n11\\\\n,\\\\n-\\\\n1\\\\n],\\\\n.....:\\\\n\"b\"\\\\n:\\\\nlist\\\\n(\\\\n\"abdceff\"\\\\n),\\\\n.....:\\\\n\"c\"\\\\n:\\\\n[\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n4.0\\\\n,\\\\n3.2\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n],\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [340]:\\\\ndf\\\\n.\\\\nnlargest\\\\n(\\\\n3\\\\n,\\\\n\"a\"\\\\n)\\\\nOut[340]:\\\\na  b    c\\\\n5  11  f  3.0\\\\n3  10  c  3.2\\\\n4   8  e  NaN\\\\nIn [341]:\\\\ndf\\\\n.\\\\nnlargest\\\\n(\\\\n5\\\\n,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n])\\\\nOut[341]:\\\\na  b    c\\\\n5  11  f  3.0\\\\n3  10  c  3.2\\\\n4   8  e  NaN\\\\n2   1  d  4.0\\\\n6  -1  f  4.0\\\\nIn [342]:\\\\ndf\\\\n.\\\\nnsmallest\\\\n(\\\\n3\\\\n,\\\\n\"a\"\\\\n)\\\\nOut[342]:\\\\na  b    c\\\\n0 -2  a  1.0\\\\n1 -1  b  2.0\\\\n6 -1  f  4.0\\\\nIn [343]:\\\\ndf\\\\n.\\\\nnsmallest\\\\n(\\\\n5\\\\n,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n])\\\\nOut[343]:\\\\na  b    c\\\\n0 -2  a  1.0\\\\n1 -1  b  2.0\\\\n6 -1  f  4.0\\\\n2  1  d  4.0\\\\n4  8  e  NaN\\\\nSorting by a MultiIndex column\\\\n#\\\\nYou must be explicit about sorting when the column is a MultiIndex, and fully specify\\nall levels to\\\\nby\\\\n.\\\\nIn [344]:\\\\ndf1\\\\n.\\\\ncolumns\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_tuples\\\\n(\\\\n.....:\\\\n[(\\\\n\"a\"\\\\n,\\\\n\"one\"\\\\n),\\\\n(\\\\n\"a\"\\\\n,\\\\n\"two\"\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n\"three\"\\\\n)]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [345]:\\\\ndf1\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n(\\\\n\"a\"\\\\n,\\\\n\"two\"\\\\n))\\\\nOut[345]:\\\\na         b\\\\none two three\\\\n0   2   1     5\\\\n2   1   2     3\\\\n1   1   3     4\\\\n3   1   4     2\\\\nCopying\\\\n#\\\\nThe\\\\ncopy()\\\\nmethod on pandas objects copies the underlying data (though not\\nthe axis indexes, since they are immutable) and returns a new object. Note that\\\\nit is seldom necessary to copy objects\\\\n. For example, there are only a\\nhandful of ways to alter a DataFrame\\\\nin-place\\\\n:\\\\nInserting, deleting, or modifying a column.\\\\nAssigning to the\\\\nindex\\\\nor\\\\ncolumns\\\\nattributes.\\\\nFor homogeneous data, directly modifying the values via the\\\\nvalues\\\\nattribute or advanced indexing.\\\\nTo be clear, no pandas method has the side effect of modifying your data;\\nalmost every method returns a new object, leaving the original object\\nuntouched. If the data is modified, it is because you did so explicitly.\\\\ndtypes\\\\n#\\\\nFor the most part, pandas uses NumPy arrays and dtypes for Series or individual\\ncolumns of a DataFrame. NumPy provides support for\\\\nfloat\\\\n,\\\\nint\\\\n,\\\\nbool\\\\n,\\\\ntimedelta64[ns]\\\\nand\\\\ndatetime64[ns]\\\\n(note that NumPy\\ndoes not support timezone-aware datetimes).\\\\npandas and third-party libraries\\\\nextend\\\\nNumPy’s type system in a few places.\\nThis section describes the extensions pandas has made internally.\\nSee\\\\nExtension types\\\\nfor how to write your own extension that\\nworks with pandas. See\\\\nthe ecosystem page\\\\nfor a list of third-party\\nlibraries that have implemented an extension.\\\\nThe following table lists all of pandas extension types. For methods requiring\\\\ndtype\\\\narguments, strings can be specified as indicated. See the respective\\ndocumentation sections for more on each type.\\\\nKind of Data\\\\nData Type\\\\nScalar\\\\nArray\\\\nString Aliases\\\\ntz-aware datetime\\\\nDatetimeTZDtype\\\\nTimestamp\\\\narrays.DatetimeArray\\\\n\\'datetime64[ns,\\\\n<tz>]\\'\\\\nCategorical\\\\nCategoricalDtype\\\\n(none)\\\\nCategorical\\\\n\\'category\\'\\\\nperiod (time spans)\\\\nPeriodDtype\\\\nPeriod\\\\narrays.PeriodArray\\\\n\\'Period[<freq>]\\'\\\\n\\'period[<freq>]\\'\\\\n,\\\\nsparse\\\\nSparseDtype\\\\n(none)\\\\narrays.SparseArray\\\\n\\'Sparse\\'\\\\n,\\\\n\\'Sparse[int]\\'\\\\n,\\\\n\\'Sparse[float]\\'\\\\nintervals\\\\nIntervalDtype\\\\nInterval\\\\narrays.IntervalArray\\\\n\\'interval\\'\\\\n,\\\\n\\'Interval\\'\\\\n,\\\\n\\'Interval[<numpy_dtype>]\\'\\\\n,\\\\n\\'Interval[datetime64[ns,\\\\n<tz>]]\\'\\\\n,\\\\n\\'Interval[timedelta64[<freq>]]\\'\\\\nnullable integer\\\\nInt64Dtype\\\\n, …\\\\n(none)\\\\narrays.IntegerArray\\\\n\\'Int8\\'\\\\n,\\\\n\\'Int16\\'\\\\n,\\\\n\\'Int32\\'\\\\n,\\\\n\\'Int64\\'\\\\n,\\\\n\\'UInt8\\'\\\\n,\\\\n\\'UInt16\\'\\\\n,\\\\n\\'UInt32\\'\\\\n,\\\\n\\'UInt64\\'\\\\nnullable float\\\\nFloat64Dtype\\\\n, …\\\\n(none)\\\\narrays.FloatingArray\\\\n\\'Float32\\'\\\\n,\\\\n\\'Float64\\'\\\\nStrings\\\\nStringDtype\\\\nstr\\\\narrays.StringArray\\\\n\\'string\\'\\\\nBoolean (with NA)\\\\nBooleanDtype\\\\nbool\\\\narrays.BooleanArray\\\\n\\'boolean\\'\\\\npandas has two ways to store strings.\\\\nobject\\\\ndtype, which can hold any Python object, including strings.\\\\nStringDtype\\\\n, which is dedicated to strings.\\\\nGenerally, we recommend using\\\\nStringDtype\\\\n. See\\\\nText data types\\\\nfor more.\\\\nFinally, arbitrary objects may be stored using the\\\\nobject\\\\ndtype, but should\\nbe avoided to the extent possible (for performance and interoperability with\\nother libraries and methods. See\\\\nobject conversion\\\\n).\\\\nA convenient\\\\ndtypes\\\\nattribute for DataFrame returns a Series\\nwith the data type of each column.\\\\nIn [346]:\\\\ndft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrand\\\\n(\\\\n3\\\\n),\\\\n.....:\\\\n\"B\"\\\\n:\\\\n1\\\\n,\\\\n.....:\\\\n\"C\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n.....:\\\\n\"D\"\\\\n:\\\\npd\\\\n.\\\\nTimestamp\\\\n(\\\\n\"20010102\"\\\\n),\\\\n.....:\\\\n\"E\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1.0\\\\n]\\\\n*\\\\n3\\\\n)\\\\n.\\\\nastype\\\\n(\\\\n\"float32\"\\\\n),\\\\n.....:\\\\n\"F\"\\\\n:\\\\nFalse\\\\n,\\\\n.....:\\\\n\"G\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n]\\\\n*\\\\n3\\\\n,\\\\ndtype\\\\n=\\\\n\"int8\"\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [347]:\\\\ndft\\\\nOut[347]:\\\\nA  B    C          D    E      F  G\\\\n0  0.035962  1  foo 2001-01-02  1.0  False  1\\\\n1  0.701379  1  foo 2001-01-02  1.0  False  1\\\\n2  0.281885  1  foo 2001-01-02  1.0  False  1\\\\nIn [348]:\\\\ndft\\\\n.\\\\ndtypes\\\\nOut[348]:\\\\nA          float64\\\\nB            int64\\\\nC           object\\\\nD    datetime64[s]\\\\nE          float32\\\\nF             bool\\\\nG             int8\\\\ndtype: object\\\\nOn a\\\\nSeries\\\\nobject, use the\\\\ndtype\\\\nattribute.\\\\nIn [349]:\\\\ndft\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\ndtype\\\\nOut[349]:\\\\ndtype(\\'float64\\')\\\\nIf a pandas object contains data with multiple dtypes\\\\nin a single column\\\\n, the\\ndtype of the column will be chosen to accommodate all of the data types\\n(\\\\nobject\\\\nis the most general).\\\\n# these ints are coerced to floats\\\\nIn [350]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6.0\\\\n])\\\\nOut[350]:\\\\n0    1.0\\\\n1    2.0\\\\n2    3.0\\\\n3    4.0\\\\n4    5.0\\\\n5    6.0\\\\ndtype: float64\\\\n# string data forces an ``object`` dtype\\\\nIn [351]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n6.0\\\\n,\\\\n\"foo\"\\\\n])\\\\nOut[351]:\\\\n0      1\\\\n1      2\\\\n2      3\\\\n3    6.0\\\\n4    foo\\\\ndtype: object\\\\nThe number of columns of each type in a\\\\nDataFrame\\\\ncan be found by calling\\\\nDataFrame.dtypes.value_counts()\\\\n.\\\\nIn [352]:\\\\ndft\\\\n.\\\\ndtypes\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[352]:\\\\nfloat64          1\\\\nint64            1\\\\nobject           1\\\\ndatetime64[s]    1\\\\nfloat32          1\\\\nbool             1\\\\nint8             1\\\\nName: count, dtype: int64\\\\nNumeric dtypes will propagate and can coexist in DataFrames.\\nIf a dtype is passed (either directly via the\\\\ndtype\\\\nkeyword, a passed\\\\nndarray\\\\n,\\nor a passed\\\\nSeries\\\\n), then it will be preserved in DataFrame operations. Furthermore,\\ndifferent numeric dtypes will\\\\nNOT\\\\nbe combined. The following example will give you a taste.\\\\nIn [353]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n,\\\\n1\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n],\\\\ndtype\\\\n=\\\\n\"float32\"\\\\n)\\\\nIn [354]:\\\\ndf1\\\\nOut[354]:\\\\nA\\\\n0  0.224364\\\\n1  1.890546\\\\n2  0.182879\\\\n3  0.787847\\\\n4 -0.188449\\\\n5  0.667715\\\\n6 -0.011736\\\\n7 -0.399073\\\\nIn [355]:\\\\ndf1\\\\n.\\\\ndtypes\\\\nOut[355]:\\\\nA    float32\\\\ndtype: object\\\\nIn [356]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\ndtype\\\\n=\\\\n\"float16\"\\\\n),\\\\n.....:\\\\n\"B\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n)),\\\\n.....:\\\\n\"C\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n255\\\\n,\\\\nsize\\\\n=\\\\n8\\\\n),\\\\ndtype\\\\n=\\\\n\"uint8\"\\\\n),\\\\n# [0,255] (range of uint8)\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [357]:\\\\ndf2\\\\nOut[357]:\\\\nA         B    C\\\\n0  0.823242  0.256090   26\\\\n1  1.607422  1.426469   86\\\\n2 -0.333740 -0.416203   46\\\\n3 -0.063477  1.139976  212\\\\n4 -1.014648 -1.193477   26\\\\n5  0.678711  0.096706    7\\\\n6 -0.040863 -1.956850  184\\\\n7 -0.357422 -0.714337  206\\\\nIn [358]:\\\\ndf2\\\\n.\\\\ndtypes\\\\nOut[358]:\\\\nA    float16\\\\nB    float64\\\\nC      uint8\\\\ndtype: object\\\\ndefaults\\\\n#\\\\nBy default integer types are\\\\nint64\\\\nand float types are\\\\nfloat64\\\\n,\\\\nregardless\\\\nof platform (32-bit or 64-bit).\\nThe following will all result in\\\\nint64\\\\ndtypes.\\\\nIn [359]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\n1\\\\n,\\\\n2\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"a\"\\\\n])\\\\n.\\\\ndtypes\\\\nOut[359]:\\\\na    int64\\\\ndtype: object\\\\nIn [360]:\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]})\\\\n.\\\\ndtypes\\\\nOut[360]:\\\\na    int64\\\\ndtype: object\\\\nIn [361]:\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n1\\\\n},\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\nrange\\\\n(\\\\n2\\\\n)))\\\\n.\\\\ndtypes\\\\nOut[361]:\\\\na    int64\\\\ndtype: object\\\\nNote that Numpy will choose\\\\nplatform-dependent\\\\ntypes when creating arrays.\\nThe following\\\\nWILL\\\\nresult in\\\\nint32\\\\non 32-bit platform.\\\\nIn [362]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n1\\\\n,\\\\n2\\\\n]))\\\\nupcasting\\\\n#\\\\nTypes can potentially be\\\\nupcasted\\\\nwhen combined with other types, meaning they are promoted\\nfrom the current type (e.g.\\\\nint\\\\nto\\\\nfloat\\\\n).\\\\nIn [363]:\\\\ndf3\\\\n=\\\\ndf1\\\\n.\\\\nreindex_like\\\\n(\\\\ndf2\\\\n)\\\\n.\\\\nfillna\\\\n(\\\\nvalue\\\\n=\\\\n0.0\\\\n)\\\\n+\\\\ndf2\\\\nIn [364]:\\\\ndf3\\\\nOut[364]:\\\\nA         B      C\\\\n0  1.047606  0.256090   26.0\\\\n1  3.497968  1.426469   86.0\\\\n2 -0.150862 -0.416203   46.0\\\\n3  0.724370  1.139976  212.0\\\\n4 -1.203098 -1.193477   26.0\\\\n5  1.346426  0.096706    7.0\\\\n6 -0.052599 -1.956850  184.0\\\\n7 -0.756495 -0.714337  206.0\\\\nIn [365]:\\\\ndf3\\\\n.\\\\ndtypes\\\\nOut[365]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\nDataFrame.to_numpy()\\\\nwill return the\\\\nlower-common-denominator\\\\nof the dtypes, meaning\\nthe dtype that can accommodate\\\\nALL\\\\nof the types in the resulting homogeneous dtyped NumPy array. This can\\nforce some\\\\nupcasting\\\\n.\\\\nIn [366]:\\\\ndf3\\\\n.\\\\nto_numpy\\\\n()\\\\n.\\\\ndtype\\\\nOut[366]:\\\\ndtype(\\'float64\\')\\\\nastype\\\\n#\\\\nYou can use the\\\\nastype()\\\\nmethod to explicitly convert dtypes from one to another. These will by default return a copy,\\neven if the dtype was unchanged (pass\\\\ncopy=False\\\\nto change this behavior). In addition, they will raise an\\nexception if the astype operation is invalid.\\\\nUpcasting is always according to the\\\\nNumPy\\\\nrules. If two different dtypes are involved in an operation,\\nthen the more\\\\ngeneral\\\\none will be used as the result of the operation.\\\\nIn [367]:\\\\ndf3\\\\nOut[367]:\\\\nA         B      C\\\\n0  1.047606  0.256090   26.0\\\\n1  3.497968  1.426469   86.0\\\\n2 -0.150862 -0.416203   46.0\\\\n3  0.724370  1.139976  212.0\\\\n4 -1.203098 -1.193477   26.0\\\\n5  1.346426  0.096706    7.0\\\\n6 -0.052599 -1.956850  184.0\\\\n7 -0.756495 -0.714337  206.0\\\\nIn [368]:\\\\ndf3\\\\n.\\\\ndtypes\\\\nOut[368]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\n# conversion of dtypes\\\\nIn [369]:\\\\ndf3\\\\n.\\\\nastype\\\\n(\\\\n\"float32\"\\\\n)\\\\n.\\\\ndtypes\\\\nOut[369]:\\\\nA    float32\\\\nB    float32\\\\nC    float32\\\\ndtype: object\\\\nConvert a subset of columns to a specified type using\\\\nastype()\\\\n.\\\\nIn [370]:\\\\ndft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n7\\\\n,\\\\n8\\\\n,\\\\n9\\\\n]})\\\\nIn [371]:\\\\ndft\\\\n[[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n=\\\\ndft\\\\n[[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n.\\\\nastype\\\\n(\\\\nnp\\\\n.\\\\nuint8\\\\n)\\\\nIn [372]:\\\\ndft\\\\nOut[372]:\\\\na  b  c\\\\n0  1  4  7\\\\n1  2  5  8\\\\n2  3  6  9\\\\nIn [373]:\\\\ndft\\\\n.\\\\ndtypes\\\\nOut[373]:\\\\na    uint8\\\\nb    uint8\\\\nc    int64\\\\ndtype: object\\\\nConvert certain columns to a specific dtype by passing a dict to\\\\nastype()\\\\n.\\\\nIn [374]:\\\\ndft1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n0\\\\n,\\\\n1\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n7\\\\n,\\\\n8\\\\n,\\\\n9\\\\n]})\\\\nIn [375]:\\\\ndft1\\\\n=\\\\ndft1\\\\n.\\\\nastype\\\\n({\\\\n\"a\"\\\\n:\\\\nnp\\\\n.\\\\nbool_\\\\n,\\\\n\"c\"\\\\n:\\\\nnp\\\\n.\\\\nfloat64\\\\n})\\\\nIn [376]:\\\\ndft1\\\\nOut[376]:\\\\na  b    c\\\\n0   True  4  7.0\\\\n1  False  5  8.0\\\\n2   True  6  9.0\\\\nIn [377]:\\\\ndft1\\\\n.\\\\ndtypes\\\\nOut[377]:\\\\na       bool\\\\nb      int64\\\\nc    float64\\\\ndtype: object\\\\nNote\\\\nWhen trying to convert a subset of columns to a specified type using\\\\nastype()\\\\nand\\\\nloc()\\\\n, upcasting occurs.\\\\nloc()\\\\ntries to fit in what we are assigning to the current dtypes, while\\\\n[]\\\\nwill overwrite them taking the dtype from the right hand side. Therefore the following piece of code produces the unintended result.\\\\nIn [378]:\\\\ndft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n7\\\\n,\\\\n8\\\\n,\\\\n9\\\\n]})\\\\nIn [379]:\\\\ndft\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n.\\\\nastype\\\\n(\\\\nnp\\\\n.\\\\nuint8\\\\n)\\\\n.\\\\ndtypes\\\\nOut[379]:\\\\na    uint8\\\\nb    uint8\\\\ndtype: object\\\\nIn [380]:\\\\ndft\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n=\\\\ndft\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n.\\\\nastype\\\\n(\\\\nnp\\\\n.\\\\nuint8\\\\n)\\\\nIn [381]:\\\\ndft\\\\n.\\\\ndtypes\\\\nOut[381]:\\\\na    int64\\\\nb    int64\\\\nc    int64\\\\ndtype: object\\\\nobject conversion\\\\n#\\\\npandas offers various functions to try to force conversion of types from the\\\\nobject\\\\ndtype to other types.\\nIn cases where the data is already of the correct type, but stored in an\\\\nobject\\\\narray, the\\\\nDataFrame.infer_objects()\\\\nand\\\\nSeries.infer_objects()\\\\nmethods can be used to soft convert\\nto the correct type.\\\\nIn [382]:\\\\nimport\\\\ndatetime\\\\nIn [383]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n[\\\\n.....:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n],\\\\n.....:\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n],\\\\n.....:\\\\n[\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n),\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)],\\\\n.....:\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [384]:\\\\ndf\\\\n=\\\\ndf\\\\n.\\\\nT\\\\nIn [385]:\\\\ndf\\\\nOut[385]:\\\\n0  1                    2\\\\n0  1  a  2016-03-02 00:00:00\\\\n1  2  b  2016-03-02 00:00:00\\\\nIn [386]:\\\\ndf\\\\n.\\\\ndtypes\\\\nOut[386]:\\\\n0    object\\\\n1    object\\\\n2    object\\\\ndtype: object\\\\nBecause the data was transposed the original inference stored all columns as object, which\\\\ninfer_objects\\\\nwill correct.\\\\nIn [387]:\\\\ndf\\\\n.\\\\ninfer_objects\\\\n()\\\\n.\\\\ndtypes\\\\nOut[387]:\\\\n0             int64\\\\n1            object\\\\n2    datetime64[ns]\\\\ndtype: object\\\\nThe following functions are available for one dimensional object arrays or scalars to perform\\nhard conversion of objects to a specified type:\\\\nto_numeric()\\\\n(conversion to numeric dtypes)\\\\nIn [388]:\\\\nm\\\\n=\\\\n[\\\\n\"1.1\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]\\\\nIn [389]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n)\\\\nOut[389]:\\\\narray([1.1, 2. , 3. ])\\\\nto_datetime()\\\\n(conversion to datetime objects)\\\\nIn [390]:\\\\nimport\\\\ndatetime\\\\nIn [391]:\\\\nm\\\\n=\\\\n[\\\\n\"2016-07-09\"\\\\n,\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)]\\\\nIn [392]:\\\\npd\\\\n.\\\\nto_datetime\\\\n(\\\\nm\\\\n)\\\\nOut[392]:\\\\nDatetimeIndex([\\'2016-07-09\\', \\'2016-03-02\\'], dtype=\\'datetime64[ns]\\', freq=None)\\\\nto_timedelta()\\\\n(conversion to timedelta objects)\\\\nIn [393]:\\\\nm\\\\n=\\\\n[\\\\n\"5us\"\\\\n,\\\\npd\\\\n.\\\\nTimedelta\\\\n(\\\\n\"1day\"\\\\n)]\\\\nIn [394]:\\\\npd\\\\n.\\\\nto_timedelta\\\\n(\\\\nm\\\\n)\\\\nOut[394]:\\\\nTimedeltaIndex([\\'0 days 00:00:00.000005\\', \\'1 days 00:00:00\\'], dtype=\\'timedelta64[ns]\\', freq=None)\\\\nTo force a conversion, we can pass in an\\\\nerrors\\\\nargument, which specifies how pandas should deal with elements\\nthat cannot be converted to desired dtype or object. By default,\\\\nerrors=\\'raise\\'\\\\n, meaning that any errors encountered\\nwill be raised during the conversion process. However, if\\\\nerrors=\\'coerce\\'\\\\n, these errors will be ignored and pandas\\nwill convert problematic elements to\\\\npd.NaT\\\\n(for datetime and timedelta) or\\\\nnp.nan\\\\n(for numeric). This might be\\nuseful if you are reading in data which is mostly of the desired dtype (e.g. numeric, datetime), but occasionally has\\nnon-conforming elements intermixed that you want to represent as missing:\\\\nIn [395]:\\\\nimport\\\\ndatetime\\\\nIn [396]:\\\\nm\\\\n=\\\\n[\\\\n\"apple\"\\\\n,\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)]\\\\nIn [397]:\\\\npd\\\\n.\\\\nto_datetime\\\\n(\\\\nm\\\\n,\\\\nerrors\\\\n=\\\\n\"coerce\"\\\\n)\\\\nOut[397]:\\\\nDatetimeIndex([\\'NaT\\', \\'2016-03-02\\'], dtype=\\'datetime64[ns]\\', freq=None)\\\\nIn [398]:\\\\nm\\\\n=\\\\n[\\\\n\"apple\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]\\\\nIn [399]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\nerrors\\\\n=\\\\n\"coerce\"\\\\n)\\\\nOut[399]:\\\\narray([nan,  2.,  3.])\\\\nIn [400]:\\\\nm\\\\n=\\\\n[\\\\n\"apple\"\\\\n,\\\\npd\\\\n.\\\\nTimedelta\\\\n(\\\\n\"1day\"\\\\n)]\\\\nIn [401]:\\\\npd\\\\n.\\\\nto_timedelta\\\\n(\\\\nm\\\\n,\\\\nerrors\\\\n=\\\\n\"coerce\"\\\\n)\\\\nOut[401]:\\\\nTimedeltaIndex([NaT, \\'1 days\\'], dtype=\\'timedelta64[ns]\\', freq=None)\\\\nIn addition to object conversion,\\\\nto_numeric()\\\\nprovides another argument\\\\ndowncast\\\\n, which gives the\\noption of downcasting the newly (or already) numeric data to a smaller dtype, which can conserve memory:\\\\nIn [402]:\\\\nm\\\\n=\\\\n[\\\\n\"1\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]\\\\nIn [403]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"integer\"\\\\n)\\\\n# smallest signed int dtype\\\\nOut[403]:\\\\narray([1, 2, 3], dtype=int8)\\\\nIn [404]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"signed\"\\\\n)\\\\n# same as \\'integer\\'\\\\nOut[404]:\\\\narray([1, 2, 3], dtype=int8)\\\\nIn [405]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"unsigned\"\\\\n)\\\\n# smallest unsigned int dtype\\\\nOut[405]:\\\\narray([1, 2, 3], dtype=uint8)\\\\nIn [406]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"float\"\\\\n)\\\\n# smallest float dtype\\\\nOut[406]:\\\\narray([1., 2., 3.], dtype=float32)\\\\nAs these methods apply only to one-dimensional arrays, lists or scalars; they cannot be used directly on multi-dimensional objects such\\nas DataFrames. However, with\\\\napply()\\\\n, we can “apply” the function over each column efficiently:\\\\nIn [407]:\\\\nimport\\\\ndatetime\\\\nIn [408]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n\"2016-07-09\"\\\\n,\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)]]\\\\n*\\\\n2\\\\n,\\\\ndtype\\\\n=\\\\n\"O\"\\\\n)\\\\nIn [409]:\\\\ndf\\\\nOut[409]:\\\\n0                    1\\\\n0  2016-07-09  2016-03-02 00:00:00\\\\n1  2016-07-09  2016-03-02 00:00:00\\\\nIn [410]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nto_datetime\\\\n)\\\\nOut[410]:\\\\n0          1\\\\n0 2016-07-09 2016-03-02\\\\n1 2016-07-09 2016-03-02\\\\nIn [411]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n\"1.1\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]]\\\\n*\\\\n2\\\\n,\\\\ndtype\\\\n=\\\\n\"O\"\\\\n)\\\\nIn [412]:\\\\ndf\\\\nOut[412]:\\\\n0  1  2\\\\n0  1.1  2  3\\\\n1  1.1  2  3\\\\nIn [413]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nto_numeric\\\\n)\\\\nOut[413]:\\\\n0  1  2\\\\n0  1.1  2  3\\\\n1  1.1  2  3\\\\nIn [414]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n\"5us\"\\\\n,\\\\npd\\\\n.\\\\nTimedelta\\\\n(\\\\n\"1day\"\\\\n)]]\\\\n*\\\\n2\\\\n,\\\\ndtype\\\\n=\\\\n\"O\"\\\\n)\\\\nIn [415]:\\\\ndf\\\\nOut[415]:\\\\n0                1\\\\n0  5us  1 days 00:00:00\\\\n1  5us  1 days 00:00:00\\\\nIn [416]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nto_timedelta\\\\n)\\\\nOut[416]:\\\\n0      1\\\\n0 0 days 00:00:00.000005 1 days\\\\n1 0 days 00:00:00.000005 1 days\\\\ngotchas\\\\n#\\\\nPerforming selection operations on\\\\ninteger\\\\ntype data can easily upcast the data to\\\\nfloating\\\\n.\\nThe dtype of the input data will be preserved in cases where\\\\nnans\\\\nare not introduced.\\nSee also\\\\nSupport for integer NA\\\\n.\\\\nIn [417]:\\\\ndfi\\\\n=\\\\ndf3\\\\n.\\\\nastype\\\\n(\\\\n\"int32\"\\\\n)\\\\nIn [418]:\\\\ndfi\\\\n[\\\\n\"E\"\\\\n]\\\\n=\\\\n1\\\\nIn [419]:\\\\ndfi\\\\nOut[419]:\\\\nA  B    C  E\\\\n0  1  0   26  1\\\\n1  3  1   86  1\\\\n2  0  0   46  1\\\\n3  0  1  212  1\\\\n4 -1 -1   26  1\\\\n5  1  0    7  1\\\\n6  0 -1  184  1\\\\n7  0  0  206  1\\\\nIn [420]:\\\\ndfi\\\\n.\\\\ndtypes\\\\nOut[420]:\\\\nA    int32\\\\nB    int32\\\\nC    int32\\\\nE    int64\\\\ndtype: object\\\\nIn [421]:\\\\ncasted\\\\n=\\\\ndfi\\\\n[\\\\ndfi\\\\n>\\\\n0\\\\n]\\\\nIn [422]:\\\\ncasted\\\\nOut[422]:\\\\nA    B    C  E\\\\n0  1.0  NaN   26  1\\\\n1  3.0  1.0   86  1\\\\n2  NaN  NaN   46  1\\\\n3  NaN  1.0  212  1\\\\n4  NaN  NaN   26  1\\\\n5  1.0  NaN    7  1\\\\n6  NaN  NaN  184  1\\\\n7  NaN  NaN  206  1\\\\nIn [423]:\\\\ncasted\\\\n.\\\\ndtypes\\\\nOut[423]:\\\\nA    float64\\\\nB    float64\\\\nC      int32\\\\nE      int64\\\\ndtype: object\\\\nWhile float dtypes are unchanged.\\\\nIn [424]:\\\\ndfa\\\\n=\\\\ndf3\\\\n.\\\\ncopy\\\\n()\\\\nIn [425]:\\\\ndfa\\\\n[\\\\n\"A\"\\\\n]\\\\n=\\\\ndfa\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nastype\\\\n(\\\\n\"float32\"\\\\n)\\\\nIn [426]:\\\\ndfa\\\\n.\\\\ndtypes\\\\nOut[426]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\nIn [427]:\\\\ncasted\\\\n=\\\\ndfa\\\\n[\\\\ndf2\\\\n>\\\\n0\\\\n]\\\\nIn [428]:\\\\ncasted\\\\nOut[428]:\\\\nA         B      C\\\\n0  1.047606  0.256090   26.0\\\\n1  3.497968  1.426469   86.0\\\\n2       NaN       NaN   46.0\\\\n3       NaN  1.139976  212.0\\\\n4       NaN       NaN   26.0\\\\n5  1.346426  0.096706    7.0\\\\n6       NaN       NaN  184.0\\\\n7       NaN       NaN  206.0\\\\nIn [429]:\\\\ncasted\\\\n.\\\\ndtypes\\\\nOut[429]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\nSelecting columns based on\\\\ndtype\\\\n#\\\\nThe\\\\nselect_dtypes()\\\\nmethod implements subsetting of columns\\nbased on their\\\\ndtype\\\\n.\\\\nFirst, let’s create a\\\\nDataFrame\\\\nwith a slew of different\\ndtypes:\\\\nIn [430]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"string\"\\\\n:\\\\nlist\\\\n(\\\\n\"abc\"\\\\n),\\\\n.....:\\\\n\"int64\"\\\\n:\\\\nlist\\\\n(\\\\nrange\\\\n(\\\\n1\\\\n,\\\\n4\\\\n)),\\\\n.....:\\\\n\"uint8\"\\\\n:\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n3\\\\n,\\\\n6\\\\n)\\\\n.\\\\nastype\\\\n(\\\\n\"u1\"\\\\n),\\\\n.....:\\\\n\"float64\"\\\\n:\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n4.0\\\\n,\\\\n7.0\\\\n),\\\\n.....:\\\\n\"bool1\"\\\\n:\\\\n[\\\\nTrue\\\\n,\\\\nFalse\\\\n,\\\\nTrue\\\\n],\\\\n.....:\\\\n\"bool2\"\\\\n:\\\\n[\\\\nFalse\\\\n,\\\\nTrue\\\\n,\\\\nFalse\\\\n],\\\\n.....:\\\\n\"dates\"\\\\n:\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"now\"\\\\n,\\\\nperiods\\\\n=\\\\n3\\\\n),\\\\n.....:\\\\n\"category\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nlist\\\\n(\\\\n\"ABC\"\\\\n))\\\\n.\\\\nastype\\\\n(\\\\n\"category\"\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [431]:\\\\ndf\\\\n[\\\\n\"tdeltas\"\\\\n]\\\\n=\\\\ndf\\\\n.\\\\ndates\\\\n.\\\\ndiff\\\\n()\\\\nIn [432]:\\\\ndf\\\\n[\\\\n\"uint64\"\\\\n]\\\\n=\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n3\\\\n,\\\\n6\\\\n)\\\\n.\\\\nastype\\\\n(\\\\n\"u8\"\\\\n)\\\\nIn [433]:\\\\ndf\\\\n[\\\\n\"other_dates\"\\\\n]\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n3\\\\n)\\\\nIn [434]:\\\\ndf\\\\n[\\\\n\"tz_aware_dates\"\\\\n]\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n3\\\\n,\\\\ntz\\\\n=\\\\n\"US/Eastern\"\\\\n)\\\\nIn [435]:\\\\ndf\\\\nOut[435]:\\\\nstring  int64  uint8  ...  uint64  other_dates            tz_aware_dates\\\\n0      a      1      3  ...       3   2013-01-01 2013-01-01 00:00:00-05:00\\\\n1      b      2      4  ...       4   2013-01-02 2013-01-02 00:00:00-05:00\\\\n2      c      3      5  ...       5   2013-01-03 2013-01-03 00:00:00-05:00\\\\n[3 rows x 12 columns]\\\\nAnd the dtypes:\\\\nIn [436]:\\\\ndf\\\\n.\\\\ndtypes\\\\nOut[436]:\\\\nstring                                object\\\\nint64                                  int64\\\\nuint8                                  uint8\\\\nfloat64                              float64\\\\nbool1                                   bool\\\\nbool2                                   bool\\\\ndates                         datetime64[ns]\\\\ncategory                            category\\\\ntdeltas                      timedelta64[ns]\\\\nuint64                                uint64\\\\nother_dates                   datetime64[ns]\\\\ntz_aware_dates    datetime64[ns, US/Eastern]\\\\ndtype: object\\\\nselect_dtypes()\\\\nhas two parameters\\\\ninclude\\\\nand\\\\nexclude\\\\nthat allow you to\\nsay “give me the columns\\\\nwith\\\\nthese dtypes” (\\\\ninclude\\\\n) and/or “give the\\ncolumns\\\\nwithout\\\\nthese dtypes” (\\\\nexclude\\\\n).\\\\nFor example, to select\\\\nbool\\\\ncolumns:\\\\nIn [437]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\nbool\\\\n])\\\\nOut[437]:\\\\nbool1  bool2\\\\n0   True  False\\\\n1  False   True\\\\n2   True  False\\\\nYou can also pass the name of a dtype in the\\\\nNumPy dtype hierarchy\\\\n:\\\\nIn [438]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"bool\"\\\\n])\\\\nOut[438]:\\\\nbool1  bool2\\\\n0   True  False\\\\n1  False   True\\\\n2   True  False\\\\nselect_dtypes()\\\\nalso works with generic dtypes as well.\\\\nFor example, to select all numeric and boolean columns while excluding unsigned\\nintegers:\\\\nIn [439]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"number\"\\\\n,\\\\n\"bool\"\\\\n],\\\\nexclude\\\\n=\\\\n[\\\\n\"unsignedinteger\"\\\\n])\\\\nOut[439]:\\\\nint64  float64  bool1  bool2 tdeltas\\\\n0      1      4.0   True  False     NaT\\\\n1      2      5.0  False   True  1 days\\\\n2      3      6.0   True  False  1 days\\\\nTo select string columns you must use the\\\\nobject\\\\ndtype:\\\\nIn [440]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"object\"\\\\n])\\\\nOut[440]:\\\\nstring\\\\n0      a\\\\n1      b\\\\n2      c\\\\nTo see all the child dtypes of a generic\\\\ndtype\\\\nlike\\\\nnumpy.number\\\\nyou\\ncan define a function that returns a tree of child dtypes:\\\\nIn [441]:\\\\ndef\\\\nsubdtypes\\\\n(\\\\ndtype\\\\n):\\\\n.....:\\\\nsubs\\\\n=\\\\ndtype\\\\n.\\\\n__subclasses__\\\\n()\\\\n.....:\\\\nif\\\\nnot\\\\nsubs\\\\n:\\\\n.....:\\\\nreturn\\\\ndtype\\\\n.....:\\\\nreturn\\\\n[\\\\ndtype\\\\n,\\\\n[\\\\nsubdtypes\\\\n(\\\\ndt\\\\n)\\\\nfor\\\\ndt\\\\nin\\\\nsubs\\\\n]]\\\\n.....:\\\\nAll NumPy dtypes are subclasses of\\\\nnumpy.generic\\\\n:\\\\nIn [442]:\\\\nsubdtypes\\\\n(\\\\nnp\\\\n.\\\\ngeneric\\\\n)\\\\nOut[442]:\\\\n[numpy.generic,\\\\n[[numpy.number,\\\\n[[numpy.integer,\\\\n[[numpy.signedinteger,\\\\n[numpy.int8,\\\\nnumpy.int16,\\\\nnumpy.int32,\\\\nnumpy.int64,\\\\nnumpy.longlong,\\\\nnumpy.timedelta64]],\\\\n[numpy.unsignedinteger,\\\\n[numpy.uint8,\\\\nnumpy.uint16,\\\\nnumpy.uint32,\\\\nnumpy.uint64,\\\\nnumpy.ulonglong]]]],\\\\n[numpy.inexact,\\\\n[[numpy.floating,\\\\n[numpy.float16, numpy.float32, numpy.float64, numpy.longdouble]],\\\\n[numpy.complexfloating,\\\\n[numpy.complex64, numpy.complex128, numpy.clongdouble]]]]]],\\\\n[numpy.flexible,\\\\n[[numpy.character, [numpy.bytes_, numpy.str_]],\\\\n[numpy.void, [numpy.record]]]],\\\\nnumpy.bool_,\\\\nnumpy.datetime64,\\\\nnumpy.object_]]\\\\nNote\\\\npandas also defines the types\\\\ncategory\\\\n, and\\\\ndatetime64[ns,\\\\ntz]\\\\n, which are not integrated into the normal\\nNumPy hierarchy and won’t show up with the above function.\\\\nprevious\\\\nIntro to data structures\\\\nnext\\\\nIO tools (text, CSV, HDF5, …)\\\\nOn this page\\\\nHead and tail\\\\nAttributes and underlying data\\\\nAccelerated operations\\\\nFlexible binary operations\\\\nMatching / broadcasting behavior\\\\nMissing data / operations with fill values\\\\nFlexible comparisons\\\\nBoolean reductions\\\\nComparing if objects are equivalent\\\\nComparing array-like objects\\\\nCombining overlapping data sets\\\\nGeneral DataFrame combine\\\\nDescriptive statistics\\\\nSummarizing data: describe\\\\nIndex of min/max values\\\\nValue counts (histogramming) / mode\\\\nDiscretization and quantiling\\\\nFunction application\\\\nTablewise function application\\\\nRow or column-wise function application\\\\nAggregation API\\\\nAggregating with multiple functions\\\\nAggregating with a dict\\\\nCustom describe\\\\nTransform API\\\\nTransform with multiple functions\\\\nTransforming with a dict\\\\nApplying elementwise functions\\\\nReindexing and altering labels\\\\nReindexing to align with another object\\\\nAligning objects with each other with\\\\nalign\\\\nFilling while reindexing\\\\nLimits on filling while reindexing\\\\nDropping labels from an axis\\\\nRenaming / mapping labels\\\\nIteration\\\\nitems\\\\niterrows\\\\nitertuples\\\\n.dt accessor\\\\nVectorized string methods\\\\nSorting\\\\nBy index\\\\nBy values\\\\nBy indexes and values\\\\nsearchsorted\\\\nsmallest / largest values\\\\nSorting by a MultiIndex column\\\\nCopying\\\\ndtypes\\\\ndefaults\\\\nupcasting\\\\nastype\\\\nobject conversion\\\\ngotchas\\\\nSelecting columns based on\\\\ndtype\\\\nShow Source\\\\n\\\\n--- Page Break ---\\\\n\\\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "699ec512-c130-4a84-b89b-9a16f2e98956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name=\"cl100k_base\",\n",
    "    chunk_size=100,\n",
    "    chunk_overlap=0\n",
    ")\n",
    "texts = text_splitter.split_text(docs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a51b3d37-d4b1-49b1-8876-7b3cb6e5b10e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User Guide\\\\n10 minutes to pandas\\\\n10 minutes to pandas\\\\n#\\\\nThis is a short introduction to pandas, geared mainly for new users.\\nYou can see more complex recipes in the\\\\nCookbook\\\\n.\\\\nCustomarily, we import as follows:\\\\nIn [1]:\\\\nimport\\\\nnumpy\\\\nas\\\\nnp\\\\nIn [2]:\\\\nimport\\\\npandas\\\\nas\\\\npd\\\\nBasic data structures in pandas\\\\n#\\\\nPandas provides two types of classes for handling data:\\\\nSeries\\\\n: a one-dimensional labeled array holding data of any type\\\\nsuch as integers, strings, Python objects etc.\\\\nDataFrame\\\\n: a two-dimensional data structure that holds data like\\na two-dimension array or a table with rows and columns.\\\\nObject creation\\\\n#\\\\nSee the\\\\nIntro to data structures section\\\\n.\\\\nCreating a\\\\nSeries\\\\nby passing a list of values, letting pandas create\\na default\\\\nRangeIndex\\\\n.\\\\nIn [3]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n3\\\\n,\\\\n5\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n6\\\\n,\\\\n8\\\\n])\\\\nIn [4]:\\\\ns\\\\nOut[4]:\\\\n0    1.0\\\\n1    3.0\\\\n2    5.0\\\\n3    NaN\\\\n4    6.0\\\\n5    8.0\\\\ndtype: float64\\\\nCreating a\\\\nDataFrame\\\\nby passing a NumPy array with a datetime index using\\\\ndate_range()\\\\nand labeled columns:\\\\nIn [5]:\\\\ndates\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n6\\\\n)\\\\nIn [6]:\\\\ndates\\\\nOut[6]:\\\\nDatetimeIndex([\\'2013-01-01\\', \\'2013-01-02\\', \\'2013-01-03\\', \\'2013-01-04\\',\\\\n\\'2013-01-05\\', \\'2013-01-06\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=\\'D\\')\\\\nIn [7]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n6\\\\n,\\\\n4\\\\n),\\\\nindex\\\\n=\\\\ndates\\\\n,\\\\ncolumns\\\\n=\\\\nlist\\\\n(\\\\n\"ABCD\"\\\\n))\\\\nIn [8]:\\\\ndf\\\\nOut[8]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988\\\\nCreating a\\\\nDataFrame\\\\nby passing a dictionary of objects where the keys are the column\\nlabels and the values are the column values.\\\\nIn [9]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n...:\\\\n{\\\\n...:\\\\n\"A\"\\\\n:\\\\n1.0\\\\n,\\\\n...:\\\\n\"B\"\\\\n:\\\\npd\\\\n.\\\\nTimestamp\\\\n(\\\\n\"20130102\"\\\\n),\\\\n...:\\\\n\"C\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n1\\\\n,\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\nrange\\\\n(\\\\n4\\\\n)),\\\\ndtype\\\\n=\\\\n\"float32\"\\\\n),\\\\n...:\\\\n\"D\"\\\\n:\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n3\\\\n]\\\\n*\\\\n4\\\\n,\\\\ndtype\\\\n=\\\\n\"int32\"\\\\n),\\\\n...:\\\\n\"E\"\\\\n:\\\\npd\\\\n.\\\\nCategorical\\\\n([\\\\n\"test\"\\\\n,\\\\n\"train\"\\\\n,\\\\n\"test\"\\\\n,\\\\n\"train\"\\\\n]),\\\\n...:\\\\n\"F\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n...:\\\\n}\\\\n...:\\\\n)\\\\n...:\\\\nIn [10]:\\\\ndf2\\\\nOut[10]:\\\\nA          B    C  D      E    F\\\\n0  1.0 2013-01-02  1.0  3   test  foo\\\\n1  1.0 2013-01-02  1.0  3  train  foo\\\\n2  1.0 2013-01-02  1.0  3   test  foo\\\\n3  1.0 2013-01-02  1.0  3  train  foo\\\\nThe columns of the resulting\\\\nDataFrame\\\\nhave different\\\\ndtypes\\\\n:\\\\nIn [11]:\\\\ndf2\\\\n.\\\\ndtypes\\\\nOut[11]:\\\\nA          float64\\\\nB    datetime64[s]\\\\nC          float32\\\\nD            int32\\\\nE         category\\\\nF           object\\\\ndtype: object\\\\nIf you’re using IPython, tab completion for column names (as well as public\\nattributes) is automatically enabled. Here’s a subset of the attributes that\\nwill be completed:\\\\nIn [12]:\\\\ndf2\\\\n.<\\\\nTAB\\\\n>\\\\n# noqa: E225, E999\\\\ndf2.A                  df2.bool\\\\ndf2.abs                df2.boxplot\\\\ndf2.add                df2.C\\\\ndf2.add_prefix         df2.clip\\\\ndf2.add_suffix         df2.columns\\\\ndf2.align              df2.copy\\\\ndf2.all                df2.count\\\\ndf2.any                df2.combine\\\\ndf2.append             df2.D\\\\ndf2.apply              df2.describe\\\\ndf2.applymap           df2.diff\\\\ndf2.B                  df2.duplicated\\\\nAs you can see, the columns\\\\nA\\\\n,\\\\nB\\\\n,\\\\nC\\\\n, and\\\\nD\\\\nare automatically\\ntab completed.\\\\nE\\\\nand\\\\nF\\\\nare there as well; the rest of the attributes have been\\ntruncated for brevity.\\\\nViewing data\\\\n#\\\\nSee the\\\\nEssentially basics functionality section\\\\n.\\\\nUse\\\\nDataFrame.head()\\\\nand\\\\nDataFrame.tail()\\\\nto view the top and bottom rows of the frame\\nrespectively:\\\\nIn [13]:\\\\ndf\\\\n.\\\\nhead\\\\n()\\\\nOut[13]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\nIn [14]:\\\\ndf\\\\n.\\\\ntail\\\\n(\\\\n3\\\\n)\\\\nOut[14]:\\\\nA         B         C         D\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988\\\\nDisplay the\\\\nDataFrame.index\\\\nor\\\\nDataFrame.columns\\\\n:\\\\nIn [15]:\\\\ndf\\\\n.\\\\nindex\\\\nOut[15]:\\\\nDatetimeIndex([\\'2013-01-01\\', \\'2013-01-02\\', \\'2013-01-03\\', \\'2013-01-04\\',\\\\n\\'2013-01-05\\', \\'2013-01-06\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=\\'D\\')\\\\nIn [16]:\\\\ndf\\\\n.\\\\ncolumns\\\\nOut[16]:\\\\nIndex([\\'A\\', \\'B\\', \\'C\\', \\'D\\'], dtype=\\'object\\')\\\\nReturn a NumPy representation of the underlying data with\\\\nDataFrame.to_numpy()\\\\nwithout the index or column labels:\\\\nIn [17]:\\\\ndf\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[17]:\\\\narray([[ 0.4691, -0.2829, -1.5091, -1.1356],\\\\n[ 1.2121, -0.1732,  0.1192, -1.0442],\\\\n[-0.8618, -2.1046, -0.4949,  1.0718],\\\\n[ 0.7216, -0.7068, -1.0396,  0.2719],\\\\n[-0.425 ,  0.567 ,  0.2762, -1.0874],\\\\n[-0.6737,  0.1136, -1.4784,  0.525 ]])\\\\nNote\\\\nNumPy arrays have one dtype for the entire array while pandas DataFrames\\nhave one dtype per column\\\\n. When you call\\\\nDataFrame.to_numpy()\\\\n, pandas will\\nfind the NumPy dtype that can hold\\\\nall\\\\nof the dtypes in the DataFrame.\\nIf the common data type is\\\\nobject\\\\n,\\\\nDataFrame.to_numpy()\\\\nwill require\\ncopying data.\\\\nIn [18]:\\\\ndf2\\\\n.\\\\ndtypes\\\\nOut[18]:\\\\nA          float64\\\\nB    datetime64[s]\\\\nC          float32\\\\nD            int32\\\\nE         category\\\\nF           object\\\\ndtype: object\\\\nIn [19]:\\\\ndf2\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[19]:\\\\narray([[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'test\\', \\'foo\\'],\\\\n[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'train\\', \\'foo\\'],\\\\n[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'test\\', \\'foo\\'],\\\\n[1.0, Timestamp(\\'2013-01-02 00:00:00\\'), 1.0, 3, \\'train\\', \\'foo\\']],\\\\ndtype=object)\\\\ndescribe()\\\\nshows a quick statistic summary of your data:\\\\nIn [20]:\\\\ndf\\\\n.\\\\ndescribe\\\\n()\\\\nOut[20]:\\\\nA         B         C         D\\\\ncount  6.000000  6.000000  6.000000  6.000000\\\\nmean   0.073711 -0.431125 -0.687758 -0.233103\\\\nstd    0.843157  0.922818  0.779887  0.973118\\\\nmin   -0.861849 -2.104569 -1.509059 -1.135632\\\\n25%   -0.611510 -0.600794 -1.368714 -1.076610\\\\n50%    0.022070 -0.228039 -0.767252 -0.386188\\\\n75%    0.658444  0.041933 -0.034326  0.461706\\\\nmax    1.212112  0.567020  0.276232  1.071804\\\\nTransposing your data:\\\\nIn [21]:\\\\ndf\\\\n.\\\\nT\\\\nOut[21]:\\\\n2013-01-01  2013-01-02  2013-01-03  2013-01-04  2013-01-05  2013-01-06\\\\nA    0.469112    1.212112   -0.861849    0.721555   -0.424972   -0.673690\\\\nB   -0.282863   -0.173215   -2.104569   -0.706771    0.567020    0.113648\\\\nC   -1.509059    0.119209   -0.494929   -1.039575    0.276232   -1.478427\\\\nD   -1.135632   -1.044236    1.071804    0.271860   -1.087401    0.524988\\\\nDataFrame.sort_index()\\\\nsorts by an axis:\\\\nIn [22]:\\\\ndf\\\\n.\\\\nsort_index\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n,\\\\nascending\\\\n=\\\\nFalse\\\\n)\\\\nOut[22]:\\\\nD         C         B         A\\\\n2013-01-01 -1.135632 -1.509059 -0.282863  0.469112\\\\n2013-01-02 -1.044236  0.119209 -0.173215  1.212112\\\\n2013-01-03  1.071804 -0.494929 -2.104569 -0.861849\\\\n2013-01-04  0.271860 -1.039575 -0.706771  0.721555\\\\n2013-01-05 -1.087401  0.276232  0.567020 -0.424972\\\\n2013-01-06  0.524988 -1.478427  0.113648 -0.673690\\\\nDataFrame.sort_values()\\\\nsorts by values:\\\\nIn [23]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"B\"\\\\n)\\\\nOut[23]:\\\\nA         B         C         D\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401\\\\nSelection\\\\n#\\\\nNote\\\\nWhile standard Python / NumPy expressions for selecting and setting are\\nintuitive and come in handy for interactive work, for production code, we\\nrecommend the optimized pandas data access methods,\\\\nDataFrame.at()\\\\n,\\\\nDataFrame.iat()\\\\n,\\\\nDataFrame.loc()\\\\nand\\\\nDataFrame.iloc()\\\\n.\\\\nSee the indexing documentation\\\\nIndexing and Selecting Data\\\\nand\\\\nMultiIndex / Advanced Indexing\\\\n.\\\\nGetitem (\\\\n[]\\\\n)\\\\n#\\\\nFor a\\\\nDataFrame\\\\n, passing a single label selects a columns and\\nyields a\\\\nSeries\\\\nequivalent to\\\\ndf.A\\\\n:\\\\nIn [24]:\\\\ndf\\\\n[\\\\n\"A\"\\\\n]\\\\nOut[24]:\\\\n2013-01-01    0.469112\\\\n2013-01-02    1.212112\\\\n2013-01-03   -0.861849\\\\n2013-01-04    0.721555\\\\n2013-01-05   -0.424972\\\\n2013-01-06   -0.673690\\\\nFreq: D, Name: A, dtype: float64\\\\nFor a\\\\nDataFrame\\\\n, passing a slice\\\\n:\\\\nselects matching rows:\\\\nIn [25]:\\\\ndf\\\\n[\\\\n0\\\\n:\\\\n3\\\\n]\\\\nOut[25]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\nIn [26]:\\\\ndf\\\\n[\\\\n\"20130102\"\\\\n:\\\\n\"20130104\"\\\\n]\\\\nOut[26]:\\\\nA         B         C         D\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\nSelection by label\\\\n#\\\\nSee more in\\\\nSelection by Label\\\\nusing\\\\nDataFrame.loc()\\\\nor\\\\nDataFrame.at()\\\\n.\\\\nSelecting a row matching a label:\\\\nIn [27]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n]]\\\\nOut[27]:\\\\nA    0.469112\\\\nB   -0.282863\\\\nC   -1.509059\\\\nD   -1.135632\\\\nName: 2013-01-01 00:00:00, dtype: float64\\\\nSelecting all rows (\\\\n:\\\\n) with a select column labels:\\\\nIn [28]:\\\\ndf\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n]]\\\\nOut[28]:\\\\nA         B\\\\n2013-01-01  0.469112 -0.282863\\\\n2013-01-02  1.212112 -0.173215\\\\n2013-01-03 -0.861849 -2.104569\\\\n2013-01-04  0.721555 -0.706771\\\\n2013-01-05 -0.424972  0.567020\\\\n2013-01-06 -0.673690  0.113648\\\\nFor label slicing, both endpoints are\\\\nincluded\\\\n:\\\\nIn [29]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\n\"20130102\"\\\\n:\\\\n\"20130104\"\\\\n,\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n]]\\\\nOut[29]:\\\\nA         B\\\\n2013-01-02  1.212112 -0.173215\\\\n2013-01-03 -0.861849 -2.104569\\\\n2013-01-04  0.721555 -0.706771\\\\nSelecting a single row and column label returns a scalar:\\\\nIn [30]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n],\\\\n\"A\"\\\\n]\\\\nOut[30]:\\\\n0.4691122999071863\\\\nFor getting fast access to a scalar (equivalent to the prior method):\\\\nIn [31]:\\\\ndf\\\\n.\\\\nat\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n],\\\\n\"A\"\\\\n]\\\\nOut[31]:\\\\n0.4691122999071863\\\\nSelection by position\\\\n#\\\\nSee more in\\\\nSelection by Position\\\\nusing\\\\nDataFrame.iloc()\\\\nor\\\\nDataFrame.iat()\\\\n.\\\\nSelect via the position of the passed integers:\\\\nIn [32]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n]\\\\nOut[32]:\\\\nA    0.721555\\\\nB   -0.706771\\\\nC   -1.039575\\\\nD    0.271860\\\\nName: 2013-01-04 00:00:00, dtype: float64\\\\nInteger slices acts similar to NumPy/Python:\\\\nIn [33]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n5\\\\n,\\\\n0\\\\n:\\\\n2\\\\n]\\\\nOut[33]:\\\\nA         B\\\\n2013-01-04  0.721555 -0.706771\\\\n2013-01-05 -0.424972  0.567020\\\\nLists of integer position locations:\\\\nIn [34]:\\\\ndf\\\\n.\\\\niloc\\\\n[[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n4\\\\n],\\\\n[\\\\n0\\\\n,\\\\n2\\\\n]]\\\\nOut[34]:\\\\nA         C\\\\n2013-01-02  1.212112  0.119209\\\\n2013-01-03 -0.861849 -0.494929\\\\n2013-01-05 -0.424972  0.276232\\\\nFor slicing rows explicitly:\\\\nIn [35]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n:\\\\n3\\\\n,\\\\n:]\\\\nOut[35]:\\\\nA         B         C         D\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804\\\\nFor slicing columns explicitly:\\\\nIn [36]:\\\\ndf\\\\n.\\\\niloc\\\\n[:,\\\\n1\\\\n:\\\\n3\\\\n]\\\\nOut[36]:\\\\nB         C\\\\n2013-01-01 -0.282863 -1.509059\\\\n2013-01-02 -0.173215  0.119209\\\\n2013-01-03 -2.104569 -0.494929\\\\n2013-01-04 -0.706771 -1.039575\\\\n2013-01-05  0.567020  0.276232\\\\n2013-01-06  0.113648 -1.478427\\\\nFor getting a value explicitly:\\\\nIn [37]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n,\\\\n1\\\\n]\\\\nOut[37]:\\\\n-0.17321464905330858\\\\nFor getting fast access to a scalar (equivalent to the prior method):\\\\nIn [38]:\\\\ndf\\\\n.\\\\niat\\\\n[\\\\n1\\\\n,\\\\n1\\\\n]\\\\nOut[38]:\\\\n-0.17321464905330858\\\\nBoolean indexing\\\\n#\\\\nSelect rows where\\\\ndf.A\\\\nis greater than\\\\n0\\\\n.\\\\nIn [39]:\\\\ndf\\\\n[\\\\ndf\\\\n[\\\\n\"A\"\\\\n]\\\\n>\\\\n0\\\\n]\\\\nOut[39]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860\\\\nSelecting values from a\\\\nDataFrame\\\\nwhere a boolean condition is met:\\\\nIn [40]:\\\\ndf\\\\n[\\\\ndf\\\\n>\\\\n0\\\\n]\\\\nOut[40]:\\\\nA         B         C         D\\\\n2013-01-01  0.469112       NaN       NaN       NaN\\\\n2013-01-02  1.212112       NaN  0.119209       NaN\\\\n2013-01-03       NaN       NaN       NaN  1.071804\\\\n2013-01-04  0.721555       NaN       NaN  0.271860\\\\n2013-01-05       NaN  0.567020  0.276232       NaN\\\\n2013-01-06       NaN  0.113648       NaN  0.524988\\\\nUsing\\\\nisin()\\\\nmethod for filtering:\\\\nIn [41]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [42]:\\\\ndf2\\\\n[\\\\n\"E\"\\\\n]\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n,\\\\n\"four\"\\\\n,\\\\n\"three\"\\\\n]\\\\nIn [43]:\\\\ndf2\\\\nOut[43]:\\\\nA         B         C         D      E\\\\n2013-01-01  0.469112 -0.282863 -1.509059 -1.135632    one\\\\n2013-01-02  1.212112 -0.173215  0.119209 -1.044236    one\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804    two\\\\n2013-01-04  0.721555 -0.706771 -1.039575  0.271860  three\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401   four\\\\n2013-01-06 -0.673690  0.113648 -1.478427  0.524988  three\\\\nIn [44]:\\\\ndf2\\\\n[\\\\ndf2\\\\n[\\\\n\"E\"\\\\n]\\\\n.\\\\nisin\\\\n([\\\\n\"two\"\\\\n,\\\\n\"four\"\\\\n])]\\\\nOut[44]:\\\\nA         B         C         D     E\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  1.071804   two\\\\n2013-01-05 -0.424972  0.567020  0.276232 -1.087401  four\\\\nSetting\\\\n#\\\\nSetting a new column automatically aligns the data by the indexes:\\\\nIn [45]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130102\"\\\\n,\\\\nperiods\\\\n=\\\\n6\\\\n))\\\\nIn [46]:\\\\ns1\\\\nOut[46]:\\\\n2013-01-02    1\\\\n2013-01-03    2\\\\n2013-01-04    3\\\\n2013-01-05    4\\\\n2013-01-06    5\\\\n2013-01-07    6\\\\nFreq: D, dtype: int64\\\\nIn [47]:\\\\ndf\\\\n[\\\\n\"F\"\\\\n]\\\\n=\\\\ns1\\\\nSetting values by label:\\\\nIn [48]:\\\\ndf\\\\n.\\\\nat\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n],\\\\n\"A\"\\\\n]\\\\n=\\\\n0\\\\nSetting values by position:\\\\nIn [49]:\\\\ndf\\\\n.\\\\niat\\\\n[\\\\n0\\\\n,\\\\n1\\\\n]\\\\n=\\\\n0\\\\nSetting by assigning with a NumPy array:\\\\nIn [50]:\\\\ndf\\\\n.\\\\nloc\\\\n[:,\\\\n\"D\"\\\\n]\\\\n=\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n5\\\\n]\\\\n*\\\\nlen\\\\n(\\\\ndf\\\\n))\\\\nThe result of the prior setting operations:\\\\nIn [51]:\\\\ndf\\\\nOut[51]:\\\\nA         B         C    D    F\\\\n2013-01-01  0.000000  0.000000 -1.509059  5.0  NaN\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0\\\\n2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0\\\\n2013-01-05 -0.424972  0.567020  0.276232  5.0  4.0\\\\n2013-01-06 -0.673690  0.113648 -1.478427  5.0  5.0\\\\nA\\\\nwhere\\\\noperation with setting:\\\\nIn [52]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [53]:\\\\ndf2\\\\n[\\\\ndf2\\\\n>\\\\n0\\\\n]\\\\n=\\\\n-\\\\ndf2\\\\nIn [54]:\\\\ndf2\\\\nOut[54]:\\\\nA         B         C    D    F\\\\n2013-01-01  0.000000  0.000000 -1.509059 -5.0  NaN\\\\n2013-01-02 -1.212112 -0.173215 -0.119209 -5.0 -1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929 -5.0 -2.0\\\\n2013-01-04 -0.721555 -0.706771 -1.039575 -5.0 -3.0\\\\n2013-01-05 -0.424972 -0.567020 -0.276232 -5.0 -4.0\\\\n2013-01-06 -0.673690 -0.113648 -1.478427 -5.0 -5.0\\\\nMissing data\\\\n#\\\\nFor NumPy data types,\\\\nnp.nan\\\\nrepresents missing data. It is by\\ndefault not included in computations. See the\\\\nMissing Data section\\\\n.\\\\nReindexing allows you to change/add/delete the index on a specified axis. This\\nreturns a copy of the data:\\\\nIn [55]:\\\\ndf1\\\\n=\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\nindex\\\\n=\\\\ndates\\\\n[\\\\n0\\\\n:\\\\n4\\\\n],\\\\ncolumns\\\\n=\\\\nlist\\\\n(\\\\ndf\\\\n.\\\\ncolumns\\\\n)\\\\n+\\\\n[\\\\n\"E\"\\\\n])\\\\nIn [56]:\\\\ndf1\\\\n.\\\\nloc\\\\n[\\\\ndates\\\\n[\\\\n0\\\\n]\\\\n:\\\\ndates\\\\n[\\\\n1\\\\n],\\\\n\"E\"\\\\n]\\\\n=\\\\n1\\\\nIn [57]:\\\\ndf1\\\\nOut[57]:\\\\nA         B         C    D    F    E\\\\n2013-01-01  0.000000  0.000000 -1.509059  5.0  NaN  1.0\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0  NaN\\\\n2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0  NaN\\\\nDataFrame.dropna()\\\\ndrops any rows that have missing data:\\\\nIn [58]:\\\\ndf1\\\\n.\\\\ndropna\\\\n(\\\\nhow\\\\n=\\\\n\"any\"\\\\n)\\\\nOut[58]:\\\\nA         B         C    D    F    E\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0\\\\nDataFrame.fillna()\\\\nfills missing data:\\\\nIn [59]:\\\\ndf1\\\\n.\\\\nfillna\\\\n(\\\\nvalue\\\\n=\\\\n5\\\\n)\\\\nOut[59]:\\\\nA         B         C    D    F    E\\\\n2013-01-01  0.000000  0.000000 -1.509059  5.0  5.0  1.0\\\\n2013-01-02  1.212112 -0.173215  0.119209  5.0  1.0  1.0\\\\n2013-01-03 -0.861849 -2.104569 -0.494929  5.0  2.0  5.0\\\\n2013-01-04  0.721555 -0.706771 -1.039575  5.0  3.0  5.0\\\\nisna()\\\\ngets the boolean mask where values are\\\\nnan\\\\n:\\\\nIn [60]:\\\\npd\\\\n.\\\\nisna\\\\n(\\\\ndf1\\\\n)\\\\nOut[60]:\\\\nA      B      C      D      F      E\\\\n2013-01-01  False  False  False  False   True  False\\\\n2013-01-02  False  False  False  False  False  False\\\\n2013-01-03  False  False  False  False  False   True\\\\n2013-01-04  False  False  False  False  False   True\\\\nOperations\\\\n#\\\\nSee the\\\\nBasic section on Binary Ops\\\\n.\\\\nStats\\\\n#\\\\nOperations in general\\\\nexclude\\\\nmissing data.\\\\nCalculate the mean value for each column:\\\\nIn [61]:\\\\ndf\\\\n.\\\\nmean\\\\n()\\\\nOut[61]:\\\\nA   -0.004474\\\\nB   -0.383981\\\\nC   -0.687758\\\\nD    5.000000\\\\nF    3.000000\\\\ndtype: float64\\\\nCalculate the mean value for each row:\\\\nIn [62]:\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[62]:\\\\n2013-01-01    0.872735\\\\n2013-01-02    1.431621\\\\n2013-01-03    0.707731\\\\n2013-01-04    1.395042\\\\n2013-01-05    1.883656\\\\n2013-01-06    1.592306\\\\nFreq: D, dtype: float64\\\\nOperating with another\\\\nSeries\\\\nor\\\\nDataFrame\\\\nwith a different index or column\\nwill align the result with the union of the index or column labels. In addition, pandas\\nautomatically broadcasts along the specified dimension and will fill unaligned labels with\\\\nnp.nan\\\\n.\\\\nIn [63]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n3\\\\n,\\\\n5\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n6\\\\n,\\\\n8\\\\n],\\\\nindex\\\\n=\\\\ndates\\\\n)\\\\n.\\\\nshift\\\\n(\\\\n2\\\\n)\\\\nIn [64]:\\\\ns\\\\nOut[64]:\\\\n2013-01-01    NaN\\\\n2013-01-02    NaN\\\\n2013-01-03    1.0\\\\n2013-01-04    3.0\\\\n2013-01-05    5.0\\\\n2013-01-06    NaN\\\\nFreq: D, dtype: float64\\\\nIn [65]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ns\\\\n,\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[65]:\\\\nA         B         C    D    F\\\\n2013-01-01       NaN       NaN       NaN  NaN  NaN\\\\n2013-01-02       NaN       NaN       NaN  NaN  NaN\\\\n2013-01-03 -1.861849 -3.104569 -1.494929  4.0  1.0\\\\n2013-01-04 -2.278445 -3.706771 -4.039575  2.0  0.0\\\\n2013-01-05 -5.424972 -4.432980 -4.723768  0.0 -1.0\\\\n2013-01-06       NaN       NaN       NaN  NaN  NaN\\\\nUser defined functions\\\\n#\\\\nDataFrame.agg()\\\\nand\\\\nDataFrame.transform()\\\\napplies a user defined function\\nthat reduces or broadcasts its result respectively.\\\\nIn [66]:\\\\ndf\\\\n.\\\\nagg\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\nx\\\\n)\\\\n*\\\\n5.6\\\\n)\\\\nOut[66]:\\\\nA    -0.025054\\\\nB    -2.150294\\\\nC    -3.851445\\\\nD    28.000000\\\\nF    16.800000\\\\ndtype: float64\\\\nIn [67]:\\\\ndf\\\\n.\\\\ntransform\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n*\\\\n101.2\\\\n)\\\\nOut[67]:\\\\nA           B           C      D      F\\\\n2013-01-01    0.000000    0.000000 -152.716721  506.0    NaN\\\\n2013-01-02  122.665737  -17.529322   12.063922  506.0  101.2\\\\n2013-01-03  -87.219115 -212.982405  -50.086843  506.0  202.4\\\\n2013-01-04   73.021382  -71.525239 -105.204988  506.0  303.6\\\\n2013-01-05  -43.007200   57.382459   27.954680  506.0  404.8\\\\n2013-01-06  -68.177398   11.501219 -149.616767  506.0  506.0\\\\nValue Counts\\\\n#\\\\nSee more at\\\\nHistogramming and Discretization\\\\n.\\\\nIn [68]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n7\\\\n,\\\\nsize\\\\n=\\\\n10\\\\n))\\\\nIn [69]:\\\\ns\\\\nOut[69]:\\\\n0    4\\\\n1    2\\\\n2    1\\\\n3    2\\\\n4    6\\\\n5    4\\\\n6    4\\\\n7    6\\\\n8    4\\\\n9    4\\\\ndtype: int64\\\\nIn [70]:\\\\ns\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[70]:\\\\n4    5\\\\n2    2\\\\n6    2\\\\n1    1\\\\nName: count, dtype: int64\\\\nString Methods\\\\n#\\\\nSeries\\\\nis equipped with a set of string processing methods in the\\\\nstr\\\\nattribute that make it easy to operate on each element of the array, as in the\\ncode snippet below. See more at\\\\nVectorized String Methods\\\\n.\\\\nIn [71]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"Aaba\"\\\\n,\\\\n\"Baca\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n\"CABA\"\\\\n,\\\\n\"dog\"\\\\n,\\\\n\"cat\"\\\\n])\\\\nIn [72]:\\\\ns\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n()\\\\nOut[72]:\\\\n0       a\\\\n1       b\\\\n2       c\\\\n3    aaba\\\\n4    baca\\\\n5     NaN\\\\n6    caba\\\\n7     dog\\\\n8     cat\\\\ndtype: object\\\\nMerge\\\\n#\\\\nConcat\\\\n#\\\\npandas provides various facilities for easily combining together\\\\nSeries\\\\nand\\\\nDataFrame\\\\nobjects with various kinds of set logic for the indexes\\nand relational algebra functionality in the case of join / merge-type\\noperations.\\\\nSee the\\\\nMerging section\\\\n.\\\\nConcatenating pandas objects together row-wise with\\\\nconcat()\\\\n:\\\\nIn [73]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n4\\\\n))\\\\nIn [74]:\\\\ndf\\\\nOut[74]:\\\\n0         1         2         3\\\\n0 -0.548702  1.467327 -1.015962 -0.483075\\\\n1  1.637550 -1.217659 -0.291519 -1.745505\\\\n2 -0.263952  0.991460 -0.919069  0.266046\\\\n3 -0.709661  1.669052  1.037882 -1.705775\\\\n4 -0.919854 -0.042379  1.247642 -0.009920\\\\n5  0.290213  0.495767  0.362949  1.548106\\\\n6 -1.131345 -0.089329  0.337863 -0.945867\\\\n7 -0.932132  1.956030  0.017587 -0.016692\\\\n8 -0.575247  0.254161 -1.143704  0.215897\\\\n9  1.193555 -0.077118 -0.408530 -0.862495\\\\n# break it into pieces\\\\nIn [75]:\\\\npieces\\\\n=\\\\n[\\\\ndf\\\\n[:\\\\n3\\\\n],\\\\ndf\\\\n[\\\\n3\\\\n:\\\\n7\\\\n],\\\\ndf\\\\n[\\\\n7\\\\n:]]\\\\nIn [76]:\\\\npd\\\\n.\\\\nconcat\\\\n(\\\\npieces\\\\n)\\\\nOut[76]:\\\\n0         1         2         3\\\\n0 -0.548702  1.467327 -1.015962 -0.483075\\\\n1  1.637550 -1.217659 -0.291519 -1.745505\\\\n2 -0.263952  0.991460 -0.919069  0.266046\\\\n3 -0.709661  1.669052  1.037882 -1.705775\\\\n4 -0.919854 -0.042379  1.247642 -0.009920\\\\n5  0.290213  0.495767  0.362949  1.548106\\\\n6 -1.131345 -0.089329  0.337863 -0.945867\\\\n7 -0.932132  1.956030  0.017587 -0.016692\\\\n8 -0.575247  0.254161 -1.143704  0.215897\\\\n9  1.193555 -0.077118 -0.408530 -0.862495\\\\nNote\\\\nAdding a column to a\\\\nDataFrame\\\\nis relatively fast. However, adding\\na row requires a copy, and may be expensive. We recommend passing a\\npre-built list of records to the\\\\nDataFrame\\\\nconstructor instead\\nof building a\\\\nDataFrame\\\\nby iteratively appending records to it.\\\\nJoin\\\\n#\\\\nmerge()\\\\nenables SQL style join types along specific columns. See the\\\\nDatabase style joining\\\\nsection.\\\\nIn [77]:\\\\nleft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n],\\\\n\"lval\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]})\\\\nIn [78]:\\\\nright\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n],\\\\n\"rval\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n]})\\\\nIn [79]:\\\\nleft\\\\nOut[79]:\\\\nkey  lval\\\\n0  foo     1\\\\n1  foo     2\\\\nIn [80]:\\\\nright\\\\nOut[80]:\\\\nkey  rval\\\\n0  foo     4\\\\n1  foo     5\\\\nIn [81]:\\\\npd\\\\n.\\\\nmerge\\\\n(\\\\nleft\\\\n,\\\\nright\\\\n,\\\\non\\\\n=\\\\n\"key\"\\\\n)\\\\nOut[81]:\\\\nkey  lval  rval\\\\n0  foo     1     4\\\\n1  foo     1     5\\\\n2  foo     2     4\\\\n3  foo     2     5\\\\nmerge()\\\\non unique keys:\\\\nIn [82]:\\\\nleft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n],\\\\n\"lval\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]})\\\\nIn [83]:\\\\nright\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"key\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n],\\\\n\"rval\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n]})\\\\nIn [84]:\\\\nleft\\\\nOut[84]:\\\\nkey  lval\\\\n0  foo     1\\\\n1  bar     2\\\\nIn [85]:\\\\nright\\\\nOut[85]:\\\\nkey  rval\\\\n0  foo     4\\\\n1  bar     5\\\\nIn [86]:\\\\npd\\\\n.\\\\nmerge\\\\n(\\\\nleft\\\\n,\\\\nright\\\\n,\\\\non\\\\n=\\\\n\"key\"\\\\n)\\\\nOut[86]:\\\\nkey  lval  rval\\\\n0  foo     1     4\\\\n1  bar     2     5\\\\nGrouping\\\\n#\\\\nBy “group by” we are referring to a process involving one or more of the\\nfollowing steps:\\\\nSplitting\\\\nthe data into groups based on some criteria\\\\nApplying\\\\na function to each group independently\\\\nCombining\\\\nthe results into a data structure\\\\nSee the\\\\nGrouping section\\\\n.\\\\nIn [87]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n\"A\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n],\\\\n....:\\\\n\"B\"\\\\n:\\\\n[\\\\n\"one\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"three\"\\\\n],\\\\n....:\\\\n\"C\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\n....:\\\\n\"D\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nIn [88]:\\\\ndf\\\\nOut[88]:\\\\nA      B         C         D\\\\n0  foo    one  1.346061 -1.577585\\\\n1  bar    one  1.511763  0.396823\\\\n2  foo    two  1.627081 -0.105381\\\\n3  bar  three -0.990582 -0.532532\\\\n4  foo    two -0.441652  1.453749\\\\n5  bar    two  1.211526  1.208843\\\\n6  foo    one  0.268520 -0.080952\\\\n7  foo  three  0.024580 -0.264610\\\\nGrouping by a column label, selecting column labels, and then applying the\\\\nDataFrameGroupBy.sum()\\\\nfunction to the resulting\\ngroups:\\\\nIn [89]:\\\\ndf\\\\n.\\\\ngroupby\\\\n(\\\\n\"A\"\\\\n)[[\\\\n\"C\"\\\\n,\\\\n\"D\"\\\\n]]\\\\n.\\\\nsum\\\\n()\\\\nOut[89]:\\\\nC         D\\\\nA\\\\nbar  1.732707  1.073134\\\\nfoo  2.824590 -0.574779\\\\nGrouping by multiple columns label forms\\\\nMultiIndex\\\\n.\\\\nIn [90]:\\\\ndf\\\\n.\\\\ngroupby\\\\n([\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n])\\\\n.\\\\nsum\\\\n()\\\\nOut[90]:\\\\nC         D\\\\nA   B\\\\nbar one    1.511763  0.396823\\\\nthree -0.990582 -0.532532\\\\ntwo    1.211526  1.208843\\\\nfoo one    1.614581 -1.658537\\\\nthree  0.024580 -0.264610\\\\ntwo    1.185429  1.348368\\\\nReshaping\\\\n#\\\\nSee the sections on\\\\nHierarchical Indexing\\\\nand\\\\nReshaping\\\\n.\\\\nStack\\\\n#\\\\nIn [91]:\\\\narrays\\\\n=\\\\n[\\\\n....:\\\\n[\\\\n\"bar\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n,\\\\n\"baz\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"qux\"\\\\n,\\\\n\"qux\"\\\\n],\\\\n....:\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n],\\\\n....:\\\\n]\\\\n....:\\\\nIn [92]:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_arrays\\\\n(\\\\narrays\\\\n,\\\\nnames\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n])\\\\nIn [93]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n,\\\\n2\\\\n),\\\\nindex\\\\n=\\\\nindex\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n])\\\\nIn [94]:\\\\ndf2\\\\n=\\\\ndf\\\\n[:\\\\n4\\\\n]\\\\nIn [95]:\\\\ndf2\\\\nOut[95]:\\\\nA         B\\\\nfirst second\\\\nbar   one    -0.727965 -0.589346\\\\ntwo     0.339969 -0.693205\\\\nbaz   one    -0.339355  0.593616\\\\ntwo     0.884345  1.591431\\\\nThe\\\\nstack()\\\\nmethod “compresses” a level in the DataFrame’s\\ncolumns:\\\\nIn [96]:\\\\nstacked\\\\n=\\\\ndf2\\\\n.\\\\nstack\\\\n(\\\\nfuture_stack\\\\n=\\\\nTrue\\\\n)\\\\nIn [97]:\\\\nstacked\\\\nOut[97]:\\\\nfirst  second\\\\nbar    one     A   -0.727965\\\\nB   -0.589346\\\\ntwo     A    0.339969\\\\nB   -0.693205\\\\nbaz    one     A   -0.339355\\\\nB    0.593616\\\\ntwo     A    0.884345\\\\nB    1.591431\\\\ndtype: float64\\\\nWith a “stacked” DataFrame or Series (having a\\\\nMultiIndex\\\\nas the\\\\nindex\\\\n), the inverse operation of\\\\nstack()\\\\nis\\\\nunstack()\\\\n, which by default unstacks the\\\\nlast level\\\\n:\\\\nIn [98]:\\\\nstacked\\\\n.\\\\nunstack\\\\n()\\\\nOut[98]:\\\\nA         B\\\\nfirst second\\\\nbar   one    -0.727965 -0.589346\\\\ntwo     0.339969 -0.693205\\\\nbaz   one    -0.339355  0.593616\\\\ntwo     0.884345  1.591431\\\\nIn [99]:\\\\nstacked\\\\n.\\\\nunstack\\\\n(\\\\n1\\\\n)\\\\nOut[99]:\\\\nsecond        one       two\\\\nfirst\\\\nbar   A -0.727965  0.339969\\\\nB -0.589346 -0.693205\\\\nbaz   A -0.339355  0.884345\\\\nB  0.593616  1.591431\\\\nIn [100]:\\\\nstacked\\\\n.\\\\nunstack\\\\n(\\\\n0\\\\n)\\\\nOut[100]:\\\\nfirst          bar       baz\\\\nsecond\\\\none    A -0.727965 -0.339355\\\\nB -0.589346  0.593616\\\\ntwo    A  0.339969  0.884345\\\\nB -0.693205  1.591431\\\\nPivot tables\\\\n#\\\\nSee the section on\\\\nPivot Tables\\\\n.\\\\nIn [101]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\n[\\\\n\"one\"\\\\n,\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n]\\\\n*\\\\n3\\\\n,\\\\n.....:\\\\n\"B\"\\\\n:\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n]\\\\n*\\\\n4\\\\n,\\\\n.....:\\\\n\"C\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"bar\"\\\\n]\\\\n*\\\\n2\\\\n,\\\\n.....:\\\\n\"D\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n12\\\\n),\\\\n.....:\\\\n\"E\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n12\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [102]:\\\\ndf\\\\nOut[102]:\\\\nA  B    C         D         E\\\\n0     one  A  foo -1.202872  0.047609\\\\n1     one  B  foo -1.814470 -0.136473\\\\n2     two  C  foo  1.018601 -0.561757\\\\n3   three  A  bar -0.595447 -1.623033\\\\n4     one  B  bar  1.395433  0.029399\\\\n5     one  C  bar -0.392670 -0.542108\\\\n6     two  A  foo  0.007207  0.282696\\\\n7   three  B  foo  1.928123 -0.087302\\\\n8     one  C  foo -0.055224 -1.575170\\\\n9     one  A  bar  2.395985  1.771208\\\\n10    two  B  bar  1.552825  0.816482\\\\n11  three  C  bar  0.166599  1.100230\\\\npivot_table()\\\\npivots a\\\\nDataFrame\\\\nspecifying the\\\\nvalues\\\\n,\\\\nindex\\\\nand\\\\ncolumns\\\\nIn [103]:\\\\npd\\\\n.\\\\npivot_table\\\\n(\\\\ndf\\\\n,\\\\nvalues\\\\n=\\\\n\"D\"\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"C\"\\\\n])\\\\nOut[103]:\\\\nC             bar       foo\\\\nA     B\\\\none   A  2.395985 -1.202872\\\\nB  1.395433 -1.814470\\\\nC -0.392670 -0.055224\\\\nthree A -0.595447       NaN\\\\nB       NaN  1.928123\\\\nC  0.166599       NaN\\\\ntwo   A       NaN  0.007207\\\\nB  1.552825       NaN\\\\nC       NaN  1.018601\\\\nTime series\\\\n#\\\\npandas has simple, powerful, and efficient functionality for performing\\nresampling operations during frequency conversion (e.g., converting secondly\\ndata into 5-minutely data). This is extremely common in, but not limited to,\\nfinancial applications. See the\\\\nTime Series section\\\\n.\\\\nIn [104]:\\\\nrng\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2012\"\\\\n,\\\\nperiods\\\\n=\\\\n100\\\\n,\\\\nfreq\\\\n=\\\\n\"s\"\\\\n)\\\\nIn [105]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n500\\\\n,\\\\nlen\\\\n(\\\\nrng\\\\n)),\\\\nindex\\\\n=\\\\nrng\\\\n)\\\\nIn [106]:\\\\nts\\\\n.\\\\nresample\\\\n(\\\\n\"5Min\"\\\\n)\\\\n.\\\\nsum\\\\n()\\\\nOut[106]:\\\\n2012-01-01    24182\\\\nFreq: 5min, dtype: int64\\\\nSeries.tz_localize()\\\\nlocalizes a time series to a time zone:\\\\nIn [107]:\\\\nrng\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"3/6/2012 00:00\"\\\\n,\\\\nperiods\\\\n=\\\\n5\\\\n,\\\\nfreq\\\\n=\\\\n\"D\"\\\\n)\\\\nIn [108]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\nlen\\\\n(\\\\nrng\\\\n)),\\\\nrng\\\\n)\\\\nIn [109]:\\\\nts\\\\nOut[109]:\\\\n2012-03-06    1.857704\\\\n2012-03-07   -1.193545\\\\n2012-03-08    0.677510\\\\n2012-03-09   -0.153931\\\\n2012-03-10    0.520091\\\\nFreq: D, dtype: float64\\\\nIn [110]:\\\\nts_utc\\\\n=\\\\nts\\\\n.\\\\ntz_localize\\\\n(\\\\n\"UTC\"\\\\n)\\\\nIn [111]:\\\\nts_utc\\\\nOut[111]:\\\\n2012-03-06 00:00:00+00:00    1.857704\\\\n2012-03-07 00:00:00+00:00   -1.193545\\\\n2012-03-08 00:00:00+00:00    0.677510\\\\n2012-03-09 00:00:00+00:00   -0.153931\\\\n2012-03-10 00:00:00+00:00    0.520091\\\\nFreq: D, dtype: float64\\\\nSeries.tz_convert()\\\\nconverts a timezones aware time series to another time zone:\\\\nIn [112]:\\\\nts_utc\\\\n.\\\\ntz_convert\\\\n(\\\\n\"US/Eastern\"\\\\n)\\\\nOut[112]:\\\\n2012-03-05 19:00:00-05:00    1.857704\\\\n2012-03-06 19:00:00-05:00   -1.193545\\\\n2012-03-07 19:00:00-05:00    0.677510\\\\n2012-03-08 19:00:00-05:00   -0.153931\\\\n2012-03-09 19:00:00-05:00    0.520091\\\\nFreq: D, dtype: float64\\\\nAdding a non-fixed duration (\\\\nBusinessDay\\\\n) to a time series:\\\\nIn [113]:\\\\nrng\\\\nOut[113]:\\\\nDatetimeIndex([\\'2012-03-06\\', \\'2012-03-07\\', \\'2012-03-08\\', \\'2012-03-09\\',\\\\n\\'2012-03-10\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=\\'D\\')\\\\nIn [114]:\\\\nrng\\\\n+\\\\npd\\\\n.\\\\noffsets\\\\n.\\\\nBusinessDay\\\\n(\\\\n5\\\\n)\\\\nOut[114]:\\\\nDatetimeIndex([\\'2012-03-13\\', \\'2012-03-14\\', \\'2012-03-15\\', \\'2012-03-16\\',\\\\n\\'2012-03-16\\'],\\\\ndtype=\\'datetime64[ns]\\', freq=None)\\\\nCategoricals\\\\n#\\\\npandas can include categorical data in a\\\\nDataFrame\\\\n. For full docs, see the\\\\ncategorical introduction\\\\nand the\\\\nAPI documentation\\\\n.\\\\nIn [115]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"id\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"raw_grade\"\\\\n:\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"e\"\\\\n]}\\\\n.....:\\\\n)\\\\n.....:\\\\nConverting the raw grades to a categorical data type:\\\\nIn [116]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"raw_grade\"\\\\n]\\\\n.\\\\nastype\\\\n(\\\\n\"category\"\\\\n)\\\\nIn [117]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\nOut[117]:\\\\n0    a\\\\n1    b\\\\n2    b\\\\n3    a\\\\n4    a\\\\n5    e\\\\nName: grade, dtype: category\\\\nCategories (3, object): [\\'a\\', \\'b\\', \\'e\\']\\\\nRename the categories to more meaningful names:\\\\nIn [118]:\\\\nnew_categories\\\\n=\\\\n[\\\\n\"very good\"\\\\n,\\\\n\"good\"\\\\n,\\\\n\"very bad\"\\\\n]\\\\nIn [119]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n.\\\\ncat\\\\n.\\\\nrename_categories\\\\n(\\\\nnew_categories\\\\n)\\\\nReorder the categories and simultaneously add the missing categories (methods under\\\\nSeries.cat()\\\\nreturn a new\\\\nSeries\\\\nby default):\\\\nIn [120]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\n.\\\\ncat\\\\n.\\\\nset_categories\\\\n(\\\\n.....:\\\\n[\\\\n\"very bad\"\\\\n,\\\\n\"bad\"\\\\n,\\\\n\"medium\"\\\\n,\\\\n\"good\"\\\\n,\\\\n\"very good\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [121]:\\\\ndf\\\\n[\\\\n\"grade\"\\\\n]\\\\nOut[121]:\\\\n0    very good\\\\n1         good\\\\n2         good\\\\n3    very good\\\\n4    very good\\\\n5     very bad\\\\nName: grade, dtype: category\\\\nCategories (5, object): [\\'very bad\\', \\'bad\\', \\'medium\\', \\'good\\', \\'very good\\']\\\\nSorting is per order in the categories, not lexical order:\\\\nIn [122]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"grade\"\\\\n)\\\\nOut[122]:\\\\nid raw_grade      grade\\\\n5   6         e   very bad\\\\n1   2         b       good\\\\n2   3         b       good\\\\n0   1         a  very good\\\\n3   4         a  very good\\\\n4   5         a  very good\\\\nGrouping by a categorical column with\\\\nobserved=False\\\\nalso shows empty categories:\\\\nIn [123]:\\\\ndf\\\\n.\\\\ngroupby\\\\n(\\\\n\"grade\"\\\\n,\\\\nobserved\\\\n=\\\\nFalse\\\\n)\\\\n.\\\\nsize\\\\n()\\\\nOut[123]:\\\\ngrade\\\\nvery bad     1\\\\nbad          0\\\\nmedium       0\\\\ngood         2\\\\nvery good    3\\\\ndtype: int64\\\\nPlotting\\\\n#\\\\nSee the\\\\nPlotting\\\\ndocs.\\\\nWe use the standard convention for referencing the matplotlib API:\\\\nIn [124]:\\\\nimport\\\\nmatplotlib.pyplot\\\\nas\\\\nplt\\\\nIn [125]:\\\\nplt\\\\n.\\\\nclose\\\\n(\\\\n\"all\"\\\\n)\\\\nThe\\\\nplt.close\\\\nmethod is used to\\\\nclose\\\\na figure window:\\\\nIn [126]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n),\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n1000\\\\n))\\\\nIn [127]:\\\\nts\\\\n=\\\\nts\\\\n.\\\\ncumsum\\\\n()\\\\nIn [128]:\\\\nts\\\\n.\\\\nplot\\\\n();\\\\nNote\\\\nWhen using Jupyter, the plot will appear using\\\\nplot()\\\\n.  Otherwise use\\\\nmatplotlib.pyplot.show\\\\nto show it or\\\\nmatplotlib.pyplot.savefig\\\\nto write it to a file.\\\\nplot()\\\\nplots all columns:\\\\nIn [129]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n,\\\\n4\\\\n),\\\\nindex\\\\n=\\\\nts\\\\n.\\\\nindex\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"D\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [130]:\\\\ndf\\\\n=\\\\ndf\\\\n.\\\\ncumsum\\\\n()\\\\nIn [131]:\\\\nplt\\\\n.\\\\nfigure\\\\n();\\\\nIn [132]:\\\\ndf\\\\n.\\\\nplot\\\\n();\\\\nIn [133]:\\\\nplt\\\\n.\\\\nlegend\\\\n(\\\\nloc\\\\n=\\\\n\\'best\\'\\\\n);\\\\nImporting and exporting data\\\\n#\\\\nSee the\\\\nIO Tools\\\\nsection.\\\\nCSV\\\\n#\\\\nWriting to a csv file:\\\\nusing\\\\nDataFrame.to_csv()\\\\nIn [134]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n5\\\\n,\\\\n(\\\\n10\\\\n,\\\\n5\\\\n)))\\\\nIn [135]:\\\\ndf\\\\n.\\\\nto_csv\\\\n(\\\\n\"foo.csv\"\\\\n)\\\\nReading from a csv file:\\\\nusing\\\\nread_csv()\\\\nIn [136]:\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"foo.csv\"\\\\n)\\\\nOut[136]:\\\\nUnnamed: 0  0  1  2  3  4\\\\n0           0  4  3  1  1  2\\\\n1           1  1  0  2  3  2\\\\n2           2  1  4  2  1  2\\\\n3           3  0  4  0  2  2\\\\n4           4  4  2  2  3  4\\\\n5           5  4  0  4  3  1\\\\n6           6  2  1  2  0  3\\\\n7           7  4  0  4  4  4\\\\n8           8  4  4  1  0  1\\\\n9           9  0  4  3  0  3\\\\nParquet\\\\n#\\\\nWriting to a Parquet file:\\\\nIn [137]:\\\\ndf\\\\n.\\\\nto_parquet\\\\n(\\\\n\"foo.parquet\"\\\\n)\\\\nReading from a Parquet file Store using\\\\nread_parquet()\\\\n:\\\\nIn [138]:\\\\npd\\\\n.\\\\nread_parquet\\\\n(\\\\n\"foo.parquet\"\\\\n)\\\\nOut[138]:\\\\n0  1  2  3  4\\\\n0  4  3  1  1  2\\\\n1  1  0  2  3  2\\\\n2  1  4  2  1  2\\\\n3  0  4  0  2  2\\\\n4  4  2  2  3  4\\\\n5  4  0  4  3  1\\\\n6  2  1  2  0  3\\\\n7  4  0  4  4  4\\\\n8  4  4  1  0  1\\\\n9  0  4  3  0  3\\\\nExcel\\\\n#\\\\nReading and writing to\\\\nExcel\\\\n.\\\\nWriting to an excel file using\\\\nDataFrame.to_excel()\\\\n:\\\\nIn [139]:\\\\ndf\\\\n.\\\\nto_excel\\\\n(\\\\n\"foo.xlsx\"\\\\n,\\\\nsheet_name\\\\n=\\\\n\"Sheet1\"\\\\n)\\\\nReading from an excel file using\\\\nread_excel()\\\\n:\\\\nIn [140]:\\\\npd\\\\n.\\\\nread_excel\\\\n(\\\\n\"foo.xlsx\"\\\\n,\\\\n\"Sheet1\"\\\\n,\\\\nindex_col\\\\n=\\\\nNone\\\\n,\\\\nna_values\\\\n=\\\\n[\\\\n\"NA\"\\\\n])\\\\nOut[140]:\\\\nUnnamed: 0  0  1  2  3  4\\\\n0           0  4  3  1  1  2\\\\n1           1  1  0  2  3  2\\\\n2           2  1  4  2  1  2\\\\n3           3  0  4  0  2  2\\\\n4           4  4  2  2  3  4\\\\n5           5  4  0  4  3  1\\\\n6           6  2  1  2  0  3\\\\n7           7  4  0  4  4  4\\\\n8           8  4  4  1  0  1\\\\n9           9  0  4  3  0  3\\\\nGotchas\\\\n#\\\\nIf you are attempting to perform a boolean operation on a\\\\nSeries\\\\nor\\\\nDataFrame\\\\nyou might see an exception like:\\\\nIn [141]:\\\\nif\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\nFalse\\\\n,\\\\nTrue\\\\n,\\\\nFalse\\\\n]):\\\\n.....:\\\\nprint\\\\n(\\\\n\"I was true\"\\\\n)\\\\n.....:\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\n<ipython-input-141-b27eb9c1dfc0>\\\\nin\\\\n?\\\\n()\\\\n---->\\\\n1\\\\nif\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\nFalse\\\\n,\\\\nTrue\\\\n,\\\\nFalse\\\\n]):\\\\n2\\\\nprint\\\\n(\\\\n\"I was true\"\\\\n)\\\\n~/work/pandas/pandas/pandas/core/generic.py\\\\nin\\\\n?\\\\n(self)\\\\n1575\\\\n@final\\\\n1576\\\\ndef\\\\n__nonzero__\\\\n(\\\\nself\\\\n)\\\\n->\\\\nNoReturn\\\\n:\\\\n->\\\\n1577\\\\nraise\\\\nValueError\\\\n(\\\\n1578\\\\nf\\\\n\"The truth value of a\\\\n{\\\\ntype\\\\n(\\\\nself\\\\n)\\\\n.\\\\n__name__\\\\n}\\\\nis ambiguous. \"\\\\n1579\\\\n\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\\\\n1580\\\\n)\\\\nValueError\\\\n: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\\nSee\\\\nComparisons\\\\nand\\\\nGotchas\\\\nfor an explanation and what to do.\\\\nprevious\\\\nUser Guide\\\\nnext\\\\nIntro to data structures\\\\nOn this page\\\\nBasic data structures in pandas\\\\nObject creation\\\\nViewing data\\\\nSelection\\\\nGetitem (\\\\n[]\\\\n)\\\\nSelection by label\\\\nSelection by position\\\\nBoolean indexing\\\\nSetting\\\\nMissing data\\\\nOperations\\\\nStats\\\\nUser defined functions\\\\nValue Counts\\\\nString Methods\\\\nMerge\\\\nConcat\\\\nJoin\\\\nGrouping\\\\nReshaping\\\\nStack\\\\nPivot tables\\\\nTime series\\\\nCategoricals\\\\nPlotting\\\\nImporting and exporting data\\\\nCSV\\\\nParquet\\\\nExcel\\\\nGotchas\\\\nShow Source\\\\n\\\\n--- Page Break ---\\\\n\\\\nUser Guide\\\\nIntro to...\\\\nIntro to data structures\\\\n#\\\\nWe’ll start with a quick, non-comprehensive overview of the fundamental data\\nstructures in pandas to get you started. The fundamental behavior about data\\ntypes, indexing, axis labeling, and alignment apply across all of the\\nobjects. To get started, import NumPy and load pandas into your namespace:\\\\nIn [1]:\\\\nimport\\\\nnumpy\\\\nas\\\\nnp\\\\nIn [2]:\\\\nimport\\\\npandas\\\\nas\\\\npd\\\\nFundamentally,\\\\ndata alignment is intrinsic\\\\n. The link\\nbetween labels and data will not be broken unless done so explicitly by you.\\\\nWe’ll give a brief intro to the data structures, then consider all of the broad\\ncategories of functionality and methods in separate sections.\\\\nSeries\\\\n#\\\\nSeries\\\\nis a one-dimensional labeled array capable of holding any data\\ntype (integers, strings, floating point numbers, Python objects, etc.). The axis\\nlabels are collectively referred to as the\\\\nindex\\\\n. The basic method to create a\\\\nSeries\\\\nis to call:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\ndata\\\\n,\\\\nindex\\\\n=\\\\nindex\\\\n)\\\\nHere,\\\\ndata\\\\ncan be many different things:\\\\na Python dict\\\\nan ndarray\\\\na scalar value (like 5)\\\\nThe passed\\\\nindex\\\\nis a list of axis labels. Thus, this separates into a few\\ncases depending on what\\\\ndata is\\\\n:\\\\nFrom ndarray\\\\nIf\\\\ndata\\\\nis an ndarray,\\\\nindex\\\\nmust be the same length as\\\\ndata\\\\n. If no\\nindex is passed, one will be created having values\\\\n[0,\\\\n...,\\\\nlen(data)\\\\n-\\\\n1]\\\\n.\\\\nIn [3]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [4]:\\\\ns\\\\nOut[4]:\\\\na    0.469112\\\\nb   -0.282863\\\\nc   -1.509059\\\\nd   -1.135632\\\\ne    1.212112\\\\ndtype: float64\\\\nIn [5]:\\\\ns\\\\n.\\\\nindex\\\\nOut[5]:\\\\nIndex([\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\'], dtype=\\'object\\')\\\\nIn [6]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n))\\\\nOut[6]:\\\\n0   -0.173215\\\\n1    0.119209\\\\n2   -1.044236\\\\n3   -0.861849\\\\n4   -2.104569\\\\ndtype: float64\\\\nNote\\\\npandas supports non-unique index values. If an operation\\nthat does not support duplicate index values is attempted, an exception\\nwill be raised at that time.\\\\nFrom dict\\\\nSeries\\\\ncan be instantiated from dicts:\\\\nIn [7]:\\\\nd\\\\n=\\\\n{\\\\n\"b\"\\\\n:\\\\n1\\\\n,\\\\n\"a\"\\\\n:\\\\n0\\\\n,\\\\n\"c\"\\\\n:\\\\n2\\\\n}\\\\nIn [8]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nd\\\\n)\\\\nOut[8]:\\\\nb    1\\\\na    0\\\\nc    2\\\\ndtype: int64\\\\nIf an index is passed, the values in data corresponding to the labels in the\\nindex will be pulled out.\\\\nIn [9]:\\\\nd\\\\n=\\\\n{\\\\n\"a\"\\\\n:\\\\n0.0\\\\n,\\\\n\"b\"\\\\n:\\\\n1.0\\\\n,\\\\n\"c\"\\\\n:\\\\n2.0\\\\n}\\\\nIn [10]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nd\\\\n)\\\\nOut[10]:\\\\na    0.0\\\\nb    1.0\\\\nc    2.0\\\\ndtype: float64\\\\nIn [11]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"a\"\\\\n])\\\\nOut[11]:\\\\nb    1.0\\\\nc    2.0\\\\nd    NaN\\\\na    0.0\\\\ndtype: float64\\\\nNote\\\\nNaN (not a number) is the standard missing data marker used in pandas.\\\\nFrom scalar value\\\\nIf\\\\ndata\\\\nis a scalar value, an index must be\\nprovided. The value will be repeated to match the length of\\\\nindex\\\\n.\\\\nIn [12]:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n5.0\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nOut[12]:\\\\na    5.0\\\\nb    5.0\\\\nc    5.0\\\\nd    5.0\\\\ne    5.0\\\\ndtype: float64\\\\nSeries is ndarray-like\\\\n#\\\\nSeries\\\\nacts very similarly to a\\\\nndarray\\\\nand is a valid argument to most NumPy functions.\\nHowever, operations such as slicing will also slice the index.\\\\nIn [13]:\\\\ns\\\\n.\\\\niloc\\\\n[\\\\n0\\\\n]\\\\nOut[13]:\\\\n0.4691122999071863\\\\nIn [14]:\\\\ns\\\\n.\\\\niloc\\\\n[:\\\\n3\\\\n]\\\\nOut[14]:\\\\na    0.469112\\\\nb   -0.282863\\\\nc   -1.509059\\\\ndtype: float64\\\\nIn [15]:\\\\ns\\\\n[\\\\ns\\\\n>\\\\ns\\\\n.\\\\nmedian\\\\n()]\\\\nOut[15]:\\\\na    0.469112\\\\ne    1.212112\\\\ndtype: float64\\\\nIn [16]:\\\\ns\\\\n.\\\\niloc\\\\n[[\\\\n4\\\\n,\\\\n3\\\\n,\\\\n1\\\\n]]\\\\nOut[16]:\\\\ne    1.212112\\\\nd   -1.135632\\\\nb   -0.282863\\\\ndtype: float64\\\\nIn [17]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\ns\\\\n)\\\\nOut[17]:\\\\na    1.598575\\\\nb    0.753623\\\\nc    0.221118\\\\nd    0.321219\\\\ne    3.360575\\\\ndtype: float64\\\\nNote\\\\nWe will address array-based indexing like\\\\ns.iloc[[4,\\\\n3,\\\\n1]]\\\\nin\\\\nsection on indexing\\\\n.\\\\nLike a NumPy array, a pandas\\\\nSeries\\\\nhas a single\\\\ndtype\\\\n.\\\\nIn [18]:\\\\ns\\\\n.\\\\ndtype\\\\nOut[18]:\\\\ndtype(\\'float64\\')\\\\nThis is often a NumPy dtype. However, pandas and 3rd-party libraries\\nextend NumPy’s type system in a few places, in which case the dtype would\\nbe an\\\\nExtensionDtype\\\\n. Some examples within\\npandas are\\\\nCategorical data\\\\nand\\\\nNullable integer data type\\\\n. See\\\\ndtypes\\\\nfor more.\\\\nIf you need the actual array backing a\\\\nSeries\\\\n, use\\\\nSeries.array\\\\n.\\\\nIn [19]:\\\\ns\\\\n.\\\\narray\\\\nOut[19]:\\\\n<NumpyExtensionArray>\\\\n[ 0.4691122999071863, -0.2828633443286633, -1.5090585031735124,\\\\n-1.1356323710171934,  1.2121120250208506]\\\\nLength: 5, dtype: float64\\\\nAccessing the array can be useful when you need to do some operation without the\\nindex (to disable\\\\nautomatic alignment\\\\n, for example).\\\\nSeries.array\\\\nwill always be an\\\\nExtensionArray\\\\n.\\nBriefly, an ExtensionArray is a thin wrapper around one or more\\\\nconcrete\\\\narrays like a\\\\nnumpy.ndarray\\\\n. pandas knows how to take an\\\\nExtensionArray\\\\nand\\nstore it in a\\\\nSeries\\\\nor a column of a\\\\nDataFrame\\\\n.\\nSee\\\\ndtypes\\\\nfor more.\\\\nWhile\\\\nSeries\\\\nis ndarray-like, if you need an\\\\nactual\\\\nndarray, then use\\\\nSeries.to_numpy()\\\\n.\\\\nIn [20]:\\\\ns\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[20]:\\\\narray([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])\\\\nEven if the\\\\nSeries\\\\nis backed by a\\\\nExtensionArray\\\\n,\\\\nSeries.to_numpy()\\\\nwill return a NumPy ndarray.\\\\nSeries is dict-like\\\\n#\\\\nA\\\\nSeries\\\\nis also like a fixed-size dict in that you can get and set values by index\\nlabel:\\\\nIn [21]:\\\\ns\\\\n[\\\\n\"a\"\\\\n]\\\\nOut[21]:\\\\n0.4691122999071863\\\\nIn [22]:\\\\ns\\\\n[\\\\n\"e\"\\\\n]\\\\n=\\\\n12.0\\\\nIn [23]:\\\\ns\\\\nOut[23]:\\\\na     0.469112\\\\nb    -0.282863\\\\nc    -1.509059\\\\nd    -1.135632\\\\ne    12.000000\\\\ndtype: float64\\\\nIn [24]:\\\\n\"e\"\\\\nin\\\\ns\\\\nOut[24]:\\\\nTrue\\\\nIn [25]:\\\\n\"f\"\\\\nin\\\\ns\\\\nOut[25]:\\\\nFalse\\\\nIf a label is not contained in the index, an exception is raised:\\\\nIn [26]:\\\\ns\\\\n[\\\\n\"f\"\\\\n]\\\\n---------------------------------------------------------------------------\\\\nKeyError\\\\nTraceback (most recent call last)\\\\nFile ~/work/pandas/pandas/pandas/core/indexes/base.py:3812,\\\\nin\\\\nIndex.get_loc\\\\n(self, key)\\\\n3811\\\\ntry\\\\n:\\\\n->\\\\n3812\\\\nreturn\\\\nself\\\\n.\\\\n_engine\\\\n.\\\\nget_loc\\\\n(\\\\ncasted_key\\\\n)\\\\n3813\\\\nexcept\\\\nKeyError\\\\nas\\\\nerr\\\\n:\\\\nFile ~/work/pandas/pandas/pandas/_libs/index.pyx:167,\\\\nin\\\\npandas._libs.index.IndexEngine.get_loc\\\\n()\\\\nFile ~/work/pandas/pandas/pandas/_libs/index.pyx:196,\\\\nin\\\\npandas._libs.index.IndexEngine.get_loc\\\\n()\\\\nFile pandas/_libs/hashtable_class_helper.pxi:7088,\\\\nin\\\\npandas._libs.hashtable.PyObjectHashTable.get_item\\\\n()\\\\nFile pandas/_libs/hashtable_class_helper.pxi:7096,\\\\nin\\\\npandas._libs.hashtable.PyObjectHashTable.get_item\\\\n()\\\\nKeyError\\\\n: \\'f\\'\\\\nThe\\\\nabove\\\\nexception\\\\nwas\\\\nthe\\\\ndirect\\\\ncause\\\\nof\\\\nthe\\\\nfollowing\\\\nexception\\\\n:\\\\nKeyError\\\\nTraceback (most recent call last)\\\\nCell\\\\nIn\\\\n[\\\\n26\\\\n],\\\\nline\\\\n1\\\\n---->\\\\n1\\\\ns\\\\n[\\\\n\"f\"\\\\n]\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:1130,\\\\nin\\\\nSeries.__getitem__\\\\n(self, key)\\\\n1127\\\\nreturn\\\\nself\\\\n.\\\\n_values\\\\n[\\\\nkey\\\\n]\\\\n1129\\\\nelif\\\\nkey_is_scalar\\\\n:\\\\n->\\\\n1130\\\\nreturn\\\\nself\\\\n.\\\\n_get_value\\\\n(\\\\nkey\\\\n)\\\\n1132\\\\n# Convert generator to list before going through hashable part\\\\n1133\\\\n# (We will iterate through the generator there to check for slices)\\\\n1134\\\\nif\\\\nis_iterator\\\\n(\\\\nkey\\\\n):\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:1246,\\\\nin\\\\nSeries._get_value\\\\n(self, label, takeable)\\\\n1243\\\\nreturn\\\\nself\\\\n.\\\\n_values\\\\n[\\\\nlabel\\\\n]\\\\n1245\\\\n# Similar to Index.get_value, but we do not fall back to positional\\\\n->\\\\n1246\\\\nloc\\\\n=\\\\nself\\\\n.\\\\nindex\\\\n.\\\\nget_loc\\\\n(\\\\nlabel\\\\n)\\\\n1248\\\\nif\\\\nis_integer\\\\n(\\\\nloc\\\\n):\\\\n1249\\\\nreturn\\\\nself\\\\n.\\\\n_values\\\\n[\\\\nloc\\\\n]\\\\nFile ~/work/pandas/pandas/pandas/core/indexes/base.py:3819,\\\\nin\\\\nIndex.get_loc\\\\n(self, key)\\\\n3814\\\\nif\\\\nisinstance\\\\n(\\\\ncasted_key\\\\n,\\\\nslice\\\\n)\\\\nor\\\\n(\\\\n3815\\\\nisinstance\\\\n(\\\\ncasted_key\\\\n,\\\\nabc\\\\n.\\\\nIterable\\\\n)\\\\n3816\\\\nand\\\\nany\\\\n(\\\\nisinstance\\\\n(\\\\nx\\\\n,\\\\nslice\\\\n)\\\\nfor\\\\nx\\\\nin\\\\ncasted_key\\\\n)\\\\n3817\\\\n):\\\\n3818\\\\nraise\\\\nInvalidIndexError\\\\n(\\\\nkey\\\\n)\\\\n->\\\\n3819\\\\nraise\\\\nKeyError\\\\n(\\\\nkey\\\\n)\\\\nfrom\\\\nerr\\\\n3820\\\\nexcept\\\\nTypeError\\\\n:\\\\n3821\\\\n# If we have a listlike key, _check_indexing_error will raise\\\\n3822\\\\n#  InvalidIndexError. Otherwise we fall through and re-raise\\\\n3823\\\\n#  the TypeError.\\\\n3824\\\\nself\\\\n.\\\\n_check_indexing_error\\\\n(\\\\nkey\\\\n)\\\\nKeyError\\\\n: \\'f\\'\\\\nUsing the\\\\nSeries.get()\\\\nmethod, a missing label will return None or specified default:\\\\nIn [27]:\\\\ns\\\\n.\\\\nget\\\\n(\\\\n\"f\"\\\\n)\\\\nIn [28]:\\\\ns\\\\n.\\\\nget\\\\n(\\\\n\"f\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n)\\\\nOut[28]:\\\\nnan\\\\nThese labels can also be accessed by\\\\nattribute\\\\n.\\\\nVectorized operations and label alignment with Series\\\\n#\\\\nWhen working with raw NumPy arrays, looping through value-by-value is usually\\nnot necessary. The same is true when working with\\\\nSeries\\\\nin pandas.\\\\nSeries\\\\ncan also be passed into most NumPy methods expecting an ndarray.\\\\nIn [29]:\\\\ns\\\\n+\\\\ns\\\\nOut[29]:\\\\na     0.938225\\\\nb    -0.565727\\\\nc    -3.018117\\\\nd    -2.271265\\\\ne    24.000000\\\\ndtype: float64\\\\nIn [30]:\\\\ns\\\\n*\\\\n2\\\\nOut[30]:\\\\na     0.938225\\\\nb    -0.565727\\\\nc    -3.018117\\\\nd    -2.271265\\\\ne    24.000000\\\\ndtype: float64\\\\nIn [31]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\ns\\\\n)\\\\nOut[31]:\\\\na         1.598575\\\\nb         0.753623\\\\nc         0.221118\\\\nd         0.321219\\\\ne    162754.791419\\\\ndtype: float64\\\\nA key difference between\\\\nSeries\\\\nand ndarray is that operations between\\\\nSeries\\\\nautomatically align the data based on label. Thus, you can write computations\\nwithout giving consideration to whether the\\\\nSeries\\\\ninvolved have the same\\nlabels.\\\\nIn [32]:\\\\ns\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n:]\\\\n+\\\\ns\\\\n.\\\\niloc\\\\n[:\\\\n-\\\\n1\\\\n]\\\\nOut[32]:\\\\na         NaN\\\\nb   -0.565727\\\\nc   -3.018117\\\\nd   -2.271265\\\\ne         NaN\\\\ndtype: float64\\\\nThe result of an operation between unaligned\\\\nSeries\\\\nwill have the\\\\nunion\\\\nof\\nthe indexes involved. If a label is not found in one\\\\nSeries\\\\nor the other, the\\nresult will be marked as missing\\\\nNaN\\\\n. Being able to write code without doing\\nany explicit data alignment grants immense freedom and flexibility in\\ninteractive data analysis and research. The integrated data alignment features\\nof the pandas data structures set pandas apart from the majority of related\\ntools for working with labeled data.\\\\nNote\\\\nIn general, we chose to make the default result of operations between\\ndifferently indexed objects yield the\\\\nunion\\\\nof the indexes in order to\\navoid loss of information. Having an index label, though the data is\\nmissing, is typically important information as part of a computation. You\\nof course have the option of dropping labels with missing data via the\\\\ndropna\\\\nfunction.\\\\nName attribute\\\\n#\\\\nSeries\\\\nalso has a\\\\nname\\\\nattribute:\\\\nIn [33]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nname\\\\n=\\\\n\"something\"\\\\n)\\\\nIn [34]:\\\\ns\\\\nOut[34]:\\\\n0   -0.494929\\\\n1    1.071804\\\\n2    0.721555\\\\n3   -0.706771\\\\n4   -1.039575\\\\nName: something, dtype: float64\\\\nIn [35]:\\\\ns\\\\n.\\\\nname\\\\nOut[35]:\\\\n\\'something\\'\\\\nThe\\\\nSeries\\\\nname\\\\ncan be assigned automatically in many cases, in particular,\\nwhen selecting a single column from a\\\\nDataFrame\\\\n, the\\\\nname\\\\nwill be assigned\\nthe column label.\\\\nYou can rename a\\\\nSeries\\\\nwith the\\\\npandas.Series.rename()\\\\nmethod.\\\\nIn [36]:\\\\ns2\\\\n=\\\\ns\\\\n.\\\\nrename\\\\n(\\\\n\"different\"\\\\n)\\\\nIn [37]:\\\\ns2\\\\n.\\\\nname\\\\nOut[37]:\\\\n\\'different\\'\\\\nNote that\\\\ns\\\\nand\\\\ns2\\\\nrefer to different objects.\\\\nDataFrame\\\\n#\\\\nDataFrame\\\\nis a 2-dimensional labeled data structure with columns of\\npotentially different types. You can think of it like a spreadsheet or SQL\\ntable, or a dict of Series objects. It is generally the most commonly used\\npandas object. Like Series, DataFrame accepts many different kinds of input:\\\\nDict of 1D ndarrays, lists, dicts, or\\\\nSeries\\\\n2-D numpy.ndarray\\\\nStructured or record\\\\nndarray\\\\nA\\\\nSeries\\\\nAnother\\\\nDataFrame\\\\nAlong with the data, you can optionally pass\\\\nindex\\\\n(row labels) and\\\\ncolumns\\\\n(column labels) arguments. If you pass an index and / or columns,\\nyou are guaranteeing the index and / or columns of the resulting\\nDataFrame. Thus, a dict of Series plus a specific index will discard all data\\nnot matching up to the passed index.\\\\nIf axis labels are not passed, they will be constructed from the input data\\nbased on common sense rules.\\\\nFrom dict of Series or dicts\\\\n#\\\\nThe resulting\\\\nindex\\\\nwill be the\\\\nunion\\\\nof the indexes of the various\\nSeries. If there are any nested dicts, these will first be converted to\\nSeries. If no columns are passed, the columns will be the ordered list of dict\\nkeys.\\\\nIn [38]:\\\\nd\\\\n=\\\\n{\\\\n....:\\\\n\"one\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]),\\\\n....:\\\\n\"two\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n....:\\\\n}\\\\n....:\\\\nIn [39]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n)\\\\nIn [40]:\\\\ndf\\\\nOut[40]:\\\\none  two\\\\na  1.0  1.0\\\\nb  2.0  2.0\\\\nc  3.0  3.0\\\\nd  NaN  4.0\\\\nIn [41]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"d\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n])\\\\nOut[41]:\\\\none  two\\\\nd  NaN  4.0\\\\nb  2.0  2.0\\\\na  1.0  1.0\\\\nIn [42]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"d\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n])\\\\nOut[42]:\\\\ntwo three\\\\nd  4.0   NaN\\\\nb  2.0   NaN\\\\na  1.0   NaN\\\\nThe row and column labels can be accessed respectively by accessing the\\\\nindex\\\\nand\\\\ncolumns\\\\nattributes:\\\\nNote\\\\nWhen a particular set of columns is passed along with a dict of data, the\\npassed columns override the keys in the dict.\\\\nIn [43]:\\\\ndf\\\\n.\\\\nindex\\\\nOut[43]:\\\\nIndex([\\'a\\', \\'b\\', \\'c\\', \\'d\\'], dtype=\\'object\\')\\\\nIn [44]:\\\\ndf\\\\n.\\\\ncolumns\\\\nOut[44]:\\\\nIndex([\\'one\\', \\'two\\'], dtype=\\'object\\')\\\\nFrom dict of ndarrays / lists\\\\n#\\\\nAll ndarrays must share the same length. If an index is passed, it must\\nalso be the same length as the arrays. If no index is passed, the\\nresult will be\\\\nrange(n)\\\\n, where\\\\nn\\\\nis the array length.\\\\nIn [45]:\\\\nd\\\\n=\\\\n{\\\\n\"one\"\\\\n:\\\\n[\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n],\\\\n\"two\"\\\\n:\\\\n[\\\\n4.0\\\\n,\\\\n3.0\\\\n,\\\\n2.0\\\\n,\\\\n1.0\\\\n]}\\\\nIn [46]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n)\\\\nOut[46]:\\\\none  two\\\\n0  1.0  4.0\\\\n1  2.0  3.0\\\\n2  3.0  2.0\\\\n3  4.0  1.0\\\\nIn [47]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nd\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n])\\\\nOut[47]:\\\\none  two\\\\na  1.0  4.0\\\\nb  2.0  3.0\\\\nc  3.0  2.0\\\\nd  4.0  1.0\\\\nFrom structured or record array\\\\n#\\\\nThis case is handled identically to a dict of arrays.\\\\nIn [48]:\\\\ndata\\\\n=\\\\nnp\\\\n.\\\\nzeros\\\\n((\\\\n2\\\\n,),\\\\ndtype\\\\n=\\\\n[(\\\\n\"A\"\\\\n,\\\\n\"i4\"\\\\n),\\\\n(\\\\n\"B\"\\\\n,\\\\n\"f4\"\\\\n),\\\\n(\\\\n\"C\"\\\\n,\\\\n\"a10\"\\\\n)])\\\\nIn [49]:\\\\ndata\\\\n[:]\\\\n=\\\\n[(\\\\n1\\\\n,\\\\n2.0\\\\n,\\\\n\"Hello\"\\\\n),\\\\n(\\\\n2\\\\n,\\\\n3.0\\\\n,\\\\n\"World\"\\\\n)]\\\\nIn [50]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n)\\\\nOut[50]:\\\\nA    B         C\\\\n0  1  2.0  b\\'Hello\\'\\\\n1  2  3.0  b\\'World\\'\\\\nIn [51]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n])\\\\nOut[51]:\\\\nA    B         C\\\\nfirst   1  2.0  b\\'Hello\\'\\\\nsecond  2  3.0  b\\'World\\'\\\\nIn [52]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"C\"\\\\n,\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n])\\\\nOut[52]:\\\\nC  A    B\\\\n0  b\\'Hello\\'  1  2.0\\\\n1  b\\'World\\'  2  3.0\\\\nNote\\\\nDataFrame is not intended to work exactly like a 2-dimensional NumPy\\nndarray.\\\\nFrom a list of dicts\\\\n#\\\\nIn [53]:\\\\ndata2\\\\n=\\\\n[{\\\\n\"a\"\\\\n:\\\\n1\\\\n,\\\\n\"b\"\\\\n:\\\\n2\\\\n},\\\\n{\\\\n\"a\"\\\\n:\\\\n5\\\\n,\\\\n\"b\"\\\\n:\\\\n10\\\\n,\\\\n\"c\"\\\\n:\\\\n20\\\\n}]\\\\nIn [54]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata2\\\\n)\\\\nOut[54]:\\\\na   b     c\\\\n0  1   2   NaN\\\\n1  5  10  20.0\\\\nIn [55]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata2\\\\n,\\\\nindex\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n])\\\\nOut[55]:\\\\na   b     c\\\\nfirst   1   2   NaN\\\\nsecond  5  10  20.0\\\\nIn [56]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata2\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n])\\\\nOut[56]:\\\\na   b\\\\n0  1   2\\\\n1  5  10\\\\nFrom a dict of tuples\\\\n#\\\\nYou can automatically create a MultiIndexed frame by passing a tuples\\ndictionary.\\\\nIn [57]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n(\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n1\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n2\\\\n},\\\\n....:\\\\n(\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n3\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n4\\\\n},\\\\n....:\\\\n(\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n5\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n6\\\\n},\\\\n....:\\\\n(\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"C\"\\\\n):\\\\n7\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n8\\\\n},\\\\n....:\\\\n(\\\\n\"b\"\\\\n,\\\\n\"b\"\\\\n):\\\\n{(\\\\n\"A\"\\\\n,\\\\n\"D\"\\\\n):\\\\n9\\\\n,\\\\n(\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n):\\\\n10\\\\n},\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nOut[57]:\\\\na              b\\\\nb    a    c    a     b\\\\nA B  1.0  4.0  5.0  8.0  10.0\\\\nC  2.0  3.0  6.0  7.0   NaN\\\\nD  NaN  NaN  NaN  NaN   9.0\\\\nFrom a Series\\\\n#\\\\nThe result will be a DataFrame with the same index as the input Series, and\\nwith one column whose name is the original name of the Series (only if no other\\ncolumn name provided).\\\\nIn [58]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nrange\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\n\"abc\"\\\\n),\\\\nname\\\\n=\\\\n\"ser\"\\\\n)\\\\nIn [59]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nser\\\\n)\\\\nOut[59]:\\\\nser\\\\na    0\\\\nb    1\\\\nc    2\\\\nFrom a list of namedtuples\\\\n#\\\\nThe field names of the first\\\\nnamedtuple\\\\nin the list determine the columns\\nof the\\\\nDataFrame\\\\n. The remaining namedtuples (or tuples) are simply unpacked\\nand their values are fed into the rows of the\\\\nDataFrame\\\\n. If any of those\\ntuples is shorter than the first\\\\nnamedtuple\\\\nthen the later columns in the\\ncorresponding row are marked as missing values. If any are longer than the\\nfirst\\\\nnamedtuple\\\\n, a\\\\nValueError\\\\nis raised.\\\\nIn [60]:\\\\nfrom\\\\ncollections\\\\nimport\\\\nnamedtuple\\\\nIn [61]:\\\\nPoint\\\\n=\\\\nnamedtuple\\\\n(\\\\n\"Point\"\\\\n,\\\\n\"x y\"\\\\n)\\\\nIn [62]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n0\\\\n),\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n3\\\\n),\\\\n(\\\\n2\\\\n,\\\\n3\\\\n)])\\\\nOut[62]:\\\\nx  y\\\\n0  0  0\\\\n1  0  3\\\\n2  2  3\\\\nIn [63]:\\\\nPoint3D\\\\n=\\\\nnamedtuple\\\\n(\\\\n\"Point3D\"\\\\n,\\\\n\"x y z\"\\\\n)\\\\nIn [64]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\nPoint3D\\\\n(\\\\n0\\\\n,\\\\n0\\\\n,\\\\n0\\\\n),\\\\nPoint3D\\\\n(\\\\n0\\\\n,\\\\n3\\\\n,\\\\n5\\\\n),\\\\nPoint\\\\n(\\\\n2\\\\n,\\\\n3\\\\n)])\\\\nOut[64]:\\\\nx  y    z\\\\n0  0  0  0.0\\\\n1  0  3  5.0\\\\n2  2  3  NaN\\\\nFrom a list of dataclasses\\\\n#\\\\nData Classes as introduced in\\\\nPEP557\\\\n,\\ncan be passed into the DataFrame constructor.\\nPassing a list of dataclasses is equivalent to passing a list of dictionaries.\\\\nPlease be aware, that all values in the list should be dataclasses, mixing\\ntypes in the list would result in a\\\\nTypeError\\\\n.\\\\nIn [65]:\\\\nfrom\\\\ndataclasses\\\\nimport\\\\nmake_dataclass\\\\nIn [66]:\\\\nPoint\\\\n=\\\\nmake_dataclass\\\\n(\\\\n\"Point\"\\\\n,\\\\n[(\\\\n\"x\"\\\\n,\\\\nint\\\\n),\\\\n(\\\\n\"y\"\\\\n,\\\\nint\\\\n)])\\\\nIn [67]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n0\\\\n),\\\\nPoint\\\\n(\\\\n0\\\\n,\\\\n3\\\\n),\\\\nPoint\\\\n(\\\\n2\\\\n,\\\\n3\\\\n)])\\\\nOut[67]:\\\\nx  y\\\\n0  0  0\\\\n1  0  3\\\\n2  2  3\\\\nMissing data\\\\nTo construct a DataFrame with missing data, we use\\\\nnp.nan\\\\nto\\nrepresent missing values. Alternatively, you may pass a\\\\nnumpy.MaskedArray\\\\nas the data argument to the DataFrame constructor, and its masked entries will\\nbe considered missing. See\\\\nMissing data\\\\nfor more.\\\\nAlternate constructors\\\\n#\\\\nDataFrame.from_dict\\\\nDataFrame.from_dict()\\\\ntakes a dict of dicts or a dict of array-like sequences\\nand returns a DataFrame. It operates like the\\\\nDataFrame\\\\nconstructor except\\nfor the\\\\norient\\\\nparameter which is\\\\n\\'columns\\'\\\\nby default, but which can be\\nset to\\\\n\\'index\\'\\\\nin order to use the dict keys as row labels.\\\\nIn [68]:\\\\npd\\\\n.\\\\nDataFrame\\\\n.\\\\nfrom_dict\\\\n(\\\\ndict\\\\n([(\\\\n\"A\"\\\\n,\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]),\\\\n(\\\\n\"B\"\\\\n,\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n])]))\\\\nOut[68]:\\\\nA  B\\\\n0  1  4\\\\n1  2  5\\\\n2  3  6\\\\nIf you pass\\\\norient=\\'index\\'\\\\n, the keys will be the row labels. In this\\ncase, you can also pass the desired column names:\\\\nIn [69]:\\\\npd\\\\n.\\\\nDataFrame\\\\n.\\\\nfrom_dict\\\\n(\\\\n....:\\\\ndict\\\\n([(\\\\n\"A\"\\\\n,\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]),\\\\n(\\\\n\"B\"\\\\n,\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n])]),\\\\n....:\\\\norient\\\\n=\\\\n\"index\"\\\\n,\\\\n....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n],\\\\n....:\\\\n)\\\\n....:\\\\nOut[69]:\\\\none  two  three\\\\nA    1    2      3\\\\nB    4    5      6\\\\nDataFrame.from_records\\\\nDataFrame.from_records()\\\\ntakes a list of tuples or an ndarray with structured\\ndtype. It works analogously to the normal\\\\nDataFrame\\\\nconstructor, except that\\nthe resulting DataFrame index may be a specific field of the structured\\ndtype.\\\\nIn [70]:\\\\ndata\\\\nOut[70]:\\\\narray([(1, 2., b\\'Hello\\'), (2, 3., b\\'World\\')],\\\\ndtype=[(\\'A\\', \\'<i4\\'), (\\'B\\', \\'<f4\\'), (\\'C\\', \\'S10\\')])\\\\nIn [71]:\\\\npd\\\\n.\\\\nDataFrame\\\\n.\\\\nfrom_records\\\\n(\\\\ndata\\\\n,\\\\nindex\\\\n=\\\\n\"C\"\\\\n)\\\\nOut[71]:\\\\nA    B\\\\nC\\\\nb\\'Hello\\'  1  2.0\\\\nb\\'World\\'  2  3.0\\\\nColumn selection, addition, deletion\\\\n#\\\\nYou can treat a\\\\nDataFrame\\\\nsemantically like a dict of like-indexed\\\\nSeries\\\\nobjects. Getting, setting, and deleting columns works with the same syntax as\\nthe analogous dict operations:\\\\nIn [72]:\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\nOut[72]:\\\\na    1.0\\\\nb    2.0\\\\nc    3.0\\\\nd    NaN\\\\nName: one, dtype: float64\\\\nIn [73]:\\\\ndf\\\\n[\\\\n\"three\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\n*\\\\ndf\\\\n[\\\\n\"two\"\\\\n]\\\\nIn [74]:\\\\ndf\\\\n[\\\\n\"flag\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\n>\\\\n2\\\\nIn [75]:\\\\ndf\\\\nOut[75]:\\\\none  two  three   flag\\\\na  1.0  1.0    1.0  False\\\\nb  2.0  2.0    4.0  False\\\\nc  3.0  3.0    9.0   True\\\\nd  NaN  4.0    NaN  False\\\\nColumns can be deleted or popped like with a dict:\\\\nIn [76]:\\\\ndel\\\\ndf\\\\n[\\\\n\"two\"\\\\n]\\\\nIn [77]:\\\\nthree\\\\n=\\\\ndf\\\\n.\\\\npop\\\\n(\\\\n\"three\"\\\\n)\\\\nIn [78]:\\\\ndf\\\\nOut[78]:\\\\none   flag\\\\na  1.0  False\\\\nb  2.0  False\\\\nc  3.0   True\\\\nd  NaN  False\\\\nWhen inserting a scalar value, it will naturally be propagated to fill the\\ncolumn:\\\\nIn [79]:\\\\ndf\\\\n[\\\\n\"foo\"\\\\n]\\\\n=\\\\n\"bar\"\\\\nIn [80]:\\\\ndf\\\\nOut[80]:\\\\none   flag  foo\\\\na  1.0  False  bar\\\\nb  2.0  False  bar\\\\nc  3.0   True  bar\\\\nd  NaN  False  bar\\\\nWhen inserting a\\\\nSeries\\\\nthat does not have the same index as the\\\\nDataFrame\\\\n, it\\nwill be conformed to the DataFrame’s index:\\\\nIn [81]:\\\\ndf\\\\n[\\\\n\"one_trunc\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"one\"\\\\n][:\\\\n2\\\\n]\\\\nIn [82]:\\\\ndf\\\\nOut[82]:\\\\none   flag  foo  one_trunc\\\\na  1.0  False  bar        1.0\\\\nb  2.0  False  bar        2.0\\\\nc  3.0   True  bar        NaN\\\\nd  NaN  False  bar        NaN\\\\nYou can insert raw ndarrays but their length must match the length of the\\nDataFrame’s index.\\\\nBy default, columns get inserted at the end.\\\\nDataFrame.insert()\\\\ninserts at a particular location in the columns:\\\\nIn [83]:\\\\ndf\\\\n.\\\\ninsert\\\\n(\\\\n1\\\\n,\\\\n\"bar\"\\\\n,\\\\ndf\\\\n[\\\\n\"one\"\\\\n])\\\\nIn [84]:\\\\ndf\\\\nOut[84]:\\\\none  bar   flag  foo  one_trunc\\\\na  1.0  1.0  False  bar        1.0\\\\nb  2.0  2.0  False  bar        2.0\\\\nc  3.0  3.0   True  bar        NaN\\\\nd  NaN  NaN  False  bar        NaN\\\\nAssigning new columns in method chains\\\\n#\\\\nInspired by\\\\ndplyr’s\\\\nmutate\\\\nverb, DataFrame has an\\\\nassign()\\\\nmethod that allows you to easily create new columns that are potentially\\nderived from existing columns.\\\\nIn [85]:\\\\niris\\\\n=\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"data/iris.data\"\\\\n)\\\\nIn [86]:\\\\niris\\\\n.\\\\nhead\\\\n()\\\\nOut[86]:\\\\nSepalLength  SepalWidth  PetalLength  PetalWidth         Name\\\\n0          5.1         3.5          1.4         0.2  Iris-setosa\\\\n1          4.9         3.0          1.4         0.2  Iris-setosa\\\\n2          4.7         3.2          1.3         0.2  Iris-setosa\\\\n3          4.6         3.1          1.5         0.2  Iris-setosa\\\\n4          5.0         3.6          1.4         0.2  Iris-setosa\\\\nIn [87]:\\\\niris\\\\n.\\\\nassign\\\\n(\\\\nsepal_ratio\\\\n=\\\\niris\\\\n[\\\\n\"SepalWidth\"\\\\n]\\\\n/\\\\niris\\\\n[\\\\n\"SepalLength\"\\\\n])\\\\n.\\\\nhead\\\\n()\\\\nOut[87]:\\\\nSepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio\\\\n0          5.1         3.5          1.4         0.2  Iris-setosa     0.686275\\\\n1          4.9         3.0          1.4         0.2  Iris-setosa     0.612245\\\\n2          4.7         3.2          1.3         0.2  Iris-setosa     0.680851\\\\n3          4.6         3.1          1.5         0.2  Iris-setosa     0.673913\\\\n4          5.0         3.6          1.4         0.2  Iris-setosa     0.720000\\\\nIn the example above, we inserted a precomputed value. We can also pass in\\na function of one argument to be evaluated on the DataFrame being assigned to.\\\\nIn [88]:\\\\niris\\\\n.\\\\nassign\\\\n(\\\\nsepal_ratio\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\n(\\\\nx\\\\n[\\\\n\"SepalWidth\"\\\\n]\\\\n/\\\\nx\\\\n[\\\\n\"SepalLength\"\\\\n]))\\\\n.\\\\nhead\\\\n()\\\\nOut[88]:\\\\nSepalLength  SepalWidth  PetalLength  PetalWidth         Name  sepal_ratio\\\\n0          5.1         3.5          1.4         0.2  Iris-setosa     0.686275\\\\n1          4.9         3.0          1.4         0.2  Iris-setosa     0.612245\\\\n2          4.7         3.2          1.3         0.2  Iris-setosa     0.680851\\\\n3          4.6         3.1          1.5         0.2  Iris-setosa     0.673913\\\\n4          5.0         3.6          1.4         0.2  Iris-setosa     0.720000\\\\nassign()\\\\nalways\\\\nreturns a copy of the data, leaving the original\\nDataFrame untouched.\\\\nPassing a callable, as opposed to an actual value to be inserted, is\\nuseful when you don’t have a reference to the DataFrame at hand. This is\\ncommon when using\\\\nassign()\\\\nin a chain of operations. For example,\\nwe can limit the DataFrame to just those observations with a Sepal Length\\ngreater than 5, calculate the ratio, and plot:\\\\nIn [89]:\\\\n(\\\\n....:\\\\niris\\\\n.\\\\nquery\\\\n(\\\\n\"SepalLength > 5\"\\\\n)\\\\n....:\\\\n.\\\\nassign\\\\n(\\\\n....:\\\\nSepalRatio\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nSepalWidth\\\\n/\\\\nx\\\\n.\\\\nSepalLength\\\\n,\\\\n....:\\\\nPetalRatio\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nPetalWidth\\\\n/\\\\nx\\\\n.\\\\nPetalLength\\\\n,\\\\n....:\\\\n)\\\\n....:\\\\n.\\\\nplot\\\\n(\\\\nkind\\\\n=\\\\n\"scatter\"\\\\n,\\\\nx\\\\n=\\\\n\"SepalRatio\"\\\\n,\\\\ny\\\\n=\\\\n\"PetalRatio\"\\\\n)\\\\n....:\\\\n)\\\\n....:\\\\nOut[89]:\\\\n<Axes: xlabel=\\'SepalRatio\\', ylabel=\\'PetalRatio\\'>\\\\nSince a function is passed in, the function is computed on the DataFrame\\nbeing assigned to. Importantly, this is the DataFrame that’s been filtered\\nto those rows with sepal length greater than 5. The filtering happens first,\\nand then the ratio calculations. This is an example where we didn’t\\nhave a reference to the\\\\nfiltered\\\\nDataFrame available.\\\\nThe function signature for\\\\nassign()\\\\nis simply\\\\n**kwargs\\\\n. The keys\\nare the column names for the new fields, and the values are either a value\\nto be inserted (for example, a\\\\nSeries\\\\nor NumPy array), or a function\\nof one argument to be called on the\\\\nDataFrame\\\\n. A\\\\ncopy\\\\nof the original\\\\nDataFrame\\\\nis returned, with the new values inserted.\\\\nThe order of\\\\n**kwargs\\\\nis preserved. This allows\\nfor\\\\ndependent\\\\nassignment, where an expression later in\\\\n**kwargs\\\\ncan refer\\nto a column created earlier in the same\\\\nassign()\\\\n.\\\\nIn [90]:\\\\ndfa\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"A\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"B\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n]})\\\\nIn [91]:\\\\ndfa\\\\n.\\\\nassign\\\\n(\\\\nC\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n[\\\\n\"A\"\\\\n]\\\\n+\\\\nx\\\\n[\\\\n\"B\"\\\\n],\\\\nD\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n[\\\\n\"A\"\\\\n]\\\\n+\\\\nx\\\\n[\\\\n\"C\"\\\\n])\\\\nOut[91]:\\\\nA  B  C   D\\\\n0  1  4  5   6\\\\n1  2  5  7   9\\\\n2  3  6  9  12\\\\nIn the second expression,\\\\nx[\\'C\\']\\\\nwill refer to the newly created column,\\nthat’s equal to\\\\ndfa[\\'A\\']\\\\n+\\\\ndfa[\\'B\\']\\\\n.\\\\nIndexing / selection\\\\n#\\\\nThe basics of indexing are as follows:\\\\nOperation\\\\nSyntax\\\\nResult\\\\nSelect column\\\\ndf[col]\\\\nSeries\\\\nSelect row by label\\\\ndf.loc[label]\\\\nSeries\\\\nSelect row by integer location\\\\ndf.iloc[loc]\\\\nSeries\\\\nSlice rows\\\\ndf[5:10]\\\\nDataFrame\\\\nSelect rows by boolean vector\\\\ndf[bool_vec]\\\\nDataFrame\\\\nRow selection, for example, returns a\\\\nSeries\\\\nwhose index is the columns of the\\\\nDataFrame\\\\n:\\\\nIn [92]:\\\\ndf\\\\n.\\\\nloc\\\\n[\\\\n\"b\"\\\\n]\\\\nOut[92]:\\\\none            2.0\\\\nbar            2.0\\\\nflag         False\\\\nfoo            bar\\\\none_trunc      2.0\\\\nName: b, dtype: object\\\\nIn [93]:\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n2\\\\n]\\\\nOut[93]:\\\\none           3.0\\\\nbar           3.0\\\\nflag         True\\\\nfoo           bar\\\\none_trunc     NaN\\\\nName: c, dtype: object\\\\nFor a more exhaustive treatment of sophisticated label-based indexing and\\nslicing, see the\\\\nsection on indexing\\\\n. We will address the\\nfundamentals of reindexing / conforming to new sets of labels in the\\\\nsection on reindexing\\\\n.\\\\nData alignment and arithmetic\\\\n#\\\\nData alignment between\\\\nDataFrame\\\\nobjects automatically align on\\\\nboth the\\ncolumns and the index (row labels)\\\\n. Again, the resulting object will have the\\nunion of the column and row labels.\\\\nIn [94]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n4\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"D\"\\\\n])\\\\nIn [95]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n7\\\\n,\\\\n3\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n])\\\\nIn [96]:\\\\ndf\\\\n+\\\\ndf2\\\\nOut[96]:\\\\nA         B         C   D\\\\n0  0.045691 -0.014138  1.380871 NaN\\\\n1 -0.955398 -1.501007  0.037181 NaN\\\\n2 -0.662690  1.534833 -0.859691 NaN\\\\n3 -2.452949  1.237274 -0.133712 NaN\\\\n4  1.414490  1.951676 -2.320422 NaN\\\\n5 -0.494922 -1.649727 -1.084601 NaN\\\\n6 -1.047551 -0.748572 -0.805479 NaN\\\\n7       NaN       NaN       NaN NaN\\\\n8       NaN       NaN       NaN NaN\\\\n9       NaN       NaN       NaN NaN\\\\nWhen doing an operation between\\\\nDataFrame\\\\nand\\\\nSeries\\\\n, the default behavior is\\nto align the\\\\nSeries\\\\nindex\\\\non the\\\\nDataFrame\\\\ncolumns\\\\n, thus\\\\nbroadcasting\\\\nrow-wise. For example:\\\\nIn [97]:\\\\ndf\\\\n-\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n0\\\\n]\\\\nOut[97]:\\\\nA         B         C         D\\\\n0  0.000000  0.000000  0.000000  0.000000\\\\n1 -1.359261 -0.248717 -0.453372 -1.754659\\\\n2  0.253128  0.829678  0.010026 -1.991234\\\\n3 -1.311128  0.054325 -1.724913 -1.620544\\\\n4  0.573025  1.500742 -0.676070  1.367331\\\\n5 -1.741248  0.781993 -1.241620 -2.053136\\\\n6 -1.240774 -0.869551 -0.153282  0.000430\\\\n7 -0.743894  0.411013 -0.929563 -0.282386\\\\n8 -1.194921  1.320690  0.238224 -1.482644\\\\n9  2.293786  1.856228  0.773289 -1.446531\\\\nFor explicit control over the matching and broadcasting behavior, see the\\nsection on\\\\nflexible binary operations\\\\n.\\\\nArithmetic operations with scalars operate element-wise:\\\\nIn [98]:\\\\ndf\\\\n*\\\\n5\\\\n+\\\\n2\\\\nOut[98]:\\\\nA         B         C          D\\\\n0   3.359299 -0.124862  4.835102   3.381160\\\\n1  -3.437003 -1.368449  2.568242  -5.392133\\\\n2   4.624938  4.023526  4.885230  -6.575010\\\\n3  -3.196342  0.146766 -3.789461  -4.721559\\\\n4   6.224426  7.378849  1.454750  10.217815\\\\n5  -5.346940  3.785103 -1.373001  -6.884519\\\\n6  -2.844569 -4.472618  4.068691   3.383309\\\\n7  -0.360173  1.930201  0.187285   1.969232\\\\n8  -2.615303  6.478587  6.026220  -4.032059\\\\n9  14.828230  9.156280  8.701544  -3.851494\\\\nIn [99]:\\\\n1\\\\n/\\\\ndf\\\\nOut[99]:\\\\nA          B         C           D\\\\n0  3.678365  -2.353094  1.763605    3.620145\\\\n1 -0.919624  -1.484363  8.799067   -0.676395\\\\n2  1.904807   2.470934  1.732964   -0.583090\\\\n3 -0.962215  -2.697986 -0.863638   -0.743875\\\\n4  1.183593   0.929567 -9.170108    0.608434\\\\n5 -0.680555   2.800959 -1.482360   -0.562777\\\\n6 -1.032084  -0.772485  2.416988    3.614523\\\\n7 -2.118489 -71.634509 -2.758294 -162.507295\\\\n8 -1.083352   1.116424  1.241860   -0.828904\\\\n9  0.389765   0.698687  0.746097   -0.854483\\\\nIn [100]:\\\\ndf\\\\n**\\\\n4\\\\nOut[100]:\\\\nA             B         C             D\\\\n0   0.005462  3.261689e-02  0.103370  5.822320e-03\\\\n1   1.398165  2.059869e-01  0.000167  4.777482e+00\\\\n2   0.075962  2.682596e-02  0.110877  8.650845e+00\\\\n3   1.166571  1.887302e-02  1.797515  3.265879e+00\\\\n4   0.509555  1.339298e+00  0.000141  7.297019e+00\\\\n5   4.661717  1.624699e-02  0.207103  9.969092e+00\\\\n6   0.881334  2.808277e+00  0.029302  5.858632e-03\\\\n7   0.049647  3.797614e-08  0.017276  1.433866e-09\\\\n8   0.725974  6.437005e-01  0.420446  2.118275e+00\\\\n9  43.329821  4.196326e+00  3.227153  1.875802e+00\\\\nBoolean operators operate element-wise as well:\\\\nIn [101]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n0\\\\n,\\\\n1\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n0\\\\n,\\\\n1\\\\n,\\\\n1\\\\n]},\\\\ndtype\\\\n=\\\\nbool\\\\n)\\\\nIn [102]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n0\\\\n,\\\\n1\\\\n,\\\\n1\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n1\\\\n,\\\\n0\\\\n]},\\\\ndtype\\\\n=\\\\nbool\\\\n)\\\\nIn [103]:\\\\ndf1\\\\n&\\\\ndf2\\\\nOut[103]:\\\\na      b\\\\n0  False  False\\\\n1  False   True\\\\n2   True  False\\\\nIn [104]:\\\\ndf1\\\\n|\\\\ndf2\\\\nOut[104]:\\\\na     b\\\\n0  True  True\\\\n1  True  True\\\\n2  True  True\\\\nIn [105]:\\\\ndf1\\\\n^\\\\ndf2\\\\nOut[105]:\\\\na      b\\\\n0   True   True\\\\n1   True  False\\\\n2  False   True\\\\nIn [106]:\\\\n-\\\\ndf1\\\\nOut[106]:\\\\na      b\\\\n0  False   True\\\\n1   True  False\\\\n2  False  False\\\\nTransposing\\\\n#\\\\nTo transpose, access the\\\\nT\\\\nattribute or\\\\nDataFrame.transpose()\\\\n,\\nsimilar to an ndarray:\\\\n# only show the first 5 rows\\\\nIn [107]:\\\\ndf\\\\n[:\\\\n5\\\\n]\\\\n.\\\\nT\\\\nOut[107]:\\\\n0         1         2         3         4\\\\nA  0.271860 -1.087401  0.524988 -1.039268  0.844885\\\\nB -0.424972 -0.673690  0.404705 -0.370647  1.075770\\\\nC  0.567020  0.113648  0.577046 -1.157892 -0.109050\\\\nD  0.276232 -1.478427 -1.715002 -1.344312  1.643563\\\\nDataFrame interoperability with NumPy functions\\\\n#\\\\nMost NumPy functions can be called directly on\\\\nSeries\\\\nand\\\\nDataFrame\\\\n.\\\\nIn [108]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\ndf\\\\n)\\\\nOut[108]:\\\\nA         B         C         D\\\\n0   1.312403  0.653788  1.763006  1.318154\\\\n1   0.337092  0.509824  1.120358  0.227996\\\\n2   1.690438  1.498861  1.780770  0.179963\\\\n3   0.353713  0.690288  0.314148  0.260719\\\\n4   2.327710  2.932249  0.896686  5.173571\\\\n5   0.230066  1.429065  0.509360  0.169161\\\\n6   0.379495  0.274028  1.512461  1.318720\\\\n7   0.623732  0.986137  0.695904  0.993865\\\\n8   0.397301  2.449092  2.237242  0.299269\\\\n9  13.009059  4.183951  3.820223  0.310274\\\\nIn [109]:\\\\nnp\\\\n.\\\\nasarray\\\\n(\\\\ndf\\\\n)\\\\nOut[109]:\\\\narray([[ 0.2719, -0.425 ,  0.567 ,  0.2762],\\\\n[-1.0874, -0.6737,  0.1136, -1.4784],\\\\n[ 0.525 ,  0.4047,  0.577 , -1.715 ],\\\\n[-1.0393, -0.3706, -1.1579, -1.3443],\\\\n[ 0.8449,  1.0758, -0.109 ,  1.6436],\\\\n[-1.4694,  0.357 , -0.6746, -1.7769],\\\\n[-0.9689, -1.2945,  0.4137,  0.2767],\\\\n[-0.472 , -0.014 , -0.3625, -0.0062],\\\\n[-0.9231,  0.8957,  0.8052, -1.2064],\\\\n[ 2.5656,  1.4313,  1.3403, -1.1703]])\\\\nDataFrame\\\\nis not intended to be a drop-in replacement for ndarray as its\\nindexing semantics and data model are quite different in places from an n-dimensional\\narray.\\\\nSeries\\\\nimplements\\\\n__array_ufunc__\\\\n, which allows it to work with NumPy’s\\\\nuniversal functions\\\\n.\\\\nThe ufunc is applied to the underlying array in a\\\\nSeries\\\\n.\\\\nIn [110]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n])\\\\nIn [111]:\\\\nnp\\\\n.\\\\nexp\\\\n(\\\\nser\\\\n)\\\\nOut[111]:\\\\n0     2.718282\\\\n1     7.389056\\\\n2    20.085537\\\\n3    54.598150\\\\ndtype: float64\\\\nWhen multiple\\\\nSeries\\\\nare passed to a ufunc, they are aligned before\\nperforming the operation.\\\\nLike other parts of the library, pandas will automatically align labeled inputs\\nas part of a ufunc with multiple inputs. For example, using\\\\nnumpy.remainder()\\\\non two\\\\nSeries\\\\nwith differently ordered labels will align before the operation.\\\\nIn [112]:\\\\nser1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n])\\\\nIn [113]:\\\\nser2\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n3\\\\n,\\\\n5\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n])\\\\nIn [114]:\\\\nser1\\\\nOut[114]:\\\\na    1\\\\nb    2\\\\nc    3\\\\ndtype: int64\\\\nIn [115]:\\\\nser2\\\\nOut[115]:\\\\nb    1\\\\na    3\\\\nc    5\\\\ndtype: int64\\\\nIn [116]:\\\\nnp\\\\n.\\\\nremainder\\\\n(\\\\nser1\\\\n,\\\\nser2\\\\n)\\\\nOut[116]:\\\\na    1\\\\nb    0\\\\nc    3\\\\ndtype: int64\\\\nAs usual, the union of the two indices is taken, and non-overlapping values are filled\\nwith missing values.\\\\nIn [117]:\\\\nser3\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n2\\\\n,\\\\n4\\\\n,\\\\n6\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n])\\\\nIn [118]:\\\\nser3\\\\nOut[118]:\\\\nb    2\\\\nc    4\\\\nd    6\\\\ndtype: int64\\\\nIn [119]:\\\\nnp\\\\n.\\\\nremainder\\\\n(\\\\nser1\\\\n,\\\\nser3\\\\n)\\\\nOut[119]:\\\\na    NaN\\\\nb    0.0\\\\nc    3.0\\\\nd    NaN\\\\ndtype: float64\\\\nWhen a binary ufunc is applied to a\\\\nSeries\\\\nand\\\\nIndex\\\\n, the\\\\nSeries\\\\nimplementation takes precedence and a\\\\nSeries\\\\nis returned.\\\\nIn [120]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n])\\\\nIn [121]:\\\\nidx\\\\n=\\\\npd\\\\n.\\\\nIndex\\\\n([\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n])\\\\nIn [122]:\\\\nnp\\\\n.\\\\nmaximum\\\\n(\\\\nser\\\\n,\\\\nidx\\\\n)\\\\nOut[122]:\\\\n0    4\\\\n1    5\\\\n2    6\\\\ndtype: int64\\\\nNumPy ufuncs are safe to apply to\\\\nSeries\\\\nbacked by non-ndarray arrays,\\nfor example\\\\narrays.SparseArray\\\\n(see\\\\nSparse calculation\\\\n). If possible,\\nthe ufunc is applied without converting the underlying data to an ndarray.\\\\nConsole display\\\\n#\\\\nA very large\\\\nDataFrame\\\\nwill be truncated to display them in the console.\\nYou can also get a summary using\\\\ninfo()\\\\n.\\n(The\\\\nbaseball\\\\ndataset is from the\\\\nplyr\\\\nR package):\\\\nIn [123]:\\\\nbaseball\\\\n=\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"data/baseball.csv\"\\\\n)\\\\nIn [124]:\\\\nprint\\\\n(\\\\nbaseball\\\\n)\\\\nid     player  year  stint team  lg  ...    so  ibb  hbp   sh   sf  gidp\\\\n0   88641  womacto01  2006      2  CHN  NL  ...   4.0  0.0  0.0  3.0  0.0   0.0\\\\n1   88643  schilcu01  2006      1  BOS  AL  ...   1.0  0.0  0.0  0.0  0.0   0.0\\\\n..    ...        ...   ...    ...  ...  ..  ...   ...  ...  ...  ...  ...   ...\\\\n98  89533   aloumo01  2007      1  NYN  NL  ...  30.0  5.0  2.0  0.0  3.0  13.0\\\\n99  89534  alomasa02  2007      1  NYN  NL  ...   3.0  0.0  0.0  0.0  0.0   0.0\\\\n[100 rows x 23 columns]\\\\nIn [125]:\\\\nbaseball\\\\n.\\\\ninfo\\\\n()\\\\n<class \\'pandas.core.frame.DataFrame\\'>\\\\nRangeIndex: 100 entries, 0 to 99\\\\nData columns (total 23 columns):\\\\n#   Column  Non-Null Count  Dtype\\\\n---  ------  --------------  -----\\\\n0   id      100 non-null    int64\\\\n1   player  100 non-null    object\\\\n2   year    100 non-null    int64\\\\n3   stint   100 non-null    int64\\\\n4   team    100 non-null    object\\\\n5   lg      100 non-null    object\\\\n6   g       100 non-null    int64\\\\n7   ab      100 non-null    int64\\\\n8   r       100 non-null    int64\\\\n9   h       100 non-null    int64\\\\n10  X2b     100 non-null    int64\\\\n11  X3b     100 non-null    int64\\\\n12  hr      100 non-null    int64\\\\n13  rbi     100 non-null    float64\\\\n14  sb      100 non-null    float64\\\\n15  cs      100 non-null    float64\\\\n16  bb      100 non-null    int64\\\\n17  so      100 non-null    float64\\\\n18  ibb     100 non-null    float64\\\\n19  hbp     100 non-null    float64\\\\n20  sh      100 non-null    float64\\\\n21  sf      100 non-null    float64\\\\n22  gidp    100 non-null    float64\\\\ndtypes: float64(9), int64(11), object(3)\\\\nmemory usage: 18.1+ KB\\\\nHowever, using\\\\nDataFrame.to_string()\\\\nwill return a string representation of the\\\\nDataFrame\\\\nin tabular form, though it won’t always fit the console width:\\\\nIn [126]:\\\\nprint\\\\n(\\\\nbaseball\\\\n.\\\\niloc\\\\n[\\\\n-\\\\n20\\\\n:,\\\\n:\\\\n12\\\\n]\\\\n.\\\\nto_string\\\\n())\\\\nid     player  year  stint team  lg    g   ab   r    h  X2b  X3b\\\\n80  89474  finlest01  2007      1  COL  NL   43   94   9   17    3    0\\\\n81  89480  embreal01  2007      1  OAK  AL    4    0   0    0    0    0\\\\n82  89481  edmonji01  2007      1  SLN  NL  117  365  39   92   15    2\\\\n83  89482  easleda01  2007      1  NYN  NL   76  193  24   54    6    0\\\\n84  89489  delgaca01  2007      1  NYN  NL  139  538  71  139   30    0\\\\n85  89493  cormirh01  2007      1  CIN  NL    6    0   0    0    0    0\\\\n86  89494  coninje01  2007      2  NYN  NL   21   41   2    8    2    0\\\\n87  89495  coninje01  2007      1  CIN  NL   80  215  23   57   11    1\\\\n88  89497  clemero02  2007      1  NYA  AL    2    2   0    1    0    0\\\\n89  89498  claytro01  2007      2  BOS  AL    8    6   1    0    0    0\\\\n90  89499  claytro01  2007      1  TOR  AL   69  189  23   48   14    0\\\\n91  89501  cirilje01  2007      2  ARI  NL   28   40   6    8    4    0\\\\n92  89502  cirilje01  2007      1  MIN  AL   50  153  18   40    9    2\\\\n93  89521  bondsba01  2007      1  SFN  NL  126  340  75   94   14    0\\\\n94  89523  biggicr01  2007      1  HOU  NL  141  517  68  130   31    3\\\\n95  89525  benitar01  2007      2  FLO  NL   34    0   0    0    0    0\\\\n96  89526  benitar01  2007      1  SFN  NL   19    0   0    0    0    0\\\\n97  89530  ausmubr01  2007      1  HOU  NL  117  349  38   82   16    3\\\\n98  89533   aloumo01  2007      1  NYN  NL   87  328  51  112   19    1\\\\n99  89534  alomasa02  2007      1  NYN  NL    8   22   1    3    1    0\\\\nWide DataFrames will be printed across multiple rows by\\ndefault:\\\\nIn [127]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n,\\\\n12\\\\n))\\\\nOut[127]:\\\\n0         1         2   ...        9         10        11\\\\n0 -1.226825  0.769804 -1.281247  ... -1.110336 -0.619976  0.149748\\\\n1 -0.732339  0.687738  0.176444  ...  1.462696 -1.743161 -0.826591\\\\n2 -0.345352  1.314232  0.690579  ...  0.896171 -0.487602 -0.082240\\\\n[3 rows x 12 columns]\\\\nYou can change how much to print on a single row by setting the\\\\ndisplay.width\\\\noption:\\\\nIn [128]:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"display.width\"\\\\n,\\\\n40\\\\n)\\\\n# default is 80\\\\nIn [129]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n,\\\\n12\\\\n))\\\\nOut[129]:\\\\n0         1         2   ...        9         10        11\\\\n0 -2.182937  0.380396  0.084844  ... -0.023688  2.410179  1.450520\\\\n1  0.206053 -0.251905 -2.213588  ... -0.025747 -0.988387  0.094055\\\\n2  1.262731  1.289997  0.082423  ... -0.281461  0.030711  0.109121\\\\n[3 rows x 12 columns]\\\\nYou can adjust the max width of the individual columns by setting\\\\ndisplay.max_colwidth\\\\nIn [130]:\\\\ndatafile\\\\n=\\\\n{\\\\n.....:\\\\n\"filename\"\\\\n:\\\\n[\\\\n\"filename_01\"\\\\n,\\\\n\"filename_02\"\\\\n],\\\\n.....:\\\\n\"path\"\\\\n:\\\\n[\\\\n.....:\\\\n\"media/user_name/storage/folder_01/filename_01\"\\\\n,\\\\n.....:\\\\n\"media/user_name/storage/folder_02/filename_02\"\\\\n,\\\\n.....:\\\\n],\\\\n.....:\\\\n}\\\\n.....:\\\\nIn [131]:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"display.max_colwidth\"\\\\n,\\\\n30\\\\n)\\\\nIn [132]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndatafile\\\\n)\\\\nOut[132]:\\\\nfilename                           path\\\\n0  filename_01  media/user_name/storage/fo...\\\\n1  filename_02  media/user_name/storage/fo...\\\\nIn [133]:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"display.max_colwidth\"\\\\n,\\\\n100\\\\n)\\\\nIn [134]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndatafile\\\\n)\\\\nOut[134]:\\\\nfilename                                           path\\\\n0  filename_01  media/user_name/storage/folder_01/filename_01\\\\n1  filename_02  media/user_name/storage/folder_02/filename_02\\\\nYou can also disable this feature via the\\\\nexpand_frame_repr\\\\noption.\\nThis will print the table in one block.\\\\nDataFrame column attribute access and IPython completion\\\\n#\\\\nIf a\\\\nDataFrame\\\\ncolumn label is a valid Python variable name, the column can be\\naccessed like an attribute:\\\\nIn [135]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"foo1\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\n\"foo2\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n)})\\\\nIn [136]:\\\\ndf\\\\nOut[136]:\\\\nfoo1      foo2\\\\n0  1.126203  0.781836\\\\n1 -0.977349 -1.071357\\\\n2  1.474071  0.441153\\\\n3 -0.064034  2.353925\\\\n4 -1.282782  0.583787\\\\nIn [137]:\\\\ndf\\\\n.\\\\nfoo1\\\\nOut[137]:\\\\n0    1.126203\\\\n1   -0.977349\\\\n2    1.474071\\\\n3   -0.064034\\\\n4   -1.282782\\\\nName: foo1, dtype: float64\\\\nThe columns are also connected to the\\\\nIPython\\\\ncompletion mechanism so they can be tab-completed:\\\\nIn [5]:\\\\ndf\\\\n.\\\\nfoo\\\\n<\\\\nTAB\\\\n>\\\\n# noqa: E225, E999\\\\ndf.foo1  df.foo2\\\\nprevious\\\\n10 minutes to pandas\\\\nnext\\\\nEssential basic functionality\\\\nOn this page\\\\nSeries\\\\nSeries is ndarray-like\\\\nSeries is dict-like\\\\nVectorized operations and label alignment with Series\\\\nName attribute\\\\nDataFrame\\\\nFrom dict of Series or dicts\\\\nFrom dict of ndarrays / lists\\\\nFrom structured or record array\\\\nFrom a list of dicts\\\\nFrom a dict of tuples\\\\nFrom a Series\\\\nFrom a list of namedtuples\\\\nFrom a list of dataclasses\\\\nAlternate constructors\\\\nColumn selection, addition, deletion\\\\nAssigning new columns in method chains\\\\nIndexing / selection\\\\nData alignment and arithmetic\\\\nTransposing\\\\nDataFrame interoperability with NumPy functions\\\\nConsole display\\\\nDataFrame column attribute access and IPython completion\\\\nShow Source\\\\n\\\\n--- Page Break ---\\\\n\\\\nUser Guide\\\\nEssential...\\\\nEssential basic functionality\\\\n#\\\\nHere we discuss a lot of the essential functionality common to the pandas data\\nstructures. To begin, let’s create some example objects like we did in\\nthe\\\\n10 minutes to pandas\\\\nsection:\\\\nIn [1]:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n8\\\\n)\\\\nIn [2]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [3]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n,\\\\n3\\\\n),\\\\nindex\\\\n=\\\\nindex\\\\n,\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n])\\\\nHead and tail\\\\n#\\\\nTo view a small sample of a Series or DataFrame object, use the\\\\nhead()\\\\nand\\\\ntail()\\\\nmethods. The default number\\nof elements to display is five, but you may pass a custom number.\\\\nIn [4]:\\\\nlong_series\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n))\\\\nIn [5]:\\\\nlong_series\\\\n.\\\\nhead\\\\n()\\\\nOut[5]:\\\\n0   -1.157892\\\\n1   -1.344312\\\\n2    0.844885\\\\n3    1.075770\\\\n4   -0.109050\\\\ndtype: float64\\\\nIn [6]:\\\\nlong_series\\\\n.\\\\ntail\\\\n(\\\\n3\\\\n)\\\\nOut[6]:\\\\n997   -0.289388\\\\n998   -1.020544\\\\n999    0.589993\\\\ndtype: float64\\\\nAttributes and underlying data\\\\n#\\\\npandas objects have a number of attributes enabling you to access the metadata\\\\nshape\\\\n: gives the axis dimensions of the object, consistent with ndarray\\\\nAxis labels\\\\nSeries\\\\n:\\\\nindex\\\\n(only axis)\\\\nDataFrame\\\\n:\\\\nindex\\\\n(rows) and\\\\ncolumns\\\\nNote,\\\\nthese attributes can be safely assigned to\\\\n!\\\\nIn [7]:\\\\ndf\\\\n[:\\\\n2\\\\n]\\\\nOut[7]:\\\\nA         B         C\\\\n2000-01-01 -0.173215  0.119209 -1.044236\\\\n2000-01-02 -0.861849 -2.104569 -0.494929\\\\nIn [8]:\\\\ndf\\\\n.\\\\ncolumns\\\\n=\\\\n[\\\\nx\\\\n.\\\\nlower\\\\n()\\\\nfor\\\\nx\\\\nin\\\\ndf\\\\n.\\\\ncolumns\\\\n]\\\\nIn [9]:\\\\ndf\\\\nOut[9]:\\\\na         b         c\\\\n2000-01-01 -0.173215  0.119209 -1.044236\\\\n2000-01-02 -0.861849 -2.104569 -0.494929\\\\n2000-01-03  1.071804  0.721555 -0.706771\\\\n2000-01-04 -1.039575  0.271860 -0.424972\\\\n2000-01-05  0.567020  0.276232 -1.087401\\\\n2000-01-06 -0.673690  0.113648 -1.478427\\\\n2000-01-07  0.524988  0.404705  0.577046\\\\n2000-01-08 -1.715002 -1.039268 -0.370647\\\\npandas objects (\\\\nIndex\\\\n,\\\\nSeries\\\\n,\\\\nDataFrame\\\\n) can be\\nthought of as containers for arrays, which hold the actual data and do the\\nactual computation. For many types, the underlying array is a\\\\nnumpy.ndarray\\\\n. However, pandas and 3rd party libraries may\\\\nextend\\\\nNumPy’s type system to add support for custom arrays\\n(see\\\\ndtypes\\\\n).\\\\nTo get the actual data inside a\\\\nIndex\\\\nor\\\\nSeries\\\\n, use\\nthe\\\\n.array\\\\nproperty\\\\nIn [10]:\\\\ns\\\\n.\\\\narray\\\\nOut[10]:\\\\n<NumpyExtensionArray>\\\\n[ 0.4691122999071863, -0.2828633443286633, -1.5090585031735124,\\\\n-1.1356323710171934,  1.2121120250208506]\\\\nLength: 5, dtype: float64\\\\nIn [11]:\\\\ns\\\\n.\\\\nindex\\\\n.\\\\narray\\\\nOut[11]:\\\\n<NumpyExtensionArray>\\\\n[\\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\']\\\\nLength: 5, dtype: object\\\\narray\\\\nwill always be an\\\\nExtensionArray\\\\n.\\nThe exact details of what an\\\\nExtensionArray\\\\nis and why pandas uses them are a bit\\nbeyond the scope of this introduction. See\\\\ndtypes\\\\nfor more.\\\\nIf you know you need a NumPy array, use\\\\nto_numpy()\\\\nor\\\\nnumpy.asarray()\\\\n.\\\\nIn [12]:\\\\ns\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[12]:\\\\narray([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])\\\\nIn [13]:\\\\nnp\\\\n.\\\\nasarray\\\\n(\\\\ns\\\\n)\\\\nOut[13]:\\\\narray([ 0.4691, -0.2829, -1.5091, -1.1356,  1.2121])\\\\nWhen the Series or Index is backed by\\nan\\\\nExtensionArray\\\\n,\\\\nto_numpy()\\\\nmay involve copying data and coercing values. See\\\\ndtypes\\\\nfor more.\\\\nto_numpy()\\\\ngives some control over the\\\\ndtype\\\\nof the\\nresulting\\\\nnumpy.ndarray\\\\n. For example, consider datetimes with timezones.\\nNumPy doesn’t have a dtype to represent timezone-aware datetimes, so there\\nare two possibly useful representations:\\\\nAn object-dtype\\\\nnumpy.ndarray\\\\nwith\\\\nTimestamp\\\\nobjects, each\\nwith the correct\\\\ntz\\\\nA\\\\ndatetime64[ns]\\\\n-dtype\\\\nnumpy.ndarray\\\\n, where the values have\\nbeen converted to UTC and the timezone discarded\\\\nTimezones may be preserved with\\\\ndtype=object\\\\nIn [14]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"2000\"\\\\n,\\\\nperiods\\\\n=\\\\n2\\\\n,\\\\ntz\\\\n=\\\\n\"CET\"\\\\n))\\\\nIn [15]:\\\\nser\\\\n.\\\\nto_numpy\\\\n(\\\\ndtype\\\\n=\\\\nobject\\\\n)\\\\nOut[15]:\\\\narray([Timestamp(\\'2000-01-01 00:00:00+0100\\', tz=\\'CET\\'),\\\\nTimestamp(\\'2000-01-02 00:00:00+0100\\', tz=\\'CET\\')], dtype=object)\\\\nOr thrown away with\\\\ndtype=\\'datetime64[ns]\\'\\\\nIn [16]:\\\\nser\\\\n.\\\\nto_numpy\\\\n(\\\\ndtype\\\\n=\\\\n\"datetime64[ns]\"\\\\n)\\\\nOut[16]:\\\\narray([\\'1999-12-31T23:00:00.000000000\\', \\'2000-01-01T23:00:00.000000000\\'],\\\\ndtype=\\'datetime64[ns]\\')\\\\nGetting the “raw data” inside a\\\\nDataFrame\\\\nis possibly a bit more\\ncomplex. When your\\\\nDataFrame\\\\nonly has a single data type for all the\\ncolumns,\\\\nDataFrame.to_numpy()\\\\nwill return the underlying data:\\\\nIn [17]:\\\\ndf\\\\n.\\\\nto_numpy\\\\n()\\\\nOut[17]:\\\\narray([[-0.1732,  0.1192, -1.0442],\\\\n[-0.8618, -2.1046, -0.4949],\\\\n[ 1.0718,  0.7216, -0.7068],\\\\n[-1.0396,  0.2719, -0.425 ],\\\\n[ 0.567 ,  0.2762, -1.0874],\\\\n[-0.6737,  0.1136, -1.4784],\\\\n[ 0.525 ,  0.4047,  0.577 ],\\\\n[-1.715 , -1.0393, -0.3706]])\\\\nIf a DataFrame contains homogeneously-typed data, the ndarray can\\nactually be modified in-place, and the changes will be reflected in the data\\nstructure. For heterogeneous data (e.g. some of the DataFrame’s columns are not\\nall the same dtype), this will not be the case. The values attribute itself,\\nunlike the axis labels, cannot be assigned to.\\\\nNote\\\\nWhen working with heterogeneous data, the dtype of the resulting ndarray\\nwill be chosen to accommodate all of the data involved. For example, if\\nstrings are involved, the result will be of object dtype. If there are only\\nfloats and integers, the resulting array will be of float dtype.\\\\nIn the past, pandas recommended\\\\nSeries.values\\\\nor\\\\nDataFrame.values\\\\nfor extracting the data from a Series or DataFrame. You’ll still find references\\nto these in old code bases and online. Going forward, we recommend avoiding\\\\n.values\\\\nand using\\\\n.array\\\\nor\\\\n.to_numpy()\\\\n.\\\\n.values\\\\nhas the following\\ndrawbacks:\\\\nWhen your Series contains an\\\\nextension type\\\\n, it’s\\nunclear whether\\\\nSeries.values\\\\nreturns a NumPy array or the extension array.\\\\nSeries.array\\\\nwill always return an\\\\nExtensionArray\\\\n, and will never\\ncopy data.\\\\nSeries.to_numpy()\\\\nwill always return a NumPy array,\\npotentially at the cost of copying / coercing values.\\\\nWhen your DataFrame contains a mixture of data types,\\\\nDataFrame.values\\\\nmay\\ninvolve copying data and coercing values to a common dtype, a relatively expensive\\noperation.\\\\nDataFrame.to_numpy()\\\\n, being a method, makes it clearer that the\\nreturned NumPy array may not be a view on the same data in the DataFrame.\\\\nAccelerated operations\\\\n#\\\\npandas has support for accelerating certain types of binary numerical and boolean operations using\\nthe\\\\nnumexpr\\\\nlibrary and the\\\\nbottleneck\\\\nlibraries.\\\\nThese libraries are especially useful when dealing with large data sets, and provide large\\nspeedups.\\\\nnumexpr\\\\nuses smart chunking, caching, and multiple cores.\\\\nbottleneck\\\\nis\\na set of specialized cython routines that are especially fast when dealing with arrays that have\\\\nnans\\\\n.\\\\nHere is a sample (using 100 column x 100,000 row\\\\nDataFrames\\\\n):\\\\nOperation\\\\n0.11.0 (ms)\\\\nPrior Version (ms)\\\\nRatio to Prior\\\\ndf1\\\\n>\\\\ndf2\\\\n13.32\\\\n125.35\\\\n0.1063\\\\ndf1\\\\n*\\\\ndf2\\\\n21.71\\\\n36.63\\\\n0.5928\\\\ndf1\\\\n+\\\\ndf2\\\\n22.04\\\\n36.50\\\\n0.6039\\\\nYou are highly encouraged to install both libraries. See the section\\\\nRecommended Dependencies\\\\nfor more installation info.\\\\nThese are both enabled to be used by default, you can control this by setting the options:\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"compute.use_bottleneck\"\\\\n,\\\\nFalse\\\\n)\\\\npd\\\\n.\\\\nset_option\\\\n(\\\\n\"compute.use_numexpr\"\\\\n,\\\\nFalse\\\\n)\\\\nFlexible binary operations\\\\n#\\\\nWith binary operations between pandas data structures, there are two key points\\nof interest:\\\\nBroadcasting behavior between higher- (e.g. DataFrame) and\\nlower-dimensional (e.g. Series) objects.\\\\nMissing data in computations.\\\\nWe will demonstrate how to manage these issues independently, though they can\\nbe handled simultaneously.\\\\nMatching / broadcasting behavior\\\\n#\\\\nDataFrame has the methods\\\\nadd()\\\\n,\\\\nsub()\\\\n,\\\\nmul()\\\\n,\\\\ndiv()\\\\nand related functions\\\\nradd()\\\\n,\\\\nrsub()\\\\n, …\\nfor carrying out binary operations. For broadcasting behavior,\\nSeries input is of primary interest. Using these functions, you can use to\\neither match on the\\\\nindex\\\\nor\\\\ncolumns\\\\nvia the\\\\naxis\\\\nkeyword:\\\\nIn [18]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n\"one\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]),\\\\n....:\\\\n\"two\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n4\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n....:\\\\n\"three\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nIn [19]:\\\\ndf\\\\nOut[19]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [20]:\\\\nrow\\\\n=\\\\ndf\\\\n.\\\\niloc\\\\n[\\\\n1\\\\n]\\\\nIn [21]:\\\\ncolumn\\\\n=\\\\ndf\\\\n[\\\\n\"two\"\\\\n]\\\\nIn [22]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\nrow\\\\n,\\\\naxis\\\\n=\\\\n\"columns\"\\\\n)\\\\nOut[22]:\\\\none       two     three\\\\na  1.051928 -0.139606       NaN\\\\nb  0.000000  0.000000  0.000000\\\\nc  0.352192 -0.433754  1.277825\\\\nd       NaN -1.632779 -0.562782\\\\nIn [23]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\nrow\\\\n,\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[23]:\\\\none       two     three\\\\na  1.051928 -0.139606       NaN\\\\nb  0.000000  0.000000  0.000000\\\\nc  0.352192 -0.433754  1.277825\\\\nd       NaN -1.632779 -0.562782\\\\nIn [24]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ncolumn\\\\n,\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[24]:\\\\none  two     three\\\\na -0.377535  0.0       NaN\\\\nb -1.569069  0.0 -1.962513\\\\nc -0.783123  0.0 -0.250933\\\\nd       NaN  0.0 -0.892516\\\\nIn [25]:\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ncolumn\\\\n,\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[25]:\\\\none  two     three\\\\na -0.377535  0.0       NaN\\\\nb -1.569069  0.0 -1.962513\\\\nc -0.783123  0.0 -0.250933\\\\nd       NaN  0.0 -0.892516\\\\nFurthermore you can align a level of a MultiIndexed DataFrame with a Series.\\\\nIn [26]:\\\\ndfmi\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [27]:\\\\ndfmi\\\\n.\\\\nindex\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_tuples\\\\n(\\\\n....:\\\\n[(\\\\n1\\\\n,\\\\n\"a\"\\\\n),\\\\n(\\\\n1\\\\n,\\\\n\"b\"\\\\n),\\\\n(\\\\n1\\\\n,\\\\n\"c\"\\\\n),\\\\n(\\\\n2\\\\n,\\\\n\"a\"\\\\n)],\\\\nnames\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n]\\\\n....:\\\\n)\\\\n....:\\\\nIn [28]:\\\\ndfmi\\\\n.\\\\nsub\\\\n(\\\\ncolumn\\\\n,\\\\naxis\\\\n=\\\\n0\\\\n,\\\\nlevel\\\\n=\\\\n\"second\"\\\\n)\\\\nOut[28]:\\\\none       two     three\\\\nfirst second\\\\n1     a      -0.377535  0.000000       NaN\\\\nb      -1.569069  0.000000 -1.962513\\\\nc      -0.783123  0.000000 -0.250933\\\\n2     a            NaN -1.493173 -2.385688\\\\nSeries and Index also support the\\\\ndivmod()\\\\nbuiltin. This function takes\\nthe floor division and modulo operation at the same time returning a two-tuple\\nof the same type as the left hand side. For example:\\\\nIn [29]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n10\\\\n))\\\\nIn [30]:\\\\ns\\\\nOut[30]:\\\\n0    0\\\\n1    1\\\\n2    2\\\\n3    3\\\\n4    4\\\\n5    5\\\\n6    6\\\\n7    7\\\\n8    8\\\\n9    9\\\\ndtype: int64\\\\nIn [31]:\\\\ndiv\\\\n,\\\\nrem\\\\n=\\\\ndivmod\\\\n(\\\\ns\\\\n,\\\\n3\\\\n)\\\\nIn [32]:\\\\ndiv\\\\nOut[32]:\\\\n0    0\\\\n1    0\\\\n2    0\\\\n3    1\\\\n4    1\\\\n5    1\\\\n6    2\\\\n7    2\\\\n8    2\\\\n9    3\\\\ndtype: int64\\\\nIn [33]:\\\\nrem\\\\nOut[33]:\\\\n0    0\\\\n1    1\\\\n2    2\\\\n3    0\\\\n4    1\\\\n5    2\\\\n6    0\\\\n7    1\\\\n8    2\\\\n9    0\\\\ndtype: int64\\\\nIn [34]:\\\\nidx\\\\n=\\\\npd\\\\n.\\\\nIndex\\\\n(\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n10\\\\n))\\\\nIn [35]:\\\\nidx\\\\nOut[35]:\\\\nIndex([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=\\'int64\\')\\\\nIn [36]:\\\\ndiv\\\\n,\\\\nrem\\\\n=\\\\ndivmod\\\\n(\\\\nidx\\\\n,\\\\n3\\\\n)\\\\nIn [37]:\\\\ndiv\\\\nOut[37]:\\\\nIndex([0, 0, 0, 1, 1, 1, 2, 2, 2, 3], dtype=\\'int64\\')\\\\nIn [38]:\\\\nrem\\\\nOut[38]:\\\\nIndex([0, 1, 2, 0, 1, 2, 0, 1, 2, 0], dtype=\\'int64\\')\\\\nWe can also do elementwise\\\\ndivmod()\\\\n:\\\\nIn [39]:\\\\ndiv\\\\n,\\\\nrem\\\\n=\\\\ndivmod\\\\n(\\\\ns\\\\n,\\\\n[\\\\n2\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n5\\\\n,\\\\n6\\\\n,\\\\n6\\\\n])\\\\nIn [40]:\\\\ndiv\\\\nOut[40]:\\\\n0    0\\\\n1    0\\\\n2    0\\\\n3    1\\\\n4    1\\\\n5    1\\\\n6    1\\\\n7    1\\\\n8    1\\\\n9    1\\\\ndtype: int64\\\\nIn [41]:\\\\nrem\\\\nOut[41]:\\\\n0    0\\\\n1    1\\\\n2    2\\\\n3    0\\\\n4    0\\\\n5    1\\\\n6    1\\\\n7    2\\\\n8    2\\\\n9    3\\\\ndtype: int64\\\\nMissing data / operations with fill values\\\\n#\\\\nIn Series and DataFrame, the arithmetic functions have the option of inputting\\na\\\\nfill_value\\\\n, namely a value to substitute when at most one of the values at\\na location are missing. For example, when adding two DataFrame objects, you may\\nwish to treat NaN as 0 unless both DataFrames are missing that value, in which\\ncase the result will be NaN (you can later replace NaN with some other value\\nusing\\\\nfillna\\\\nif you wish).\\\\nIn [42]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [43]:\\\\ndf2\\\\n.\\\\nloc\\\\n[\\\\n\"a\"\\\\n,\\\\n\"three\"\\\\n]\\\\n=\\\\n1.0\\\\nIn [44]:\\\\ndf\\\\nOut[44]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [45]:\\\\ndf2\\\\nOut[45]:\\\\none       two     three\\\\na  1.394981  1.772517  1.000000\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [46]:\\\\ndf\\\\n+\\\\ndf2\\\\nOut[46]:\\\\none       two     three\\\\na  2.789963  3.545034       NaN\\\\nb  0.686107  3.824246 -0.100780\\\\nc  1.390491  2.956737  2.454870\\\\nd       NaN  0.558688 -1.226343\\\\nIn [47]:\\\\ndf\\\\n.\\\\nadd\\\\n(\\\\ndf2\\\\n,\\\\nfill_value\\\\n=\\\\n0\\\\n)\\\\nOut[47]:\\\\none       two     three\\\\na  2.789963  3.545034  1.000000\\\\nb  0.686107  3.824246 -0.100780\\\\nc  1.390491  2.956737  2.454870\\\\nd       NaN  0.558688 -1.226343\\\\nFlexible comparisons\\\\n#\\\\nSeries and DataFrame have the binary comparison methods\\\\neq\\\\n,\\\\nne\\\\n,\\\\nlt\\\\n,\\\\ngt\\\\n,\\\\nle\\\\n, and\\\\nge\\\\nwhose behavior is analogous to the binary\\narithmetic operations described above:\\\\nIn [48]:\\\\ndf\\\\n.\\\\ngt\\\\n(\\\\ndf2\\\\n)\\\\nOut[48]:\\\\none    two  three\\\\na  False  False  False\\\\nb  False  False  False\\\\nc  False  False  False\\\\nd  False  False  False\\\\nIn [49]:\\\\ndf2\\\\n.\\\\nne\\\\n(\\\\ndf\\\\n)\\\\nOut[49]:\\\\none    two  three\\\\na  False  False   True\\\\nb  False  False  False\\\\nc  False  False  False\\\\nd   True  False  False\\\\nThese operations produce a pandas object of the same type as the left-hand-side\\ninput that is of dtype\\\\nbool\\\\n. These\\\\nboolean\\\\nobjects can be used in\\nindexing operations, see the section on\\\\nBoolean indexing\\\\n.\\\\nBoolean reductions\\\\n#\\\\nYou can apply the reductions:\\\\nempty\\\\n,\\\\nany()\\\\n,\\\\nall()\\\\n, and\\\\nbool()\\\\nto provide a\\nway to summarize a boolean result.\\\\nIn [50]:\\\\n(\\\\ndf\\\\n>\\\\n0\\\\n)\\\\n.\\\\nall\\\\n()\\\\nOut[50]:\\\\none      False\\\\ntwo       True\\\\nthree    False\\\\ndtype: bool\\\\nIn [51]:\\\\n(\\\\ndf\\\\n>\\\\n0\\\\n)\\\\n.\\\\nany\\\\n()\\\\nOut[51]:\\\\none      True\\\\ntwo      True\\\\nthree    True\\\\ndtype: bool\\\\nYou can reduce to a final boolean value.\\\\nIn [52]:\\\\n(\\\\ndf\\\\n>\\\\n0\\\\n)\\\\n.\\\\nany\\\\n()\\\\n.\\\\nany\\\\n()\\\\nOut[52]:\\\\nTrue\\\\nYou can test if a pandas object is empty, via the\\\\nempty\\\\nproperty.\\\\nIn [53]:\\\\ndf\\\\n.\\\\nempty\\\\nOut[53]:\\\\nFalse\\\\nIn [54]:\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ncolumns\\\\n=\\\\nlist\\\\n(\\\\n\"ABC\"\\\\n))\\\\n.\\\\nempty\\\\nOut[54]:\\\\nTrue\\\\nWarning\\\\nAsserting the truthiness of a pandas object will raise an error, as the testing of the emptiness\\nor values is ambiguous.\\\\nIn [55]:\\\\nif\\\\ndf\\\\n:\\\\n....:\\\\nprint\\\\n(\\\\nTrue\\\\n)\\\\n....:\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\n<ipython-input-55-318d08b2571a>\\\\nin\\\\n?\\\\n()\\\\n---->\\\\n1\\\\nif\\\\ndf\\\\n:\\\\n2\\\\nprint\\\\n(\\\\nTrue\\\\n)\\\\n~/work/pandas/pandas/pandas/core/generic.py\\\\nin\\\\n?\\\\n(self)\\\\n1575\\\\n@final\\\\n1576\\\\ndef\\\\n__nonzero__\\\\n(\\\\nself\\\\n)\\\\n->\\\\nNoReturn\\\\n:\\\\n->\\\\n1577\\\\nraise\\\\nValueError\\\\n(\\\\n1578\\\\nf\\\\n\"The truth value of a\\\\n{\\\\ntype\\\\n(\\\\nself\\\\n)\\\\n.\\\\n__name__\\\\n}\\\\nis ambiguous. \"\\\\n1579\\\\n\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\\\\n1580\\\\n)\\\\nValueError\\\\n: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\\nIn [56]:\\\\ndf\\\\nand\\\\ndf2\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\n<ipython-input-56-b241b64bb471>\\\\nin\\\\n?\\\\n()\\\\n---->\\\\n1\\\\ndf\\\\nand\\\\ndf2\\\\n~/work/pandas/pandas/pandas/core/generic.py\\\\nin\\\\n?\\\\n(self)\\\\n1575\\\\n@final\\\\n1576\\\\ndef\\\\n__nonzero__\\\\n(\\\\nself\\\\n)\\\\n->\\\\nNoReturn\\\\n:\\\\n->\\\\n1577\\\\nraise\\\\nValueError\\\\n(\\\\n1578\\\\nf\\\\n\"The truth value of a\\\\n{\\\\ntype\\\\n(\\\\nself\\\\n)\\\\n.\\\\n__name__\\\\n}\\\\nis ambiguous. \"\\\\n1579\\\\n\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\\\\n1580\\\\n)\\\\nValueError\\\\n: The truth value of a DataFrame is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().\\\\nSee\\\\ngotchas\\\\nfor a more detailed discussion.\\\\nComparing if objects are equivalent\\\\n#\\\\nOften you may find that there is more than one way to compute the same\\nresult.  As a simple example, consider\\\\ndf\\\\n+\\\\ndf\\\\nand\\\\ndf\\\\n*\\\\n2\\\\n. To test\\nthat these two computations produce the same result, given the tools\\nshown above, you might imagine using\\\\n(df\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2).all()\\\\n. But in\\nfact, this expression is False:\\\\nIn [57]:\\\\ndf\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2\\\\nOut[57]:\\\\none   two  three\\\\na   True  True  False\\\\nb   True  True   True\\\\nc   True  True   True\\\\nd  False  True   True\\\\nIn [58]:\\\\n(\\\\ndf\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2\\\\n)\\\\n.\\\\nall\\\\n()\\\\nOut[58]:\\\\none      False\\\\ntwo       True\\\\nthree    False\\\\ndtype: bool\\\\nNotice that the boolean DataFrame\\\\ndf\\\\n+\\\\ndf\\\\n==\\\\ndf\\\\n*\\\\n2\\\\ncontains some False values!\\nThis is because NaNs do not compare as equals:\\\\nIn [59]:\\\\nnp\\\\n.\\\\nnan\\\\n==\\\\nnp\\\\n.\\\\nnan\\\\nOut[59]:\\\\nFalse\\\\nSo, NDFrames (such as Series and DataFrames)\\nhave an\\\\nequals()\\\\nmethod for testing equality, with NaNs in\\ncorresponding locations treated as equal.\\\\nIn [60]:\\\\n(\\\\ndf\\\\n+\\\\ndf\\\\n)\\\\n.\\\\nequals\\\\n(\\\\ndf\\\\n*\\\\n2\\\\n)\\\\nOut[60]:\\\\nTrue\\\\nNote that the Series or DataFrame index needs to be in the same order for\\nequality to be True:\\\\nIn [61]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"col\"\\\\n:\\\\n[\\\\n\"foo\"\\\\n,\\\\n0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n]})\\\\nIn [62]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"col\"\\\\n:\\\\n[\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n0\\\\n,\\\\n\"foo\"\\\\n]},\\\\nindex\\\\n=\\\\n[\\\\n2\\\\n,\\\\n1\\\\n,\\\\n0\\\\n])\\\\nIn [63]:\\\\ndf1\\\\n.\\\\nequals\\\\n(\\\\ndf2\\\\n)\\\\nOut[63]:\\\\nFalse\\\\nIn [64]:\\\\ndf1\\\\n.\\\\nequals\\\\n(\\\\ndf2\\\\n.\\\\nsort_index\\\\n())\\\\nOut[64]:\\\\nTrue\\\\nComparing array-like objects\\\\n#\\\\nYou can conveniently perform element-wise comparisons when comparing a pandas\\ndata structure with a scalar value:\\\\nIn [65]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\n\"foo\"\\\\nOut[65]:\\\\n0     True\\\\n1    False\\\\n2    False\\\\ndtype: bool\\\\nIn [66]:\\\\npd\\\\n.\\\\nIndex\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\n\"foo\"\\\\nOut[66]:\\\\narray([ True, False, False])\\\\npandas also handles element-wise comparisons between different array-like\\nobjects of the same length:\\\\nIn [67]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\npd\\\\n.\\\\nIndex\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"qux\"\\\\n])\\\\nOut[67]:\\\\n0     True\\\\n1     True\\\\n2    False\\\\ndtype: bool\\\\nIn [68]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"baz\"\\\\n])\\\\n==\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n\"foo\"\\\\n,\\\\n\"bar\"\\\\n,\\\\n\"qux\"\\\\n])\\\\nOut[68]:\\\\n0     True\\\\n1     True\\\\n2    False\\\\ndtype: bool\\\\nTrying to compare\\\\nIndex\\\\nor\\\\nSeries\\\\nobjects of different lengths will\\nraise a ValueError:\\\\nIn [69]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n])\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\nCell\\\\nIn\\\\n[\\\\n69\\\\n],\\\\nline\\\\n1\\\\n---->\\\\n1\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n])\\\\nFile ~/work/pandas/pandas/pandas/core/ops/common.py:76,\\\\nin\\\\n_unpack_zerodim_and_defer.<locals>.new_method\\\\n(self, other)\\\\n72\\\\nreturn\\\\nNotImplemented\\\\n74\\\\nother\\\\n=\\\\nitem_from_zerodim\\\\n(\\\\nother\\\\n)\\\\n--->\\\\n76\\\\nreturn\\\\nmethod\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/arraylike.py:40,\\\\nin\\\\nOpsMixin.__eq__\\\\n(self, other)\\\\n38\\\\n@unpack_zerodim_and_defer\\\\n(\\\\n\"__eq__\"\\\\n)\\\\n39\\\\ndef\\\\n__eq__\\\\n(\\\\nself\\\\n,\\\\nother\\\\n):\\\\n--->\\\\n40\\\\nreturn\\\\nself\\\\n.\\\\n_cmp_method\\\\n(\\\\nother\\\\n,\\\\noperator\\\\n.\\\\neq\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:6125,\\\\nin\\\\nSeries._cmp_method\\\\n(self, other, op)\\\\n6122\\\\nres_name\\\\n=\\\\nops\\\\n.\\\\nget_op_result_name\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\n6124\\\\nif\\\\nisinstance\\\\n(\\\\nother\\\\n,\\\\nSeries\\\\n)\\\\nand\\\\nnot\\\\nself\\\\n.\\\\n_indexed_same\\\\n(\\\\nother\\\\n):\\\\n->\\\\n6125\\\\nraise\\\\nValueError\\\\n(\\\\n\"Can only compare identically-labeled Series objects\"\\\\n)\\\\n6127\\\\nlvalues\\\\n=\\\\nself\\\\n.\\\\n_values\\\\n6128\\\\nrvalues\\\\n=\\\\nextract_array\\\\n(\\\\nother\\\\n,\\\\nextract_numpy\\\\n=\\\\nTrue\\\\n,\\\\nextract_range\\\\n=\\\\nTrue\\\\n)\\\\nValueError\\\\n: Can only compare identically-labeled Series objects\\\\nIn [70]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n])\\\\n---------------------------------------------------------------------------\\\\nValueError\\\\nTraceback (most recent call last)\\\\nCell\\\\nIn\\\\n[\\\\n70\\\\n],\\\\nline\\\\n1\\\\n---->\\\\n1\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n,\\\\n\\'bar\\'\\\\n,\\\\n\\'baz\\'\\\\n])\\\\n==\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\\'foo\\'\\\\n])\\\\nFile ~/work/pandas/pandas/pandas/core/ops/common.py:76,\\\\nin\\\\n_unpack_zerodim_and_defer.<locals>.new_method\\\\n(self, other)\\\\n72\\\\nreturn\\\\nNotImplemented\\\\n74\\\\nother\\\\n=\\\\nitem_from_zerodim\\\\n(\\\\nother\\\\n)\\\\n--->\\\\n76\\\\nreturn\\\\nmethod\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/arraylike.py:40,\\\\nin\\\\nOpsMixin.__eq__\\\\n(self, other)\\\\n38\\\\n@unpack_zerodim_and_defer\\\\n(\\\\n\"__eq__\"\\\\n)\\\\n39\\\\ndef\\\\n__eq__\\\\n(\\\\nself\\\\n,\\\\nother\\\\n):\\\\n--->\\\\n40\\\\nreturn\\\\nself\\\\n.\\\\n_cmp_method\\\\n(\\\\nother\\\\n,\\\\noperator\\\\n.\\\\neq\\\\n)\\\\nFile ~/work/pandas/pandas/pandas/core/series.py:6125,\\\\nin\\\\nSeries._cmp_method\\\\n(self, other, op)\\\\n6122\\\\nres_name\\\\n=\\\\nops\\\\n.\\\\nget_op_result_name\\\\n(\\\\nself\\\\n,\\\\nother\\\\n)\\\\n6124\\\\nif\\\\nisinstance\\\\n(\\\\nother\\\\n,\\\\nSeries\\\\n)\\\\nand\\\\nnot\\\\nself\\\\n.\\\\n_indexed_same\\\\n(\\\\nother\\\\n):\\\\n->\\\\n6125\\\\nraise\\\\nValueError\\\\n(\\\\n\"Can only compare identically-labeled Series objects\"\\\\n)\\\\n6127\\\\nlvalues\\\\n=\\\\nself\\\\n.\\\\n_values\\\\n6128\\\\nrvalues\\\\n=\\\\nextract_array\\\\n(\\\\nother\\\\n,\\\\nextract_numpy\\\\n=\\\\nTrue\\\\n,\\\\nextract_range\\\\n=\\\\nTrue\\\\n)\\\\nValueError\\\\n: Can only compare identically-labeled Series objects\\\\nCombining overlapping data sets\\\\n#\\\\nA problem occasionally arising is the combination of two similar data sets\\nwhere values in one are preferred over the other. An example would be two data\\nseries representing a particular economic indicator where one is considered to\\nbe of “higher quality”. However, the lower quality series might extend further\\nback in history or have more complete data coverage. As such, we would like to\\ncombine two DataFrame objects where missing values in one DataFrame are\\nconditionally filled with like-labeled values from the other DataFrame. The\\nfunction implementing this operation is\\\\ncombine_first()\\\\n,\\nwhich we illustrate:\\\\nIn [71]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n\"A\"\\\\n:\\\\n[\\\\n1.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n5.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n],\\\\n\"B\"\\\\n:\\\\n[\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n2.0\\\\n,\\\\n3.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n6.0\\\\n]}\\\\n....:\\\\n)\\\\n....:\\\\nIn [72]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n....:\\\\n{\\\\n....:\\\\n\"A\"\\\\n:\\\\n[\\\\n5.0\\\\n,\\\\n2.0\\\\n,\\\\n4.0\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n7.0\\\\n],\\\\n....:\\\\n\"B\"\\\\n:\\\\n[\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n,\\\\n6.0\\\\n,\\\\n8.0\\\\n],\\\\n....:\\\\n}\\\\n....:\\\\n)\\\\n....:\\\\nIn [73]:\\\\ndf1\\\\nOut[73]:\\\\nA    B\\\\n0  1.0  NaN\\\\n1  NaN  2.0\\\\n2  3.0  3.0\\\\n3  5.0  NaN\\\\n4  NaN  6.0\\\\nIn [74]:\\\\ndf2\\\\nOut[74]:\\\\nA    B\\\\n0  5.0  NaN\\\\n1  2.0  NaN\\\\n2  4.0  3.0\\\\n3  NaN  4.0\\\\n4  3.0  6.0\\\\n5  7.0  8.0\\\\nIn [75]:\\\\ndf1\\\\n.\\\\ncombine_first\\\\n(\\\\ndf2\\\\n)\\\\nOut[75]:\\\\nA    B\\\\n0  1.0  NaN\\\\n1  2.0  2.0\\\\n2  3.0  3.0\\\\n3  5.0  4.0\\\\n4  3.0  6.0\\\\n5  7.0  8.0\\\\nGeneral DataFrame combine\\\\n#\\\\nThe\\\\ncombine_first()\\\\nmethod above calls the more general\\\\nDataFrame.combine()\\\\n. This method takes another DataFrame\\nand a combiner function, aligns the input DataFrame and then passes the combiner\\nfunction pairs of Series (i.e., columns whose names are the same).\\\\nSo, for instance, to reproduce\\\\ncombine_first()\\\\nas above:\\\\nIn [76]:\\\\ndef\\\\ncombiner\\\\n(\\\\nx\\\\n,\\\\ny\\\\n):\\\\n....:\\\\nreturn\\\\nnp\\\\n.\\\\nwhere\\\\n(\\\\npd\\\\n.\\\\nisna\\\\n(\\\\nx\\\\n),\\\\ny\\\\n,\\\\nx\\\\n)\\\\n....:\\\\nIn [77]:\\\\ndf1\\\\n.\\\\ncombine\\\\n(\\\\ndf2\\\\n,\\\\ncombiner\\\\n)\\\\nOut[77]:\\\\nA    B\\\\n0  1.0  NaN\\\\n1  2.0  2.0\\\\n2  3.0  3.0\\\\n3  5.0  4.0\\\\n4  3.0  6.0\\\\n5  7.0  8.0\\\\nDescriptive statistics\\\\n#\\\\nThere exists a large number of methods for computing descriptive statistics and\\nother related operations on\\\\nSeries\\\\n,\\\\nDataFrame\\\\n. Most of these\\nare aggregations (hence producing a lower-dimensional result) like\\\\nsum()\\\\n,\\\\nmean()\\\\n, and\\\\nquantile()\\\\n,\\nbut some of them, like\\\\ncumsum()\\\\nand\\\\ncumprod()\\\\n,\\nproduce an object of the same size. Generally speaking, these methods take an\\\\naxis\\\\nargument, just like\\\\nndarray.{sum, std, …}\\\\n, but the axis can be\\nspecified by name or integer:\\\\nSeries\\\\n: no axis argument needed\\\\nDataFrame\\\\n: “index” (axis=0, default), “columns” (axis=1)\\\\nFor example:\\\\nIn [78]:\\\\ndf\\\\nOut[78]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [79]:\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\n0\\\\n)\\\\nOut[79]:\\\\none      0.811094\\\\ntwo      1.360588\\\\nthree    0.187958\\\\ndtype: float64\\\\nIn [80]:\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\n1\\\\n)\\\\nOut[80]:\\\\na    1.583749\\\\nb    0.734929\\\\nc    1.133683\\\\nd   -0.166914\\\\ndtype: float64\\\\nAll such methods have a\\\\nskipna\\\\noption signaling whether to exclude missing\\ndata (\\\\nTrue\\\\nby default):\\\\nIn [81]:\\\\ndf\\\\n.\\\\nsum\\\\n(\\\\n0\\\\n,\\\\nskipna\\\\n=\\\\nFalse\\\\n)\\\\nOut[81]:\\\\none           NaN\\\\ntwo      5.442353\\\\nthree         NaN\\\\ndtype: float64\\\\nIn [82]:\\\\ndf\\\\n.\\\\nsum\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n,\\\\nskipna\\\\n=\\\\nTrue\\\\n)\\\\nOut[82]:\\\\na    3.167498\\\\nb    2.204786\\\\nc    3.401050\\\\nd   -0.333828\\\\ndtype: float64\\\\nCombined with the broadcasting / arithmetic behavior, one can describe various\\nstatistical procedures, like standardization (rendering data zero mean and\\nstandard deviation of 1), very concisely:\\\\nIn [83]:\\\\nts_stand\\\\n=\\\\n(\\\\ndf\\\\n-\\\\ndf\\\\n.\\\\nmean\\\\n())\\\\n/\\\\ndf\\\\n.\\\\nstd\\\\n()\\\\nIn [84]:\\\\nts_stand\\\\n.\\\\nstd\\\\n()\\\\nOut[84]:\\\\none      1.0\\\\ntwo      1.0\\\\nthree    1.0\\\\ndtype: float64\\\\nIn [85]:\\\\nxs_stand\\\\n=\\\\ndf\\\\n.\\\\nsub\\\\n(\\\\ndf\\\\n.\\\\nmean\\\\n(\\\\n1\\\\n),\\\\naxis\\\\n=\\\\n0\\\\n)\\\\n.\\\\ndiv\\\\n(\\\\ndf\\\\n.\\\\nstd\\\\n(\\\\n1\\\\n),\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nIn [86]:\\\\nxs_stand\\\\n.\\\\nstd\\\\n(\\\\n1\\\\n)\\\\nOut[86]:\\\\na    1.0\\\\nb    1.0\\\\nc    1.0\\\\nd    1.0\\\\ndtype: float64\\\\nNote that methods like\\\\ncumsum()\\\\nand\\\\ncumprod()\\\\npreserve the location of\\\\nNaN\\\\nvalues. This is somewhat different from\\\\nexpanding()\\\\nand\\\\nrolling()\\\\nsince\\\\nNaN\\\\nbehavior\\nis furthermore dictated by a\\\\nmin_periods\\\\nparameter.\\\\nIn [87]:\\\\ndf\\\\n.\\\\ncumsum\\\\n()\\\\nOut[87]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  1.738035  3.684640 -0.050390\\\\nc  2.433281  5.163008  1.177045\\\\nd       NaN  5.442353  0.563873\\\\nHere is a quick reference summary table of common functions. Each also takes an\\noptional\\\\nlevel\\\\nparameter which applies only if the object has a\\\\nhierarchical index\\\\n.\\\\nFunction\\\\nDescription\\\\ncount\\\\nNumber of non-NA observations\\\\nsum\\\\nSum of values\\\\nmean\\\\nMean of values\\\\nmedian\\\\nArithmetic median of values\\\\nmin\\\\nMinimum\\\\nmax\\\\nMaximum\\\\nmode\\\\nMode\\\\nabs\\\\nAbsolute Value\\\\nprod\\\\nProduct of values\\\\nstd\\\\nBessel-corrected sample standard deviation\\\\nvar\\\\nUnbiased variance\\\\nsem\\\\nStandard error of the mean\\\\nskew\\\\nSample skewness (3rd moment)\\\\nkurt\\\\nSample kurtosis (4th moment)\\\\nquantile\\\\nSample quantile (value at %)\\\\ncumsum\\\\nCumulative sum\\\\ncumprod\\\\nCumulative product\\\\ncummax\\\\nCumulative maximum\\\\ncummin\\\\nCumulative minimum\\\\nNote that by chance some NumPy methods, like\\\\nmean\\\\n,\\\\nstd\\\\n, and\\\\nsum\\\\n,\\nwill exclude NAs on Series input by default:\\\\nIn [88]:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\ndf\\\\n[\\\\n\"one\"\\\\n])\\\\nOut[88]:\\\\n0.8110935116651192\\\\nIn [89]:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\ndf\\\\n[\\\\n\"one\"\\\\n]\\\\n.\\\\nto_numpy\\\\n())\\\\nOut[89]:\\\\nnan\\\\nSeries.nunique()\\\\nwill return the number of unique non-NA values in a\\nSeries:\\\\nIn [90]:\\\\nseries\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n500\\\\n))\\\\nIn [91]:\\\\nseries\\\\n[\\\\n20\\\\n:\\\\n500\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [92]:\\\\nseries\\\\n[\\\\n10\\\\n:\\\\n20\\\\n]\\\\n=\\\\n5\\\\nIn [93]:\\\\nseries\\\\n.\\\\nnunique\\\\n()\\\\nOut[93]:\\\\n11\\\\nSummarizing data: describe\\\\n#\\\\nThere is a convenient\\\\ndescribe()\\\\nfunction which computes a variety of summary\\nstatistics about a Series or the columns of a DataFrame (excluding NAs of\\ncourse):\\\\nIn [94]:\\\\nseries\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n))\\\\nIn [95]:\\\\nseries\\\\n[::\\\\n2\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [96]:\\\\nseries\\\\n.\\\\ndescribe\\\\n()\\\\nOut[96]:\\\\ncount    500.000000\\\\nmean      -0.021292\\\\nstd        1.015906\\\\nmin       -2.683763\\\\n25%       -0.699070\\\\n50%       -0.069718\\\\n75%        0.714483\\\\nmax        3.160915\\\\ndtype: float64\\\\nIn [97]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n,\\\\n5\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [98]:\\\\nframe\\\\n.\\\\niloc\\\\n[::\\\\n2\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [99]:\\\\nframe\\\\n.\\\\ndescribe\\\\n()\\\\nOut[99]:\\\\na           b           c           d           e\\\\ncount  500.000000  500.000000  500.000000  500.000000  500.000000\\\\nmean     0.033387    0.030045   -0.043719   -0.051686    0.005979\\\\nstd      1.017152    0.978743    1.025270    1.015988    1.006695\\\\nmin     -3.000951   -2.637901   -3.303099   -3.159200   -3.188821\\\\n25%     -0.647623   -0.576449   -0.712369   -0.691338   -0.691115\\\\n50%      0.047578   -0.021499   -0.023888   -0.032652   -0.025363\\\\n75%      0.729907    0.775880    0.618896    0.670047    0.649748\\\\nmax      2.740139    2.752332    3.004229    2.728702    3.240991\\\\nYou can select specific percentiles to include in the output:\\\\nIn [100]:\\\\nseries\\\\n.\\\\ndescribe\\\\n(\\\\npercentiles\\\\n=\\\\n[\\\\n0.05\\\\n,\\\\n0.25\\\\n,\\\\n0.75\\\\n,\\\\n0.95\\\\n])\\\\nOut[100]:\\\\ncount    500.000000\\\\nmean      -0.021292\\\\nstd        1.015906\\\\nmin       -2.683763\\\\n5%        -1.645423\\\\n25%       -0.699070\\\\n50%       -0.069718\\\\n75%        0.714483\\\\n95%        1.711409\\\\nmax        3.160915\\\\ndtype: float64\\\\nBy default, the median is always included.\\\\nFor a non-numerical Series object,\\\\ndescribe()\\\\nwill give a simple\\nsummary of the number of unique values and most frequently occurring values:\\\\nIn [101]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"a\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"a\"\\\\n])\\\\nIn [102]:\\\\ns\\\\n.\\\\ndescribe\\\\n()\\\\nOut[102]:\\\\ncount     9\\\\nunique    4\\\\ntop       a\\\\nfreq      5\\\\ndtype: object\\\\nNote that on a mixed-type DataFrame object,\\\\ndescribe()\\\\nwill\\nrestrict the summary to include only numerical columns or, if none are, only\\ncategorical columns:\\\\nIn [103]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n\"Yes\"\\\\n,\\\\n\"Yes\"\\\\n,\\\\n\"No\"\\\\n,\\\\n\"No\"\\\\n],\\\\n\"b\"\\\\n:\\\\nrange\\\\n(\\\\n4\\\\n)})\\\\nIn [104]:\\\\nframe\\\\n.\\\\ndescribe\\\\n()\\\\nOut[104]:\\\\nb\\\\ncount  4.000000\\\\nmean   1.500000\\\\nstd    1.290994\\\\nmin    0.000000\\\\n25%    0.750000\\\\n50%    1.500000\\\\n75%    2.250000\\\\nmax    3.000000\\\\nThis behavior can be controlled by providing a list of types as\\\\ninclude\\\\n/\\\\nexclude\\\\narguments. The special value\\\\nall\\\\ncan also be used:\\\\nIn [105]:\\\\nframe\\\\n.\\\\ndescribe\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"object\"\\\\n])\\\\nOut[105]:\\\\na\\\\ncount     4\\\\nunique    2\\\\ntop     Yes\\\\nfreq      2\\\\nIn [106]:\\\\nframe\\\\n.\\\\ndescribe\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"number\"\\\\n])\\\\nOut[106]:\\\\nb\\\\ncount  4.000000\\\\nmean   1.500000\\\\nstd    1.290994\\\\nmin    0.000000\\\\n25%    0.750000\\\\n50%    1.500000\\\\n75%    2.250000\\\\nmax    3.000000\\\\nIn [107]:\\\\nframe\\\\n.\\\\ndescribe\\\\n(\\\\ninclude\\\\n=\\\\n\"all\"\\\\n)\\\\nOut[107]:\\\\na         b\\\\ncount     4  4.000000\\\\nunique    2       NaN\\\\ntop     Yes       NaN\\\\nfreq      2       NaN\\\\nmean    NaN  1.500000\\\\nstd     NaN  1.290994\\\\nmin     NaN  0.000000\\\\n25%     NaN  0.750000\\\\n50%     NaN  1.500000\\\\n75%     NaN  2.250000\\\\nmax     NaN  3.000000\\\\nThat feature relies on\\\\nselect_dtypes\\\\n. Refer to\\nthere for details about accepted inputs.\\\\nIndex of min/max values\\\\n#\\\\nThe\\\\nidxmin()\\\\nand\\\\nidxmax()\\\\nfunctions on Series\\nand DataFrame compute the index labels with the minimum and maximum\\ncorresponding values:\\\\nIn [108]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n))\\\\nIn [109]:\\\\ns1\\\\nOut[109]:\\\\n0    1.118076\\\\n1   -0.352051\\\\n2   -1.242883\\\\n3   -1.277155\\\\n4   -0.641184\\\\ndtype: float64\\\\nIn [110]:\\\\ns1\\\\n.\\\\nidxmin\\\\n(),\\\\ns1\\\\n.\\\\nidxmax\\\\n()\\\\nOut[110]:\\\\n(3, 0)\\\\nIn [111]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n,\\\\n3\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n])\\\\nIn [112]:\\\\ndf1\\\\nOut[112]:\\\\nA         B         C\\\\n0 -0.327863 -0.946180 -0.137570\\\\n1 -0.186235 -0.257213 -0.486567\\\\n2 -0.507027 -0.871259 -0.111110\\\\n3  2.000339 -2.430505  0.089759\\\\n4 -0.321434 -0.033695  0.096271\\\\nIn [113]:\\\\ndf1\\\\n.\\\\nidxmin\\\\n(\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[113]:\\\\nA    2\\\\nB    3\\\\nC    1\\\\ndtype: int64\\\\nIn [114]:\\\\ndf1\\\\n.\\\\nidxmax\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[114]:\\\\n0    C\\\\n1    A\\\\n2    C\\\\n3    A\\\\n4    C\\\\ndtype: object\\\\nWhen there are multiple rows (or columns) matching the minimum or maximum\\nvalue,\\\\nidxmin()\\\\nand\\\\nidxmax()\\\\nreturn the first\\nmatching index:\\\\nIn [115]:\\\\ndf3\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\n2\\\\n,\\\\n1\\\\n,\\\\n1\\\\n,\\\\n3\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n],\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\n\"edcba\"\\\\n))\\\\nIn [116]:\\\\ndf3\\\\nOut[116]:\\\\nA\\\\ne  2.0\\\\nd  1.0\\\\nc  1.0\\\\nb  3.0\\\\na  NaN\\\\nIn [117]:\\\\ndf3\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nidxmin\\\\n()\\\\nOut[117]:\\\\n\\'d\\'\\\\nNote\\\\nidxmin\\\\nand\\\\nidxmax\\\\nare called\\\\nargmin\\\\nand\\\\nargmax\\\\nin NumPy.\\\\nValue counts (histogramming) / mode\\\\n#\\\\nThe\\\\nvalue_counts()\\\\nSeries method computes a histogram\\nof a 1D array of values. It can also be used as a function on regular arrays:\\\\nIn [118]:\\\\ndata\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n7\\\\n,\\\\nsize\\\\n=\\\\n50\\\\n)\\\\nIn [119]:\\\\ndata\\\\nOut[119]:\\\\narray([6, 6, 2, 3, 5, 3, 2, 5, 4, 5, 4, 3, 4, 5, 0, 2, 0, 4, 2, 0, 3, 2,\\\\n2, 5, 6, 5, 3, 4, 6, 4, 3, 5, 6, 4, 3, 6, 2, 6, 6, 2, 3, 4, 2, 1,\\\\n6, 2, 6, 1, 5, 4])\\\\nIn [120]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\ndata\\\\n)\\\\nIn [121]:\\\\ns\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[121]:\\\\n6    10\\\\n2    10\\\\n4     9\\\\n3     8\\\\n5     8\\\\n0     3\\\\n1     2\\\\nName: count, dtype: int64\\\\nThe\\\\nvalue_counts()\\\\nmethod can be used to count combinations across multiple columns.\\nBy default all columns are used but a subset can be selected using the\\\\nsubset\\\\nargument.\\\\nIn [122]:\\\\ndata\\\\n=\\\\n{\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n\"x\"\\\\n,\\\\n\"x\"\\\\n,\\\\n\"y\"\\\\n,\\\\n\"y\"\\\\n]}\\\\nIn [123]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\ndata\\\\n)\\\\nIn [124]:\\\\nframe\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[124]:\\\\na  b\\\\n1  x    1\\\\n2  x    1\\\\n3  y    1\\\\n4  y    1\\\\nName: count, dtype: int64\\\\nSimilarly, you can get the most frequently occurring value(s), i.e. the mode, of the values in a Series or DataFrame:\\\\nIn [125]:\\\\ns5\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n1\\\\n,\\\\n3\\\\n,\\\\n3\\\\n,\\\\n3\\\\n,\\\\n5\\\\n,\\\\n5\\\\n,\\\\n7\\\\n,\\\\n7\\\\n,\\\\n7\\\\n])\\\\nIn [126]:\\\\ns5\\\\n.\\\\nmode\\\\n()\\\\nOut[126]:\\\\n0    3\\\\n1    7\\\\ndtype: int64\\\\nIn [127]:\\\\ndf5\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n7\\\\n,\\\\nsize\\\\n=\\\\n50\\\\n),\\\\n.....:\\\\n\"B\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n-\\\\n10\\\\n,\\\\n15\\\\n,\\\\nsize\\\\n=\\\\n50\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [128]:\\\\ndf5\\\\n.\\\\nmode\\\\n()\\\\nOut[128]:\\\\nA   B\\\\n0  1.0  -9\\\\n1  NaN  10\\\\n2  NaN  13\\\\nDiscretization and quantiling\\\\n#\\\\nContinuous values can be discretized using the\\\\ncut()\\\\n(bins based on values)\\nand\\\\nqcut()\\\\n(bins based on sample quantiles) functions:\\\\nIn [129]:\\\\narr\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n20\\\\n)\\\\nIn [130]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\ncut\\\\n(\\\\narr\\\\n,\\\\n4\\\\n)\\\\nIn [131]:\\\\nfactor\\\\nOut[131]:\\\\n[(-0.251, 0.464], (-0.968, -0.251], (0.464, 1.179], (-0.251, 0.464], (-0.968, -0.251], ..., (-0.251, 0.464], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251], (-0.968, -0.251]]\\\\nLength: 20\\\\nCategories (4, interval[float64, right]): [(-0.968, -0.251] < (-0.251, 0.464] < (0.464, 1.179] <\\\\n(1.179, 1.893]]\\\\nIn [132]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\ncut\\\\n(\\\\narr\\\\n,\\\\n[\\\\n-\\\\n5\\\\n,\\\\n-\\\\n1\\\\n,\\\\n0\\\\n,\\\\n1\\\\n,\\\\n5\\\\n])\\\\nIn [133]:\\\\nfactor\\\\nOut[133]:\\\\n[(0, 1], (-1, 0], (0, 1], (0, 1], (-1, 0], ..., (-1, 0], (-1, 0], (-1, 0], (-1, 0], (-1, 0]]\\\\nLength: 20\\\\nCategories (4, interval[int64, right]): [(-5, -1] < (-1, 0] < (0, 1] < (1, 5]]\\\\nqcut()\\\\ncomputes sample quantiles. For example, we could slice up some\\nnormally distributed data into equal-size quartiles like so:\\\\nIn [134]:\\\\narr\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n30\\\\n)\\\\nIn [135]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\nqcut\\\\n(\\\\narr\\\\n,\\\\n[\\\\n0\\\\n,\\\\n0.25\\\\n,\\\\n0.5\\\\n,\\\\n0.75\\\\n,\\\\n1\\\\n])\\\\nIn [136]:\\\\nfactor\\\\nOut[136]:\\\\n[(0.569, 1.184], (-2.278, -0.301], (-2.278, -0.301], (0.569, 1.184], (0.569, 1.184], ..., (-0.301, 0.569], (1.184, 2.346], (1.184, 2.346], (-0.301, 0.569], (-2.278, -0.301]]\\\\nLength: 30\\\\nCategories (4, interval[float64, right]): [(-2.278, -0.301] < (-0.301, 0.569] < (0.569, 1.184] <\\\\n(1.184, 2.346]]\\\\nWe can also pass infinite values to define the bins:\\\\nIn [137]:\\\\narr\\\\n=\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n20\\\\n)\\\\nIn [138]:\\\\nfactor\\\\n=\\\\npd\\\\n.\\\\ncut\\\\n(\\\\narr\\\\n,\\\\n[\\\\n-\\\\nnp\\\\n.\\\\ninf\\\\n,\\\\n0\\\\n,\\\\nnp\\\\n.\\\\ninf\\\\n])\\\\nIn [139]:\\\\nfactor\\\\nOut[139]:\\\\n[(-inf, 0.0], (0.0, inf], (0.0, inf], (-inf, 0.0], (-inf, 0.0], ..., (-inf, 0.0], (-inf, 0.0], (-inf, 0.0], (0.0, inf], (0.0, inf]]\\\\nLength: 20\\\\nCategories (2, interval[float64, right]): [(-inf, 0.0] < (0.0, inf]]\\\\nFunction application\\\\n#\\\\nTo apply your own or another library’s functions to pandas objects,\\nyou should be aware of the three methods below. The appropriate\\nmethod to use depends on whether your function expects to operate\\non an entire\\\\nDataFrame\\\\nor\\\\nSeries\\\\n, row- or column-wise, or elementwise.\\\\nTablewise Function Application\\\\n:\\\\npipe()\\\\nRow or Column-wise Function Application\\\\n:\\\\napply()\\\\nAggregation API\\\\n:\\\\nagg()\\\\nand\\\\ntransform()\\\\nApplying Elementwise Functions\\\\n:\\\\nmap()\\\\nTablewise function application\\\\n#\\\\nDataFrames\\\\nand\\\\nSeries\\\\ncan be passed into functions.\\nHowever, if the function needs to be called in a chain, consider using the\\\\npipe()\\\\nmethod.\\\\nFirst some setup:\\\\nIn [140]:\\\\ndef\\\\nextract_city_name\\\\n(\\\\ndf\\\\n):\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\nChicago, IL -> Chicago for city_name column\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\ndf\\\\n[\\\\n\"city_name\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\n\"city_and_code\"\\\\n]\\\\n.\\\\nstr\\\\n.\\\\nsplit\\\\n(\\\\n\",\"\\\\n)\\\\n.\\\\nstr\\\\n.\\\\nget\\\\n(\\\\n0\\\\n)\\\\n.....:\\\\nreturn\\\\ndf\\\\n.....:\\\\nIn [141]:\\\\ndef\\\\nadd_country_name\\\\n(\\\\ndf\\\\n,\\\\ncountry_name\\\\n=\\\\nNone\\\\n):\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\nChicago -> Chicago-US for city_name column\\\\n.....:\\\\n\"\"\"\\\\n.....:\\\\ncol\\\\n=\\\\n\"city_name\"\\\\n.....:\\\\ndf\\\\n[\\\\n\"city_and_country\"\\\\n]\\\\n=\\\\ndf\\\\n[\\\\ncol\\\\n]\\\\n+\\\\ncountry_name\\\\n.....:\\\\nreturn\\\\ndf\\\\n.....:\\\\nIn [142]:\\\\ndf_p\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"city_and_code\"\\\\n:\\\\n[\\\\n\"Chicago, IL\"\\\\n]})\\\\nextract_city_name\\\\nand\\\\nadd_country_name\\\\nare functions taking and returning\\\\nDataFrames\\\\n.\\\\nNow compare the following:\\\\nIn [143]:\\\\nadd_country_name\\\\n(\\\\nextract_city_name\\\\n(\\\\ndf_p\\\\n),\\\\ncountry_name\\\\n=\\\\n\"US\"\\\\n)\\\\nOut[143]:\\\\ncity_and_code city_name city_and_country\\\\n0   Chicago, IL   Chicago        ChicagoUS\\\\nIs equivalent to:\\\\nIn [144]:\\\\ndf_p\\\\n.\\\\npipe\\\\n(\\\\nextract_city_name\\\\n)\\\\n.\\\\npipe\\\\n(\\\\nadd_country_name\\\\n,\\\\ncountry_name\\\\n=\\\\n\"US\"\\\\n)\\\\nOut[144]:\\\\ncity_and_code city_name city_and_country\\\\n0   Chicago, IL   Chicago        ChicagoUS\\\\npandas encourages the second style, which is known as method chaining.\\\\npipe\\\\nmakes it easy to use your own or another library’s functions\\nin method chains, alongside pandas’ methods.\\\\nIn the example above, the functions\\\\nextract_city_name\\\\nand\\\\nadd_country_name\\\\neach expected a\\\\nDataFrame\\\\nas the first positional argument.\\nWhat if the function you wish to apply takes its data as, say, the second argument?\\nIn this case, provide\\\\npipe\\\\nwith a tuple of\\\\n(callable,\\\\ndata_keyword)\\\\n.\\\\n.pipe\\\\nwill route the\\\\nDataFrame\\\\nto the argument specified in the tuple.\\\\nFor example, we can fit a regression using statsmodels. Their API expects a formula first and a\\\\nDataFrame\\\\nas the second argument,\\\\ndata\\\\n. We pass in the function, keyword pair\\\\n(sm.ols,\\\\n\\'data\\')\\\\nto\\\\npipe\\\\n:\\\\nIn [147]:\\\\nimport\\\\nstatsmodels.formula.api\\\\nas\\\\nsm\\\\nIn [148]:\\\\nbb\\\\n=\\\\npd\\\\n.\\\\nread_csv\\\\n(\\\\n\"data/baseball.csv\"\\\\n,\\\\nindex_col\\\\n=\\\\n\"id\"\\\\n)\\\\nIn [149]:\\\\n(\\\\n.....:\\\\nbb\\\\n.\\\\nquery\\\\n(\\\\n\"h > 0\"\\\\n)\\\\n.....:\\\\n.\\\\nassign\\\\n(\\\\nln_h\\\\n=\\\\nlambda\\\\ndf\\\\n:\\\\nnp\\\\n.\\\\nlog\\\\n(\\\\ndf\\\\n.\\\\nh\\\\n))\\\\n.....:\\\\n.\\\\npipe\\\\n((\\\\nsm\\\\n.\\\\nols\\\\n,\\\\n\"data\"\\\\n),\\\\n\"hr ~ ln_h + year + g + C(lg)\"\\\\n)\\\\n.....:\\\\n.\\\\nfit\\\\n()\\\\n.....:\\\\n.\\\\nsummary\\\\n()\\\\n.....:\\\\n)\\\\n.....:\\\\nOut[149]:\\\\n<class \\'statsmodels.iolib.summary.Summary\\'>\\\\n\"\"\"\\\\nOLS Regression Results\\\\n==============================================================================\\\\nDep. Variable:                     hr   R-squared:                       0.685\\\\nModel:                            OLS   Adj. R-squared:                  0.665\\\\nMethod:                 Least Squares   F-statistic:                     34.28\\\\nDate:                Tue, 22 Nov 2022   Prob (F-statistic):           3.48e-15\\\\nTime:                        05:34:17   Log-Likelihood:                -205.92\\\\nNo. Observations:                  68   AIC:                             421.8\\\\nDf Residuals:                      63   BIC:                             432.9\\\\nDf Model:                           4\\\\nCovariance Type:            nonrobust\\\\n===============================================================================\\\\ncoef    std err          t      P>|t|      [0.025      0.975]\\\\n-------------------------------------------------------------------------------\\\\nIntercept\\\\n-\\\\n8484.7720\\\\n4664.146\\\\n-\\\\n1.819\\\\n0.074\\\\n-\\\\n1.78e+04\\\\n835.780\\\\nC\\\\n(\\\\nlg\\\\n)[\\\\nT\\\\n.\\\\nNL\\\\n]\\\\n-\\\\n2.2736\\\\n1.325\\\\n-\\\\n1.716\\\\n0.091\\\\n-\\\\n4.922\\\\n0.375\\\\nln_h\\\\n-\\\\n1.3542\\\\n0.875\\\\n-\\\\n1.547\\\\n0.127\\\\n-\\\\n3.103\\\\n0.395\\\\nyear\\\\n4.2277\\\\n2.324\\\\n1.819\\\\n0.074\\\\n-\\\\n0.417\\\\n8.872\\\\ng\\\\n0.1841\\\\n0.029\\\\n6.258\\\\n0.000\\\\n0.125\\\\n0.243\\\\n==============================================================================\\\\nOmnibus\\\\n:                       10.875   Durbin-Watson:                   1.999\\\\nProb\\\\n(\\\\nOmnibus\\\\n):\\\\n0.004\\\\nJarque\\\\n-\\\\nBera\\\\n(\\\\nJB\\\\n):\\\\n17.298\\\\nSkew\\\\n:                           0.537   Prob(JB):                     0.000175\\\\nKurtosis\\\\n:                       5.225   Cond. No.                     1.49e+07\\\\n==============================================================================\\\\nNotes\\\\n:\\\\n[\\\\n1\\\\n]\\\\nStandard\\\\nErrors\\\\nassume\\\\nthat\\\\nthe\\\\ncovariance\\\\nmatrix\\\\nof\\\\nthe\\\\nerrors\\\\nis\\\\ncorrectly\\\\nspecified\\\\n.\\\\n[\\\\n2\\\\n]\\\\nThe\\\\ncondition\\\\nnumber\\\\nis\\\\nlarge\\\\n,\\\\n1.49e+07\\\\n.\\\\nThis\\\\nmight\\\\nindicate\\\\nthat\\\\nthere\\\\nare\\\\nstrong\\\\nmulticollinearity\\\\nor\\\\nother\\\\nnumerical\\\\nproblems\\\\n.\\\\n\"\"\"\\\\nThe pipe method is inspired by unix pipes and more recently\\\\ndplyr\\\\nand\\\\nmagrittr\\\\n, which\\nhave introduced the popular\\\\n(%>%)\\\\n(read pipe) operator for\\\\nR\\\\n.\\nThe implementation of\\\\npipe\\\\nhere is quite clean and feels right at home in Python.\\nWe encourage you to view the source code of\\\\npipe()\\\\n.\\\\nRow or column-wise function application\\\\n#\\\\nArbitrary functions can be applied along the axes of a DataFrame\\nusing the\\\\napply()\\\\nmethod, which, like the descriptive\\nstatistics methods, takes an optional\\\\naxis\\\\nargument:\\\\nIn [145]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\nx\\\\n))\\\\nOut[145]:\\\\none      0.811094\\\\ntwo      1.360588\\\\nthree    0.187958\\\\ndtype: float64\\\\nIn [146]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nmean\\\\n(\\\\nx\\\\n),\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[146]:\\\\na    1.583749\\\\nb    0.734929\\\\nc    1.133683\\\\nd   -0.166914\\\\ndtype: float64\\\\nIn [147]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nmax\\\\n()\\\\n-\\\\nx\\\\n.\\\\nmin\\\\n())\\\\nOut[147]:\\\\none      1.051928\\\\ntwo      1.632779\\\\nthree    1.840607\\\\ndtype: float64\\\\nIn [148]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nnp\\\\n.\\\\ncumsum\\\\n)\\\\nOut[148]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  1.738035  3.684640 -0.050390\\\\nc  2.433281  5.163008  1.177045\\\\nd       NaN  5.442353  0.563873\\\\nIn [149]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\nnp\\\\n.\\\\nexp\\\\n)\\\\nOut[149]:\\\\none       two     three\\\\na  4.034899  5.885648       NaN\\\\nb  1.409244  6.767440  0.950858\\\\nc  2.004201  4.385785  3.412466\\\\nd       NaN  1.322262  0.541630\\\\nThe\\\\napply()\\\\nmethod will also dispatch on a string method name.\\\\nIn [150]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\n\"mean\"\\\\n)\\\\nOut[150]:\\\\none      0.811094\\\\ntwo      1.360588\\\\nthree    0.187958\\\\ndtype: float64\\\\nIn [151]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\n\"mean\"\\\\n,\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[151]:\\\\na    1.583749\\\\nb    0.734929\\\\nc    1.133683\\\\nd   -0.166914\\\\ndtype: float64\\\\nThe return type of the function passed to\\\\napply()\\\\naffects the\\ntype of the final output from\\\\nDataFrame.apply\\\\nfor the default behaviour:\\\\nIf the applied function returns a\\\\nSeries\\\\n, the final output is a\\\\nDataFrame\\\\n.\\nThe columns match the index of the\\\\nSeries\\\\nreturned by the applied function.\\\\nIf the applied function returns any other type, the final output is a\\\\nSeries\\\\n.\\\\nThis default behaviour can be overridden using the\\\\nresult_type\\\\n, which\\naccepts three options:\\\\nreduce\\\\n,\\\\nbroadcast\\\\n, and\\\\nexpand\\\\n.\\nThese will determine how list-likes return values expand (or not) to a\\\\nDataFrame\\\\n.\\\\napply()\\\\ncombined with some cleverness can be used to answer many questions\\nabout a data set. For example, suppose we wanted to extract the date where the\\nmaximum value for each column occurred:\\\\nIn [152]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n1000\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n1000\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [153]:\\\\ntsdf\\\\n.\\\\napply\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nidxmax\\\\n())\\\\nOut[153]:\\\\nA   2000-08-06\\\\nB   2001-01-18\\\\nC   2001-07-18\\\\ndtype: datetime64[ns]\\\\nYou may also pass additional arguments and keyword arguments to the\\\\napply()\\\\nmethod.\\\\nIn [154]:\\\\ndef\\\\nsubtract_and_divide\\\\n(\\\\nx\\\\n,\\\\nsub\\\\n,\\\\ndivide\\\\n=\\\\n1\\\\n):\\\\n.....:\\\\nreturn\\\\n(\\\\nx\\\\n-\\\\nsub\\\\n)\\\\n/\\\\ndivide\\\\n.....:\\\\nIn [155]:\\\\ndf_udf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nones\\\\n((\\\\n2\\\\n,\\\\n2\\\\n)))\\\\nIn [156]:\\\\ndf_udf\\\\n.\\\\napply\\\\n(\\\\nsubtract_and_divide\\\\n,\\\\nargs\\\\n=\\\\n(\\\\n5\\\\n,),\\\\ndivide\\\\n=\\\\n3\\\\n)\\\\nOut[156]:\\\\n0         1\\\\n0 -1.333333 -1.333333\\\\n1 -1.333333 -1.333333\\\\nAnother useful feature is the ability to pass Series methods to carry out some\\nSeries operation on each column or row:\\\\nIn [157]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n10\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [158]:\\\\ntsdf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n7\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [159]:\\\\ntsdf\\\\nOut[159]:\\\\nA         B         C\\\\n2000-01-01 -0.158131 -0.232466  0.321604\\\\n2000-01-02 -1.810340 -3.105758  0.433834\\\\n2000-01-03 -1.209847 -1.156793 -0.136794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08 -0.653602  0.178875  1.008298\\\\n2000-01-09  1.007996  0.462824  0.254472\\\\n2000-01-10  0.307473  0.600337  1.643950\\\\nIn [160]:\\\\ntsdf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nSeries\\\\n.\\\\ninterpolate\\\\n)\\\\nOut[160]:\\\\nA         B         C\\\\n2000-01-01 -0.158131 -0.232466  0.321604\\\\n2000-01-02 -1.810340 -3.105758  0.433834\\\\n2000-01-03 -1.209847 -1.156793 -0.136794\\\\n2000-01-04 -1.098598 -0.889659  0.092225\\\\n2000-01-05 -0.987349 -0.622526  0.321243\\\\n2000-01-06 -0.876100 -0.355392  0.550262\\\\n2000-01-07 -0.764851 -0.088259  0.779280\\\\n2000-01-08 -0.653602  0.178875  1.008298\\\\n2000-01-09  1.007996  0.462824  0.254472\\\\n2000-01-10  0.307473  0.600337  1.643950\\\\nFinally,\\\\napply()\\\\ntakes an argument\\\\nraw\\\\nwhich is False by default, which\\nconverts each row or column into a Series before applying the function. When\\nset to True, the passed function will instead receive an ndarray object, which\\nhas positive performance implications if you do not need the indexing\\nfunctionality.\\\\nAggregation API\\\\n#\\\\nThe aggregation API allows one to express possibly multiple aggregation operations in a single concise way.\\nThis API is similar across pandas objects, see\\\\ngroupby API\\\\n, the\\\\nwindow API\\\\n, and the\\\\nresample API\\\\n.\\nThe entry point for aggregation is\\\\nDataFrame.aggregate()\\\\n, or the alias\\\\nDataFrame.agg()\\\\n.\\\\nWe will use a similar starting frame from above:\\\\nIn [161]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n10\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [162]:\\\\ntsdf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n7\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [163]:\\\\ntsdf\\\\nOut[163]:\\\\nA         B         C\\\\n2000-01-01  1.257606  1.004194  0.167574\\\\n2000-01-02 -0.749892  0.288112 -0.757304\\\\n2000-01-03 -0.207550 -0.298599  0.116018\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.814347 -0.257623  0.869226\\\\n2000-01-09 -0.250663 -1.206601  0.896839\\\\n2000-01-10  2.169758 -1.333363  0.283157\\\\nUsing a single function is equivalent to\\\\napply()\\\\n. You can also\\npass named methods as strings. These will return a\\\\nSeries\\\\nof the aggregated\\noutput:\\\\nIn [164]:\\\\ntsdf\\\\n.\\\\nagg\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nnp\\\\n.\\\\nsum\\\\n(\\\\nx\\\\n))\\\\nOut[164]:\\\\nA    3.033606\\\\nB   -1.803879\\\\nC    1.575510\\\\ndtype: float64\\\\nIn [165]:\\\\ntsdf\\\\n.\\\\nagg\\\\n(\\\\n\"sum\"\\\\n)\\\\nOut[165]:\\\\nA    3.033606\\\\nB   -1.803879\\\\nC    1.575510\\\\ndtype: float64\\\\n# these are equivalent to a ``.sum()`` because we are aggregating\\\\n# on a single function\\\\nIn [166]:\\\\ntsdf\\\\n.\\\\nsum\\\\n()\\\\nOut[166]:\\\\nA    3.033606\\\\nB   -1.803879\\\\nC    1.575510\\\\ndtype: float64\\\\nSingle aggregations on a\\\\nSeries\\\\nthis will return a scalar value:\\\\nIn [167]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n(\\\\n\"sum\"\\\\n)\\\\nOut[167]:\\\\n3.033606102414146\\\\nAggregating with multiple functions\\\\n#\\\\nYou can pass multiple aggregation arguments as a list.\\nThe results of each of the passed functions will be a row in the resulting\\\\nDataFrame\\\\n.\\nThese are naturally named from the aggregation function.\\\\nIn [168]:\\\\ntsdf\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n])\\\\nOut[168]:\\\\nA         B        C\\\\nsum  3.033606 -1.803879  1.57551\\\\nMultiple functions yield multiple rows:\\\\nIn [169]:\\\\ntsdf\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\n\"mean\"\\\\n])\\\\nOut[169]:\\\\nA         B         C\\\\nsum   3.033606 -1.803879  1.575510\\\\nmean  0.505601 -0.300647  0.262585\\\\nOn a\\\\nSeries\\\\n, multiple functions return a\\\\nSeries\\\\n, indexed by the function names:\\\\nIn [170]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\n\"mean\"\\\\n])\\\\nOut[170]:\\\\nsum     3.033606\\\\nmean    0.505601\\\\nName: A, dtype: float64\\\\nPassing a\\\\nlambda\\\\nfunction will yield a\\\\n<lambda>\\\\nnamed row:\\\\nIn [171]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nmean\\\\n()])\\\\nOut[171]:\\\\nsum         3.033606\\\\n<lambda>    0.505601\\\\nName: A, dtype: float64\\\\nPassing a named function will yield that name for the row:\\\\nIn [172]:\\\\ndef\\\\nmymean\\\\n(\\\\nx\\\\n):\\\\n.....:\\\\nreturn\\\\nx\\\\n.\\\\nmean\\\\n()\\\\n.....:\\\\nIn [173]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nagg\\\\n([\\\\n\"sum\"\\\\n,\\\\nmymean\\\\n])\\\\nOut[173]:\\\\nsum       3.033606\\\\nmymean    0.505601\\\\nName: A, dtype: float64\\\\nAggregating with a dict\\\\n#\\\\nPassing a dictionary of column names to a scalar or a list of scalars, to\\\\nDataFrame.agg\\\\nallows you to customize which functions are applied to which columns. Note that the results\\nare not in any particular order, you can use an\\\\nOrderedDict\\\\ninstead to guarantee ordering.\\\\nIn [174]:\\\\ntsdf\\\\n.\\\\nagg\\\\n({\\\\n\"A\"\\\\n:\\\\n\"mean\"\\\\n,\\\\n\"B\"\\\\n:\\\\n\"sum\"\\\\n})\\\\nOut[174]:\\\\nA    0.505601\\\\nB   -1.803879\\\\ndtype: float64\\\\nPassing a list-like will generate a\\\\nDataFrame\\\\noutput. You will get a matrix-like output\\nof all of the aggregators. The output will consist of all unique functions. Those that are\\nnot noted for a particular column will be\\\\nNaN\\\\n:\\\\nIn [175]:\\\\ntsdf\\\\n.\\\\nagg\\\\n({\\\\n\"A\"\\\\n:\\\\n[\\\\n\"mean\"\\\\n,\\\\n\"min\"\\\\n],\\\\n\"B\"\\\\n:\\\\n\"sum\"\\\\n})\\\\nOut[175]:\\\\nA         B\\\\nmean  0.505601       NaN\\\\nmin  -0.749892       NaN\\\\nsum        NaN -1.803879\\\\nCustom describe\\\\n#\\\\nWith\\\\n.agg()\\\\nit is possible to easily create a custom describe function, similar\\nto the built in\\\\ndescribe function\\\\n.\\\\nIn [176]:\\\\nfrom\\\\nfunctools\\\\nimport\\\\npartial\\\\nIn [177]:\\\\nq_25\\\\n=\\\\npartial\\\\n(\\\\npd\\\\n.\\\\nSeries\\\\n.\\\\nquantile\\\\n,\\\\nq\\\\n=\\\\n0.25\\\\n)\\\\nIn [178]:\\\\nq_25\\\\n.\\\\n__name__\\\\n=\\\\n\"25%\"\\\\nIn [179]:\\\\nq_75\\\\n=\\\\npartial\\\\n(\\\\npd\\\\n.\\\\nSeries\\\\n.\\\\nquantile\\\\n,\\\\nq\\\\n=\\\\n0.75\\\\n)\\\\nIn [180]:\\\\nq_75\\\\n.\\\\n__name__\\\\n=\\\\n\"75%\"\\\\nIn [181]:\\\\ntsdf\\\\n.\\\\nagg\\\\n([\\\\n\"count\"\\\\n,\\\\n\"mean\"\\\\n,\\\\n\"std\"\\\\n,\\\\n\"min\"\\\\n,\\\\nq_25\\\\n,\\\\n\"median\"\\\\n,\\\\nq_75\\\\n,\\\\n\"max\"\\\\n])\\\\nOut[181]:\\\\nA         B         C\\\\ncount   6.000000  6.000000  6.000000\\\\nmean    0.505601 -0.300647  0.262585\\\\nstd     1.103362  0.887508  0.606860\\\\nmin    -0.749892 -1.333363 -0.757304\\\\n25%    -0.239885 -0.979600  0.128907\\\\nmedian  0.303398 -0.278111  0.225365\\\\n75%     1.146791  0.151678  0.722709\\\\nmax     2.169758  1.004194  0.896839\\\\nTransform API\\\\n#\\\\nThe\\\\ntransform()\\\\nmethod returns an object that is indexed the same (same size)\\nas the original. This API allows you to provide\\\\nmultiple\\\\noperations at the same\\ntime rather than one-by-one. Its API is quite similar to the\\\\n.agg\\\\nAPI.\\\\nWe create a frame similar to the one used in the above sections.\\\\nIn [182]:\\\\ntsdf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n10\\\\n,\\\\n3\\\\n),\\\\n.....:\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n],\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/1/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n10\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [183]:\\\\ntsdf\\\\n.\\\\niloc\\\\n[\\\\n3\\\\n:\\\\n7\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [184]:\\\\ntsdf\\\\nOut[184]:\\\\nA         B         C\\\\n2000-01-01 -0.428759 -0.864890 -0.675341\\\\n2000-01-02 -0.168731  1.338144 -1.279321\\\\n2000-01-03 -1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374 -1.240447 -0.201052\\\\n2000-01-09 -0.157795  0.791197 -1.144209\\\\n2000-01-10 -0.030876  0.371900  0.061932\\\\nTransform the entire frame.\\\\n.transform()\\\\nallows input functions as: a NumPy function, a string\\nfunction name or a user defined function.\\\\nIn [185]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n(\\\\nnp\\\\n.\\\\nabs\\\\n)\\\\nOut[185]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nIn [186]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n(\\\\n\"abs\"\\\\n)\\\\nOut[186]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nIn [187]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n(\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nabs\\\\n())\\\\nOut[187]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nHere\\\\ntransform()\\\\nreceived a single function; this is equivalent to a\\\\nufunc\\\\napplication.\\\\nIn [188]:\\\\nnp\\\\n.\\\\nabs\\\\n(\\\\ntsdf\\\\n)\\\\nOut[188]:\\\\nA         B         C\\\\n2000-01-01  0.428759  0.864890  0.675341\\\\n2000-01-02  0.168731  1.338144  1.279321\\\\n2000-01-03  1.621034  0.438107  0.903794\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.240447  0.201052\\\\n2000-01-09  0.157795  0.791197  1.144209\\\\n2000-01-10  0.030876  0.371900  0.061932\\\\nPassing a single function to\\\\n.transform()\\\\nwith a\\\\nSeries\\\\nwill yield a single\\\\nSeries\\\\nin return.\\\\nIn [189]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\ntransform\\\\n(\\\\nnp\\\\n.\\\\nabs\\\\n)\\\\nOut[189]:\\\\n2000-01-01    0.428759\\\\n2000-01-02    0.168731\\\\n2000-01-03    1.621034\\\\n2000-01-04         NaN\\\\n2000-01-05         NaN\\\\n2000-01-06         NaN\\\\n2000-01-07         NaN\\\\n2000-01-08    0.254374\\\\n2000-01-09    0.157795\\\\n2000-01-10    0.030876\\\\nFreq: D, Name: A, dtype: float64\\\\nTransform with multiple functions\\\\n#\\\\nPassing multiple functions will yield a column MultiIndexed DataFrame.\\nThe first level will be the original frame column names; the second level\\nwill be the names of the transforming functions.\\\\nIn [190]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n([\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n])\\\\nOut[190]:\\\\nA                   B                   C\\\\nabsolute  <lambda>  absolute  <lambda>  absolute  <lambda>\\\\n2000-01-01  0.428759  0.571241  0.864890  0.135110  0.675341  0.324659\\\\n2000-01-02  0.168731  0.831269  1.338144  2.338144  1.279321 -0.279321\\\\n2000-01-03  1.621034 -0.621034  0.438107  1.438107  0.903794  1.903794\\\\n2000-01-04       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN       NaN       NaN       NaN\\\\n2000-01-08  0.254374  1.254374  1.240447 -0.240447  0.201052  0.798948\\\\n2000-01-09  0.157795  0.842205  0.791197  1.791197  1.144209 -0.144209\\\\n2000-01-10  0.030876  0.969124  0.371900  1.371900  0.061932  1.061932\\\\nPassing multiple functions to a Series will yield a DataFrame. The\\nresulting column names will be the transforming functions.\\\\nIn [191]:\\\\ntsdf\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\ntransform\\\\n([\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n])\\\\nOut[191]:\\\\nabsolute  <lambda>\\\\n2000-01-01  0.428759  0.571241\\\\n2000-01-02  0.168731  0.831269\\\\n2000-01-03  1.621034 -0.621034\\\\n2000-01-04       NaN       NaN\\\\n2000-01-05       NaN       NaN\\\\n2000-01-06       NaN       NaN\\\\n2000-01-07       NaN       NaN\\\\n2000-01-08  0.254374  1.254374\\\\n2000-01-09  0.157795  0.842205\\\\n2000-01-10  0.030876  0.969124\\\\nTransforming with a dict\\\\n#\\\\nPassing a dict of functions will allow selective transforming per column.\\\\nIn [192]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n({\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\n\"B\"\\\\n:\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n})\\\\nOut[192]:\\\\nA         B\\\\n2000-01-01  0.428759  0.135110\\\\n2000-01-02  0.168731  2.338144\\\\n2000-01-03  1.621034  1.438107\\\\n2000-01-04       NaN       NaN\\\\n2000-01-05       NaN       NaN\\\\n2000-01-06       NaN       NaN\\\\n2000-01-07       NaN       NaN\\\\n2000-01-08  0.254374 -0.240447\\\\n2000-01-09  0.157795  1.791197\\\\n2000-01-10  0.030876  1.371900\\\\nPassing a dict of lists will generate a MultiIndexed DataFrame with these\\nselective transforms.\\\\nIn [193]:\\\\ntsdf\\\\n.\\\\ntransform\\\\n({\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nabs\\\\n,\\\\n\"B\"\\\\n:\\\\n[\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n+\\\\n1\\\\n,\\\\n\"sqrt\"\\\\n]})\\\\nOut[193]:\\\\nA         B\\\\nabsolute  <lambda>      sqrt\\\\n2000-01-01  0.428759  0.135110       NaN\\\\n2000-01-02  0.168731  2.338144  1.156782\\\\n2000-01-03  1.621034  1.438107  0.661897\\\\n2000-01-04       NaN       NaN       NaN\\\\n2000-01-05       NaN       NaN       NaN\\\\n2000-01-06       NaN       NaN       NaN\\\\n2000-01-07       NaN       NaN       NaN\\\\n2000-01-08  0.254374 -0.240447       NaN\\\\n2000-01-09  0.157795  1.791197  0.889493\\\\n2000-01-10  0.030876  1.371900  0.609836\\\\nApplying elementwise functions\\\\n#\\\\nSince not all functions can be vectorized (accept NumPy arrays and return\\nanother array or value), the methods\\\\nmap()\\\\non DataFrame\\nand analogously\\\\nmap()\\\\non Series accept any Python function taking\\na single value and returning a single value. For example:\\\\nIn [194]:\\\\ndf4\\\\n=\\\\ndf\\\\n.\\\\ncopy\\\\n()\\\\nIn [195]:\\\\ndf4\\\\nOut[195]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [196]:\\\\ndef\\\\nf\\\\n(\\\\nx\\\\n):\\\\n.....:\\\\nreturn\\\\nlen\\\\n(\\\\nstr\\\\n(\\\\nx\\\\n))\\\\n.....:\\\\nIn [197]:\\\\ndf4\\\\n[\\\\n\"one\"\\\\n]\\\\n.\\\\nmap\\\\n(\\\\nf\\\\n)\\\\nOut[197]:\\\\na    18\\\\nb    19\\\\nc    18\\\\nd     3\\\\nName: one, dtype: int64\\\\nIn [198]:\\\\ndf4\\\\n.\\\\nmap\\\\n(\\\\nf\\\\n)\\\\nOut[198]:\\\\none  two  three\\\\na   18   17      3\\\\nb   19   18     20\\\\nc   18   18     16\\\\nd    3   19     19\\\\nSeries.map()\\\\nhas an additional feature; it can be used to easily\\n“link” or “map” values defined by a secondary series. This is closely related\\nto\\\\nmerging/joining functionality\\\\n:\\\\nIn [199]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n.....:\\\\n[\\\\n\"six\"\\\\n,\\\\n\"seven\"\\\\n,\\\\n\"six\"\\\\n,\\\\n\"seven\"\\\\n,\\\\n\"six\"\\\\n],\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [200]:\\\\nt\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n({\\\\n\"six\"\\\\n:\\\\n6.0\\\\n,\\\\n\"seven\"\\\\n:\\\\n7.0\\\\n})\\\\nIn [201]:\\\\ns\\\\nOut[201]:\\\\na      six\\\\nb    seven\\\\nc      six\\\\nd    seven\\\\ne      six\\\\ndtype: object\\\\nIn [202]:\\\\ns\\\\n.\\\\nmap\\\\n(\\\\nt\\\\n)\\\\nOut[202]:\\\\na    6.0\\\\nb    7.0\\\\nc    6.0\\\\nd    7.0\\\\ne    6.0\\\\ndtype: float64\\\\nReindexing and altering labels\\\\n#\\\\nreindex()\\\\nis the fundamental data alignment method in pandas.\\nIt is used to implement nearly all other features relying on label-alignment\\nfunctionality. To\\\\nreindex\\\\nmeans to conform the data to match a given set of\\nlabels along a particular axis. This accomplishes several things:\\\\nReorders the existing data to match a new set of labels\\\\nInserts missing value (NA) markers in label locations where no data for\\nthat label existed\\\\nIf specified,\\\\nfill\\\\ndata for missing labels using logic (highly relevant\\nto working with time series data)\\\\nHere is a simple example:\\\\nIn [203]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [204]:\\\\ns\\\\nOut[204]:\\\\na    1.695148\\\\nb    1.328614\\\\nc    1.234686\\\\nd   -0.385845\\\\ne   -1.326508\\\\ndtype: float64\\\\nIn [205]:\\\\ns\\\\n.\\\\nreindex\\\\n([\\\\n\"e\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"f\"\\\\n,\\\\n\"d\"\\\\n])\\\\nOut[205]:\\\\ne   -1.326508\\\\nb    1.328614\\\\nf         NaN\\\\nd   -0.385845\\\\ndtype: float64\\\\nHere, the\\\\nf\\\\nlabel was not contained in the Series and hence appears as\\\\nNaN\\\\nin the result.\\\\nWith a DataFrame, you can simultaneously reindex the index and columns:\\\\nIn [206]:\\\\ndf\\\\nOut[206]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [207]:\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\nindex\\\\n=\\\\n[\\\\n\"c\"\\\\n,\\\\n\"f\"\\\\n,\\\\n\"b\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n])\\\\nOut[207]:\\\\nthree       two       one\\\\nc  1.227435  1.478369  0.695246\\\\nf       NaN       NaN       NaN\\\\nb -0.050390  1.912123  0.343054\\\\nNote that the\\\\nIndex\\\\nobjects containing the actual axis labels can be\\\\nshared\\\\nbetween objects. So if we have a Series and a DataFrame, the\\nfollowing can be done:\\\\nIn [208]:\\\\nrs\\\\n=\\\\ns\\\\n.\\\\nreindex\\\\n(\\\\ndf\\\\n.\\\\nindex\\\\n)\\\\nIn [209]:\\\\nrs\\\\nOut[209]:\\\\na    1.695148\\\\nb    1.328614\\\\nc    1.234686\\\\nd   -0.385845\\\\ndtype: float64\\\\nIn [210]:\\\\nrs\\\\n.\\\\nindex\\\\nis\\\\ndf\\\\n.\\\\nindex\\\\nOut[210]:\\\\nTrue\\\\nThis means that the reindexed Series’s index is the same Python object as the\\nDataFrame’s index.\\\\nDataFrame.reindex()\\\\nalso supports an “axis-style” calling convention,\\nwhere you specify a single\\\\nlabels\\\\nargument and the\\\\naxis\\\\nit applies to.\\\\nIn [211]:\\\\ndf\\\\n.\\\\nreindex\\\\n([\\\\n\"c\"\\\\n,\\\\n\"f\"\\\\n,\\\\n\"b\"\\\\n],\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[211]:\\\\none       two     three\\\\nc  0.695246  1.478369  1.227435\\\\nf       NaN       NaN       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nIn [212]:\\\\ndf\\\\n.\\\\nreindex\\\\n([\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n],\\\\naxis\\\\n=\\\\n\"columns\"\\\\n)\\\\nOut[212]:\\\\nthree       two       one\\\\na       NaN  1.772517  1.394981\\\\nb -0.050390  1.912123  0.343054\\\\nc  1.227435  1.478369  0.695246\\\\nd -0.613172  0.279344       NaN\\\\nSee also\\\\nMultiIndex / Advanced Indexing\\\\nis an even more concise way of\\ndoing reindexing.\\\\nNote\\\\nWhen writing performance-sensitive code, there is a good reason to spend\\nsome time becoming a reindexing ninja:\\\\nmany operations are faster on\\npre-aligned data\\\\n. Adding two unaligned DataFrames internally triggers a\\nreindexing step. For exploratory analysis you will hardly notice the\\ndifference (because\\\\nreindex\\\\nhas been heavily optimized), but when CPU\\ncycles matter sprinkling a few explicit\\\\nreindex\\\\ncalls here and there can\\nhave an impact.\\\\nReindexing to align with another object\\\\n#\\\\nYou may wish to take an object and reindex its axes to be labeled the same as\\nanother object. While the syntax for this is straightforward albeit verbose, it\\nis a common enough operation that the\\\\nreindex_like()\\\\nmethod is\\navailable to make this simpler:\\\\nIn [213]:\\\\ndf2\\\\n=\\\\ndf\\\\n.\\\\nreindex\\\\n([\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n])\\\\nIn [214]:\\\\ndf3\\\\n=\\\\ndf2\\\\n-\\\\ndf2\\\\n.\\\\nmean\\\\n()\\\\nIn [215]:\\\\ndf2\\\\nOut[215]:\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369\\\\nIn [216]:\\\\ndf3\\\\nOut[216]:\\\\none       two\\\\na  0.583888  0.051514\\\\nb -0.468040  0.191120\\\\nc -0.115848 -0.242634\\\\nIn [217]:\\\\ndf\\\\n.\\\\nreindex_like\\\\n(\\\\ndf2\\\\n)\\\\nOut[217]:\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369\\\\nAligning objects with each other with\\\\nalign\\\\n#\\\\nThe\\\\nalign()\\\\nmethod is the fastest way to simultaneously align two objects. It\\nsupports a\\\\njoin\\\\nargument (related to\\\\njoining and merging\\\\n):\\\\njoin=\\'outer\\'\\\\n: take the union of the indexes (default)\\\\njoin=\\'left\\'\\\\n: use the calling object’s index\\\\njoin=\\'right\\'\\\\n: use the passed object’s index\\\\njoin=\\'inner\\'\\\\n: intersect the indexes\\\\nIt returns a tuple with both of the reindexed Series:\\\\nIn [218]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n5\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"e\"\\\\n])\\\\nIn [219]:\\\\ns1\\\\n=\\\\ns\\\\n[:\\\\n4\\\\n]\\\\nIn [220]:\\\\ns2\\\\n=\\\\ns\\\\n[\\\\n1\\\\n:]\\\\nIn [221]:\\\\ns1\\\\n.\\\\nalign\\\\n(\\\\ns2\\\\n)\\\\nOut[221]:\\\\n(a   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne         NaN\\\\ndtype: float64,\\\\na         NaN\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne    1.114285\\\\ndtype: float64)\\\\nIn [222]:\\\\ns1\\\\n.\\\\nalign\\\\n(\\\\ns2\\\\n,\\\\njoin\\\\n=\\\\n\"inner\"\\\\n)\\\\nOut[222]:\\\\n(b   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64,\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64)\\\\nIn [223]:\\\\ns1\\\\n.\\\\nalign\\\\n(\\\\ns2\\\\n,\\\\njoin\\\\n=\\\\n\"left\"\\\\n)\\\\nOut[223]:\\\\n(a   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64,\\\\na         NaN\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ndtype: float64)\\\\nFor DataFrames, the join method will be applied to both the index and the\\ncolumns by default:\\\\nIn [224]:\\\\ndf\\\\n.\\\\nalign\\\\n(\\\\ndf2\\\\n,\\\\njoin\\\\n=\\\\n\"inner\"\\\\n)\\\\nOut[224]:\\\\n(        one       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369,\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369)\\\\nYou can also pass an\\\\naxis\\\\noption to only align on the specified axis:\\\\nIn [225]:\\\\ndf\\\\n.\\\\nalign\\\\n(\\\\ndf2\\\\n,\\\\njoin\\\\n=\\\\n\"inner\"\\\\n,\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[225]:\\\\n(        one       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435,\\\\none       two\\\\na  1.394981  1.772517\\\\nb  0.343054  1.912123\\\\nc  0.695246  1.478369)\\\\nIf you pass a Series to\\\\nDataFrame.align()\\\\n, you can choose to align both\\nobjects either on the DataFrame’s index or columns using the\\\\naxis\\\\nargument:\\\\nIn [226]:\\\\ndf\\\\n.\\\\nalign\\\\n(\\\\ndf2\\\\n.\\\\niloc\\\\n[\\\\n0\\\\n],\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[226]:\\\\n(        one     three       two\\\\na  1.394981       NaN  1.772517\\\\nb  0.343054 -0.050390  1.912123\\\\nc  0.695246  1.227435  1.478369\\\\nd       NaN -0.613172  0.279344,\\\\none      1.394981\\\\nthree         NaN\\\\ntwo      1.772517\\\\nName: a, dtype: float64)\\\\nFilling while reindexing\\\\n#\\\\nreindex()\\\\ntakes an optional parameter\\\\nmethod\\\\nwhich is a\\nfilling method chosen from the following table:\\\\nMethod\\\\nAction\\\\npad / ffill\\\\nFill values forward\\\\nbfill / backfill\\\\nFill values backward\\\\nnearest\\\\nFill from the nearest index value\\\\nWe illustrate these fill methods on a simple Series:\\\\nIn [227]:\\\\nrng\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"1/3/2000\"\\\\n,\\\\nperiods\\\\n=\\\\n8\\\\n)\\\\nIn [228]:\\\\nts\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\nindex\\\\n=\\\\nrng\\\\n)\\\\nIn [229]:\\\\nts2\\\\n=\\\\nts\\\\n.\\\\niloc\\\\n[[\\\\n0\\\\n,\\\\n3\\\\n,\\\\n6\\\\n]]\\\\nIn [230]:\\\\nts\\\\nOut[230]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.400528\\\\n2000-01-05   -0.015083\\\\n2000-01-06    2.395489\\\\n2000-01-07    1.414806\\\\n2000-01-08    0.118428\\\\n2000-01-09    0.733639\\\\n2000-01-10   -0.936077\\\\nFreq: D, dtype: float64\\\\nIn [231]:\\\\nts2\\\\nOut[231]:\\\\n2000-01-03    0.183051\\\\n2000-01-06    2.395489\\\\n2000-01-09    0.733639\\\\nFreq: 3D, dtype: float64\\\\nIn [232]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n)\\\\nOut[232]:\\\\n2000-01-03    0.183051\\\\n2000-01-04         NaN\\\\n2000-01-05         NaN\\\\n2000-01-06    2.395489\\\\n2000-01-07         NaN\\\\n2000-01-08         NaN\\\\n2000-01-09    0.733639\\\\n2000-01-10         NaN\\\\nFreq: D, dtype: float64\\\\nIn [233]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"ffill\"\\\\n)\\\\nOut[233]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05    0.183051\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08    2.395489\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nIn [234]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"bfill\"\\\\n)\\\\nOut[234]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    2.395489\\\\n2000-01-05    2.395489\\\\n2000-01-06    2.395489\\\\n2000-01-07    0.733639\\\\n2000-01-08    0.733639\\\\n2000-01-09    0.733639\\\\n2000-01-10         NaN\\\\nFreq: D, dtype: float64\\\\nIn [235]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"nearest\"\\\\n)\\\\nOut[235]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05    2.395489\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08    0.733639\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nThese methods require that the indexes are\\\\nordered\\\\nincreasing or\\ndecreasing.\\\\nNote that the same result could have been achieved using\\\\nffill\\\\n(except for\\\\nmethod=\\'nearest\\'\\\\n) or\\\\ninterpolate\\\\n:\\\\nIn [236]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n)\\\\n.\\\\nffill\\\\n()\\\\nOut[236]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05    0.183051\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08    2.395489\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nreindex()\\\\nwill raise a ValueError if the index is not monotonically\\nincreasing or decreasing.\\\\nfillna()\\\\nand\\\\ninterpolate()\\\\nwill not perform any checks on the order of the index.\\\\nLimits on filling while reindexing\\\\n#\\\\nThe\\\\nlimit\\\\nand\\\\ntolerance\\\\narguments provide additional control over\\nfilling while reindexing. Limit specifies the maximum count of consecutive\\nmatches:\\\\nIn [237]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"ffill\"\\\\n,\\\\nlimit\\\\n=\\\\n1\\\\n)\\\\nOut[237]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05         NaN\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08         NaN\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nIn contrast, tolerance specifies the maximum distance between the index and\\nindexer values:\\\\nIn [238]:\\\\nts2\\\\n.\\\\nreindex\\\\n(\\\\nts\\\\n.\\\\nindex\\\\n,\\\\nmethod\\\\n=\\\\n\"ffill\"\\\\n,\\\\ntolerance\\\\n=\\\\n\"1 day\"\\\\n)\\\\nOut[238]:\\\\n2000-01-03    0.183051\\\\n2000-01-04    0.183051\\\\n2000-01-05         NaN\\\\n2000-01-06    2.395489\\\\n2000-01-07    2.395489\\\\n2000-01-08         NaN\\\\n2000-01-09    0.733639\\\\n2000-01-10    0.733639\\\\nFreq: D, dtype: float64\\\\nNotice that when used on a\\\\nDatetimeIndex\\\\n,\\\\nTimedeltaIndex\\\\nor\\\\nPeriodIndex\\\\n,\\\\ntolerance\\\\nwill coerced into a\\\\nTimedelta\\\\nif possible.\\nThis allows you to specify tolerance with appropriate strings.\\\\nDropping labels from an axis\\\\n#\\\\nA method closely related to\\\\nreindex\\\\nis the\\\\ndrop()\\\\nfunction.\\nIt removes a set of labels from an axis:\\\\nIn [239]:\\\\ndf\\\\nOut[239]:\\\\none       two     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [240]:\\\\ndf\\\\n.\\\\ndrop\\\\n([\\\\n\"a\"\\\\n,\\\\n\"d\"\\\\n],\\\\naxis\\\\n=\\\\n0\\\\n)\\\\nOut[240]:\\\\none       two     three\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nIn [241]:\\\\ndf\\\\n.\\\\ndrop\\\\n([\\\\n\"one\"\\\\n],\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[241]:\\\\ntwo     three\\\\na  1.772517       NaN\\\\nb  1.912123 -0.050390\\\\nc  1.478369  1.227435\\\\nd  0.279344 -0.613172\\\\nNote that the following also works, but is a bit less obvious / clean:\\\\nIn [242]:\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\ndf\\\\n.\\\\nindex\\\\n.\\\\ndifference\\\\n([\\\\n\"a\"\\\\n,\\\\n\"d\"\\\\n]))\\\\nOut[242]:\\\\none       two     three\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nRenaming / mapping labels\\\\n#\\\\nThe\\\\nrename()\\\\nmethod allows you to relabel an axis based on some\\nmapping (a dict or Series) or an arbitrary function.\\\\nIn [243]:\\\\ns\\\\nOut[243]:\\\\na   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne    1.114285\\\\ndtype: float64\\\\nIn [244]:\\\\ns\\\\n.\\\\nrename\\\\n(\\\\nstr\\\\n.\\\\nupper\\\\n)\\\\nOut[244]:\\\\nA   -0.186646\\\\nB   -1.692424\\\\nC   -0.303893\\\\nD   -1.425662\\\\nE    1.114285\\\\ndtype: float64\\\\nIf you pass a function, it must return a value when called with any of the\\nlabels (and must produce a set of unique values). A dict or\\nSeries can also be used:\\\\nIn [245]:\\\\ndf\\\\n.\\\\nrename\\\\n(\\\\n.....:\\\\ncolumns\\\\n=\\\\n{\\\\n\"one\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n\"two\"\\\\n:\\\\n\"bar\"\\\\n},\\\\n.....:\\\\nindex\\\\n=\\\\n{\\\\n\"a\"\\\\n:\\\\n\"apple\"\\\\n,\\\\n\"b\"\\\\n:\\\\n\"banana\"\\\\n,\\\\n\"d\"\\\\n:\\\\n\"durian\"\\\\n},\\\\n.....:\\\\n)\\\\n.....:\\\\nOut[245]:\\\\nfoo       bar     three\\\\napple   1.394981  1.772517       NaN\\\\nbanana  0.343054  1.912123 -0.050390\\\\nc       0.695246  1.478369  1.227435\\\\ndurian       NaN  0.279344 -0.613172\\\\nIf the mapping doesn’t include a column/index label, it isn’t renamed. Note that\\nextra labels in the mapping don’t throw an error.\\\\nDataFrame.rename()\\\\nalso supports an “axis-style” calling convention, where\\nyou specify a single\\\\nmapper\\\\nand the\\\\naxis\\\\nto apply that mapping to.\\\\nIn [246]:\\\\ndf\\\\n.\\\\nrename\\\\n({\\\\n\"one\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n\"two\"\\\\n:\\\\n\"bar\"\\\\n},\\\\naxis\\\\n=\\\\n\"columns\"\\\\n)\\\\nOut[246]:\\\\nfoo       bar     three\\\\na  1.394981  1.772517       NaN\\\\nb  0.343054  1.912123 -0.050390\\\\nc  0.695246  1.478369  1.227435\\\\nd       NaN  0.279344 -0.613172\\\\nIn [247]:\\\\ndf\\\\n.\\\\nrename\\\\n({\\\\n\"a\"\\\\n:\\\\n\"apple\"\\\\n,\\\\n\"b\"\\\\n:\\\\n\"banana\"\\\\n,\\\\n\"d\"\\\\n:\\\\n\"durian\"\\\\n},\\\\naxis\\\\n=\\\\n\"index\"\\\\n)\\\\nOut[247]:\\\\none       two     three\\\\napple   1.394981  1.772517       NaN\\\\nbanana  0.343054  1.912123 -0.050390\\\\nc       0.695246  1.478369  1.227435\\\\ndurian       NaN  0.279344 -0.613172\\\\nFinally,\\\\nrename()\\\\nalso accepts a scalar or list-like\\nfor altering the\\\\nSeries.name\\\\nattribute.\\\\nIn [248]:\\\\ns\\\\n.\\\\nrename\\\\n(\\\\n\"scalar-name\"\\\\n)\\\\nOut[248]:\\\\na   -0.186646\\\\nb   -1.692424\\\\nc   -0.303893\\\\nd   -1.425662\\\\ne    1.114285\\\\nName: scalar-name, dtype: float64\\\\nThe methods\\\\nDataFrame.rename_axis()\\\\nand\\\\nSeries.rename_axis()\\\\nallow specific names of a\\\\nMultiIndex\\\\nto be changed (as opposed to the\\nlabels).\\\\nIn [249]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"x\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"y\"\\\\n:\\\\n[\\\\n10\\\\n,\\\\n20\\\\n,\\\\n30\\\\n,\\\\n40\\\\n,\\\\n50\\\\n,\\\\n60\\\\n]},\\\\n.....:\\\\nindex\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_product\\\\n(\\\\n.....:\\\\n[[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n],\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]],\\\\nnames\\\\n=\\\\n[\\\\n\"let\"\\\\n,\\\\n\"num\"\\\\n]\\\\n.....:\\\\n),\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [250]:\\\\ndf\\\\nOut[250]:\\\\nx   y\\\\nlet num\\\\na   1    1  10\\\\n2    2  20\\\\nb   1    3  30\\\\n2    4  40\\\\nc   1    5  50\\\\n2    6  60\\\\nIn [251]:\\\\ndf\\\\n.\\\\nrename_axis\\\\n(\\\\nindex\\\\n=\\\\n{\\\\n\"let\"\\\\n:\\\\n\"abc\"\\\\n})\\\\nOut[251]:\\\\nx   y\\\\nabc num\\\\na   1    1  10\\\\n2    2  20\\\\nb   1    3  30\\\\n2    4  40\\\\nc   1    5  50\\\\n2    6  60\\\\nIn [252]:\\\\ndf\\\\n.\\\\nrename_axis\\\\n(\\\\nindex\\\\n=\\\\nstr\\\\n.\\\\nupper\\\\n)\\\\nOut[252]:\\\\nx   y\\\\nLET NUM\\\\na   1    1  10\\\\n2    2  20\\\\nb   1    3  30\\\\n2    4  40\\\\nc   1    5  50\\\\n2    6  60\\\\nIteration\\\\n#\\\\nThe behavior of basic iteration over pandas objects depends on the type.\\nWhen iterating over a Series, it is regarded as array-like, and basic iteration\\nproduces the values. DataFrames follow the dict-like convention of iterating\\nover the “keys” of the objects.\\\\nIn short, basic iteration (\\\\nfor\\\\ni\\\\nin\\\\nobject\\\\n) produces:\\\\nSeries\\\\n: values\\\\nDataFrame\\\\n: column labels\\\\nThus, for example, iterating over a DataFrame gives you the column names:\\\\nIn [253]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"col1\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\n\"col2\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n)},\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [254]:\\\\nfor\\\\ncol\\\\nin\\\\ndf\\\\n:\\\\n.....:\\\\nprint\\\\n(\\\\ncol\\\\n)\\\\n.....:\\\\ncol1\\\\ncol2\\\\npandas objects also have the dict-like\\\\nitems()\\\\nmethod to\\niterate over the (key, value) pairs.\\\\nTo iterate over the rows of a DataFrame, you can use the following methods:\\\\niterrows()\\\\n: Iterate over the rows of a DataFrame as (index, Series) pairs.\\nThis converts the rows to Series objects, which can change the dtypes and has some\\nperformance implications.\\\\nitertuples()\\\\n: Iterate over the rows of a DataFrame\\nas namedtuples of the values.  This is a lot faster than\\\\niterrows()\\\\n, and is in most cases preferable to use\\nto iterate over the values of a DataFrame.\\\\nWarning\\\\nIterating through pandas objects is generally\\\\nslow\\\\n. In many cases,\\niterating manually over the rows is not needed and can be avoided with\\none of the following approaches:\\\\nLook for a\\\\nvectorized\\\\nsolution: many operations can be performed using\\nbuilt-in methods or NumPy functions, (boolean) indexing, …\\\\nWhen you have a function that cannot work on the full DataFrame/Series\\nat once, it is better to use\\\\napply()\\\\ninstead of iterating\\nover the values. See the docs on\\\\nfunction application\\\\n.\\\\nIf you need to do iterative manipulations on the values but performance is\\nimportant, consider writing the inner loop with cython or numba.\\nSee the\\\\nenhancing performance\\\\nsection for some\\nexamples of this approach.\\\\nWarning\\\\nYou should\\\\nnever modify\\\\nsomething you are iterating over.\\nThis is not guaranteed to work in all cases. Depending on the\\ndata types, the iterator returns a copy and not a view, and writing\\nto it will have no effect!\\\\nFor example, in the following case setting the value has no effect:\\\\nIn [255]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]})\\\\nIn [256]:\\\\nfor\\\\nindex\\\\n,\\\\nrow\\\\nin\\\\ndf\\\\n.\\\\niterrows\\\\n():\\\\n.....:\\\\nrow\\\\n[\\\\n\"a\"\\\\n]\\\\n=\\\\n10\\\\n.....:\\\\nIn [257]:\\\\ndf\\\\nOut[257]:\\\\na  b\\\\n0  1  a\\\\n1  2  b\\\\n2  3  c\\\\nitems\\\\n#\\\\nConsistent with the dict-like interface,\\\\nitems()\\\\niterates\\nthrough key-value pairs:\\\\nSeries\\\\n: (index, scalar value) pairs\\\\nDataFrame\\\\n: (column, Series) pairs\\\\nFor example:\\\\nIn [258]:\\\\nfor\\\\nlabel\\\\n,\\\\nser\\\\nin\\\\ndf\\\\n.\\\\nitems\\\\n():\\\\n.....:\\\\nprint\\\\n(\\\\nlabel\\\\n)\\\\n.....:\\\\nprint\\\\n(\\\\nser\\\\n)\\\\n.....:\\\\na\\\\n0    1\\\\n1    2\\\\n2    3\\\\nName: a, dtype: int64\\\\nb\\\\n0    a\\\\n1    b\\\\n2    c\\\\nName: b, dtype: object\\\\niterrows\\\\n#\\\\niterrows()\\\\nallows you to iterate through the rows of a\\nDataFrame as Series objects. It returns an iterator yielding each\\nindex value along with a Series containing the data in each row:\\\\nIn [259]:\\\\nfor\\\\nrow_index\\\\n,\\\\nrow\\\\nin\\\\ndf\\\\n.\\\\niterrows\\\\n():\\\\n.....:\\\\nprint\\\\n(\\\\nrow_index\\\\n,\\\\nrow\\\\n,\\\\nsep\\\\n=\\\\n\"\\\\n\\\\n\\\\n\"\\\\n)\\\\n.....:\\\\n0\\\\na    1\\\\nb    a\\\\nName: 0, dtype: object\\\\n1\\\\na    2\\\\nb    b\\\\nName: 1, dtype: object\\\\n2\\\\na    3\\\\nb    c\\\\nName: 2, dtype: object\\\\nNote\\\\nBecause\\\\niterrows()\\\\nreturns a Series for each row,\\nit does\\\\nnot\\\\npreserve dtypes across the rows (dtypes are\\npreserved across columns for DataFrames). For example,\\\\nIn [260]:\\\\ndf_orig\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n1\\\\n,\\\\n1.5\\\\n]],\\\\ncolumns\\\\n=\\\\n[\\\\n\"int\"\\\\n,\\\\n\"float\"\\\\n])\\\\nIn [261]:\\\\ndf_orig\\\\n.\\\\ndtypes\\\\nOut[261]:\\\\nint        int64\\\\nfloat    float64\\\\ndtype: object\\\\nIn [262]:\\\\nrow\\\\n=\\\\nnext\\\\n(\\\\ndf_orig\\\\n.\\\\niterrows\\\\n())[\\\\n1\\\\n]\\\\nIn [263]:\\\\nrow\\\\nOut[263]:\\\\nint      1.0\\\\nfloat    1.5\\\\nName: 0, dtype: float64\\\\nAll values in\\\\nrow\\\\n, returned as a Series, are now upcasted\\nto floats, also the original integer value in column\\\\nx\\\\n:\\\\nIn [264]:\\\\nrow\\\\n[\\\\n\"int\"\\\\n]\\\\n.\\\\ndtype\\\\nOut[264]:\\\\ndtype(\\'float64\\')\\\\nIn [265]:\\\\ndf_orig\\\\n[\\\\n\"int\"\\\\n]\\\\n.\\\\ndtype\\\\nOut[265]:\\\\ndtype(\\'int64\\')\\\\nTo preserve dtypes while iterating over the rows, it is better\\nto use\\\\nitertuples()\\\\nwhich returns namedtuples of the values\\nand which is generally much faster than\\\\niterrows()\\\\n.\\\\nFor instance, a contrived way to transpose the DataFrame would be:\\\\nIn [266]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"x\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"y\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n]})\\\\nIn [267]:\\\\nprint\\\\n(\\\\ndf2\\\\n)\\\\nx  y\\\\n0  1  4\\\\n1  2  5\\\\n2  3  6\\\\nIn [268]:\\\\nprint\\\\n(\\\\ndf2\\\\n.\\\\nT\\\\n)\\\\n0  1  2\\\\nx  1  2  3\\\\ny  4  5  6\\\\nIn [269]:\\\\ndf2_t\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\nidx\\\\n:\\\\nvalues\\\\nfor\\\\nidx\\\\n,\\\\nvalues\\\\nin\\\\ndf2\\\\n.\\\\niterrows\\\\n()})\\\\nIn [270]:\\\\nprint\\\\n(\\\\ndf2_t\\\\n)\\\\n0  1  2\\\\nx  1  2  3\\\\ny  4  5  6\\\\nitertuples\\\\n#\\\\nThe\\\\nitertuples()\\\\nmethod will return an iterator\\nyielding a namedtuple for each row in the DataFrame. The first element\\nof the tuple will be the row’s corresponding index value, while the\\nremaining values are the row values.\\\\nFor instance:\\\\nIn [271]:\\\\nfor\\\\nrow\\\\nin\\\\ndf\\\\n.\\\\nitertuples\\\\n():\\\\n.....:\\\\nprint\\\\n(\\\\nrow\\\\n)\\\\n.....:\\\\nPandas(Index=0, a=1, b=\\'a\\')\\\\nPandas(Index=1, a=2, b=\\'b\\')\\\\nPandas(Index=2, a=3, b=\\'c\\')\\\\nThis method does not convert the row to a Series object; it merely\\nreturns the values inside a namedtuple. Therefore,\\\\nitertuples()\\\\npreserves the data type of the values\\nand is generally faster as\\\\niterrows()\\\\n.\\\\nNote\\\\nThe column names will be renamed to positional names if they are\\ninvalid Python identifiers, repeated, or start with an underscore.\\nWith a large number of columns (>255), regular tuples are returned.\\\\n.dt accessor\\\\n#\\\\nSeries\\\\nhas an accessor to succinctly return datetime like properties for the\\\\nvalues\\\\nof the Series, if it is a datetime/period like Series.\\nThis will return a Series, indexed like the existing Series.\\\\n# datetime\\\\nIn [272]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101 09:10:12\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n))\\\\nIn [273]:\\\\ns\\\\nOut[273]:\\\\n0   2013-01-01 09:10:12\\\\n1   2013-01-02 09:10:12\\\\n2   2013-01-03 09:10:12\\\\n3   2013-01-04 09:10:12\\\\ndtype: datetime64[ns]\\\\nIn [274]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nhour\\\\nOut[274]:\\\\n0    9\\\\n1    9\\\\n2    9\\\\n3    9\\\\ndtype: int32\\\\nIn [275]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nsecond\\\\nOut[275]:\\\\n0    12\\\\n1    12\\\\n2    12\\\\n3    12\\\\ndtype: int32\\\\nIn [276]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nday\\\\nOut[276]:\\\\n0    1\\\\n1    2\\\\n2    3\\\\n3    4\\\\ndtype: int32\\\\nThis enables nice expressions like this:\\\\nIn [277]:\\\\ns\\\\n[\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nday\\\\n==\\\\n2\\\\n]\\\\nOut[277]:\\\\n1   2013-01-02 09:10:12\\\\ndtype: datetime64[ns]\\\\nYou can easily produces tz aware transformations:\\\\nIn [278]:\\\\nstz\\\\n=\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ntz_localize\\\\n(\\\\n\"US/Eastern\"\\\\n)\\\\nIn [279]:\\\\nstz\\\\nOut[279]:\\\\n0   2013-01-01 09:10:12-05:00\\\\n1   2013-01-02 09:10:12-05:00\\\\n2   2013-01-03 09:10:12-05:00\\\\n3   2013-01-04 09:10:12-05:00\\\\ndtype: datetime64[ns, US/Eastern]\\\\nIn [280]:\\\\nstz\\\\n.\\\\ndt\\\\n.\\\\ntz\\\\nOut[280]:\\\\n<DstTzInfo \\'US/Eastern\\' LMT-1 day, 19:04:00 STD>\\\\nYou can also chain these types of operations:\\\\nIn [281]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ntz_localize\\\\n(\\\\n\"UTC\"\\\\n)\\\\n.\\\\ndt\\\\n.\\\\ntz_convert\\\\n(\\\\n\"US/Eastern\"\\\\n)\\\\nOut[281]:\\\\n0   2013-01-01 04:10:12-05:00\\\\n1   2013-01-02 04:10:12-05:00\\\\n2   2013-01-03 04:10:12-05:00\\\\n3   2013-01-04 04:10:12-05:00\\\\ndtype: datetime64[ns, US/Eastern]\\\\nYou can also format datetime values as strings with\\\\nSeries.dt.strftime()\\\\nwhich\\nsupports the same format as the standard\\\\nstrftime()\\\\n.\\\\n# DatetimeIndex\\\\nIn [282]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n))\\\\nIn [283]:\\\\ns\\\\nOut[283]:\\\\n0   2013-01-01\\\\n1   2013-01-02\\\\n2   2013-01-03\\\\n3   2013-01-04\\\\ndtype: datetime64[ns]\\\\nIn [284]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nstrftime\\\\n(\\\\n\"%Y/%m/\\\\n%d\\\\n\"\\\\n)\\\\nOut[284]:\\\\n0    2013/01/01\\\\n1    2013/01/02\\\\n2    2013/01/03\\\\n3    2013/01/04\\\\ndtype: object\\\\n# PeriodIndex\\\\nIn [285]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\nperiod_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n))\\\\nIn [286]:\\\\ns\\\\nOut[286]:\\\\n0    2013-01-01\\\\n1    2013-01-02\\\\n2    2013-01-03\\\\n3    2013-01-04\\\\ndtype: period[D]\\\\nIn [287]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nstrftime\\\\n(\\\\n\"%Y/%m/\\\\n%d\\\\n\"\\\\n)\\\\nOut[287]:\\\\n0    2013/01/01\\\\n1    2013/01/02\\\\n2    2013/01/03\\\\n3    2013/01/04\\\\ndtype: object\\\\nThe\\\\n.dt\\\\naccessor works for period and timedelta dtypes.\\\\n# period\\\\nIn [288]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\nperiod_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n,\\\\nfreq\\\\n=\\\\n\"D\"\\\\n))\\\\nIn [289]:\\\\ns\\\\nOut[289]:\\\\n0    2013-01-01\\\\n1    2013-01-02\\\\n2    2013-01-03\\\\n3    2013-01-04\\\\ndtype: period[D]\\\\nIn [290]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nyear\\\\nOut[290]:\\\\n0    2013\\\\n1    2013\\\\n2    2013\\\\n3    2013\\\\ndtype: int64\\\\nIn [291]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nday\\\\nOut[291]:\\\\n0    1\\\\n1    2\\\\n2    3\\\\n3    4\\\\ndtype: int64\\\\n# timedelta\\\\nIn [292]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\npd\\\\n.\\\\ntimedelta_range\\\\n(\\\\n\"1 day 00:00:05\"\\\\n,\\\\nperiods\\\\n=\\\\n4\\\\n,\\\\nfreq\\\\n=\\\\n\"s\"\\\\n))\\\\nIn [293]:\\\\ns\\\\nOut[293]:\\\\n0   1 days 00:00:05\\\\n1   1 days 00:00:06\\\\n2   1 days 00:00:07\\\\n3   1 days 00:00:08\\\\ndtype: timedelta64[ns]\\\\nIn [294]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ndays\\\\nOut[294]:\\\\n0    1\\\\n1    1\\\\n2    1\\\\n3    1\\\\ndtype: int64\\\\nIn [295]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\nseconds\\\\nOut[295]:\\\\n0    5\\\\n1    6\\\\n2    7\\\\n3    8\\\\ndtype: int32\\\\nIn [296]:\\\\ns\\\\n.\\\\ndt\\\\n.\\\\ncomponents\\\\nOut[296]:\\\\ndays  hours  minutes  seconds  milliseconds  microseconds  nanoseconds\\\\n0     1      0        0        5             0             0            0\\\\n1     1      0        0        6             0             0            0\\\\n2     1      0        0        7             0             0            0\\\\n3     1      0        0        8             0             0            0\\\\nNote\\\\nSeries.dt\\\\nwill raise a\\\\nTypeError\\\\nif you access with a non-datetime-like values.\\\\nVectorized string methods\\\\n#\\\\nSeries is equipped with a set of string processing methods that make it easy to\\noperate on each element of the array. Perhaps most importantly, these methods\\nexclude missing/NA values automatically. These are accessed via the Series’s\\\\nstr\\\\nattribute and generally have names matching the equivalent (scalar)\\nbuilt-in string methods. For example:\\\\nIn [297]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\n.....:\\\\n[\\\\n\"A\"\\\\n,\\\\n\"B\"\\\\n,\\\\n\"C\"\\\\n,\\\\n\"Aaba\"\\\\n,\\\\n\"Baca\"\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n\"CABA\"\\\\n,\\\\n\"dog\"\\\\n,\\\\n\"cat\"\\\\n],\\\\ndtype\\\\n=\\\\n\"string\"\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [298]:\\\\ns\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n()\\\\nOut[298]:\\\\n0       a\\\\n1       b\\\\n2       c\\\\n3    aaba\\\\n4    baca\\\\n5    <NA>\\\\n6    caba\\\\n7     dog\\\\n8     cat\\\\ndtype: string\\\\nPowerful pattern-matching methods are provided as well, but note that\\npattern-matching generally uses\\\\nregular expressions\\\\nby default (and in some cases\\nalways uses them).\\\\nNote\\\\nPrior to pandas 1.0, string methods were only available on\\\\nobject\\\\n-dtype\\\\nSeries\\\\n. pandas 1.0 added the\\\\nStringDtype\\\\nwhich is dedicated\\nto strings. See\\\\nText data types\\\\nfor more.\\\\nPlease see\\\\nVectorized String Methods\\\\nfor a complete\\ndescription.\\\\nSorting\\\\n#\\\\npandas supports three kinds of sorting: sorting by index labels,\\nsorting by column values, and sorting by a combination of both.\\\\nBy index\\\\n#\\\\nThe\\\\nSeries.sort_index()\\\\nand\\\\nDataFrame.sort_index()\\\\nmethods are\\nused to sort a pandas object by its index levels.\\\\nIn [299]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"one\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n]),\\\\n.....:\\\\n\"two\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n4\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n.....:\\\\n\"three\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n3\\\\n),\\\\nindex\\\\n=\\\\n[\\\\n\"b\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"d\"\\\\n]),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [300]:\\\\nunsorted_df\\\\n=\\\\ndf\\\\n.\\\\nreindex\\\\n(\\\\n.....:\\\\nindex\\\\n=\\\\n[\\\\n\"a\"\\\\n,\\\\n\"d\"\\\\n,\\\\n\"c\"\\\\n,\\\\n\"b\"\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"three\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"one\"\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [301]:\\\\nunsorted_df\\\\nOut[301]:\\\\nthree       two       one\\\\na       NaN -1.152244  0.562973\\\\nd -0.252916 -0.109597       NaN\\\\nc  1.273388 -0.167123  0.640382\\\\nb -0.098217  0.009797 -1.299504\\\\n# DataFrame\\\\nIn [302]:\\\\nunsorted_df\\\\n.\\\\nsort_index\\\\n()\\\\nOut[302]:\\\\nthree       two       one\\\\na       NaN -1.152244  0.562973\\\\nb -0.098217  0.009797 -1.299504\\\\nc  1.273388 -0.167123  0.640382\\\\nd -0.252916 -0.109597       NaN\\\\nIn [303]:\\\\nunsorted_df\\\\n.\\\\nsort_index\\\\n(\\\\nascending\\\\n=\\\\nFalse\\\\n)\\\\nOut[303]:\\\\nthree       two       one\\\\nd -0.252916 -0.109597       NaN\\\\nc  1.273388 -0.167123  0.640382\\\\nb -0.098217  0.009797 -1.299504\\\\na       NaN -1.152244  0.562973\\\\nIn [304]:\\\\nunsorted_df\\\\n.\\\\nsort_index\\\\n(\\\\naxis\\\\n=\\\\n1\\\\n)\\\\nOut[304]:\\\\none     three       two\\\\na  0.562973       NaN -1.152244\\\\nd       NaN -0.252916 -0.109597\\\\nc  0.640382  1.273388 -0.167123\\\\nb -1.299504 -0.098217  0.009797\\\\n# Series\\\\nIn [305]:\\\\nunsorted_df\\\\n[\\\\n\"three\"\\\\n]\\\\n.\\\\nsort_index\\\\n()\\\\nOut[305]:\\\\na         NaN\\\\nb   -0.098217\\\\nc    1.273388\\\\nd   -0.252916\\\\nName: three, dtype: float64\\\\nSorting by index also supports a\\\\nkey\\\\nparameter that takes a callable\\nfunction to apply to the index being sorted. For\\\\nMultiIndex\\\\nobjects,\\nthe key is applied per-level to the levels specified by\\\\nlevel\\\\n.\\\\nIn [306]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n\"B\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"C\"\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n]})\\\\n.\\\\nset_index\\\\n(\\\\n.....:\\\\nlist\\\\n(\\\\n\"ab\"\\\\n)\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [307]:\\\\ns1\\\\nOut[307]:\\\\nc\\\\na b\\\\nB 1  2\\\\na 2  3\\\\nC 3  4\\\\nIn [308]:\\\\ns1\\\\n.\\\\nsort_index\\\\n(\\\\nlevel\\\\n=\\\\n\"a\"\\\\n)\\\\nOut[308]:\\\\nc\\\\na b\\\\nB 1  2\\\\nC 3  4\\\\na 2  3\\\\nIn [309]:\\\\ns1\\\\n.\\\\nsort_index\\\\n(\\\\nlevel\\\\n=\\\\n\"a\"\\\\n,\\\\nkey\\\\n=\\\\nlambda\\\\nidx\\\\n:\\\\nidx\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n())\\\\nOut[309]:\\\\nc\\\\na b\\\\na 2  3\\\\nB 1  2\\\\nC 3  4\\\\nFor information on key sorting by value, see\\\\nvalue sorting\\\\n.\\\\nBy values\\\\n#\\\\nThe\\\\nSeries.sort_values()\\\\nmethod is used to sort a\\\\nSeries\\\\nby its values. The\\\\nDataFrame.sort_values()\\\\nmethod is used to sort a\\\\nDataFrame\\\\nby its column or row values.\\nThe optional\\\\nby\\\\nparameter to\\\\nDataFrame.sort_values()\\\\nmay used to specify one or more columns\\nto use to determine the sorted order.\\\\nIn [310]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n\"one\"\\\\n:\\\\n[\\\\n2\\\\n,\\\\n1\\\\n,\\\\n1\\\\n,\\\\n1\\\\n],\\\\n\"two\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n3\\\\n,\\\\n2\\\\n,\\\\n4\\\\n],\\\\n\"three\"\\\\n:\\\\n[\\\\n5\\\\n,\\\\n4\\\\n,\\\\n3\\\\n,\\\\n2\\\\n]}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [311]:\\\\ndf1\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"two\"\\\\n)\\\\nOut[311]:\\\\none  two  three\\\\n0    2    1      5\\\\n2    1    2      3\\\\n1    1    3      4\\\\n3    1    4      2\\\\nThe\\\\nby\\\\nparameter can take a list of column names, e.g.:\\\\nIn [312]:\\\\ndf1\\\\n[[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n,\\\\n\"three\"\\\\n]]\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n[\\\\n\"one\"\\\\n,\\\\n\"two\"\\\\n])\\\\nOut[312]:\\\\none  two  three\\\\n2    1    2      3\\\\n1    1    3      4\\\\n3    1    4      2\\\\n0    2    1      5\\\\nThese methods have special treatment of NA values via the\\\\nna_position\\\\nargument:\\\\nIn [313]:\\\\ns\\\\n[\\\\n2\\\\n]\\\\n=\\\\nnp\\\\n.\\\\nnan\\\\nIn [314]:\\\\ns\\\\n.\\\\nsort_values\\\\n()\\\\nOut[314]:\\\\n0       A\\\\n3    Aaba\\\\n1       B\\\\n4    Baca\\\\n6    CABA\\\\n8     cat\\\\n7     dog\\\\n2    <NA>\\\\n5    <NA>\\\\ndtype: string\\\\nIn [315]:\\\\ns\\\\n.\\\\nsort_values\\\\n(\\\\nna_position\\\\n=\\\\n\"first\"\\\\n)\\\\nOut[315]:\\\\n2    <NA>\\\\n5    <NA>\\\\n0       A\\\\n3    Aaba\\\\n1       B\\\\n4    Baca\\\\n6    CABA\\\\n8     cat\\\\n7     dog\\\\ndtype: string\\\\nSorting also supports a\\\\nkey\\\\nparameter that takes a callable function\\nto apply to the values being sorted.\\\\nIn [316]:\\\\ns1\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n\"B\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"C\"\\\\n])\\\\nIn [317]:\\\\ns1\\\\n.\\\\nsort_values\\\\n()\\\\nOut[317]:\\\\n0    B\\\\n2    C\\\\n1    a\\\\ndtype: object\\\\nIn [318]:\\\\ns1\\\\n.\\\\nsort_values\\\\n(\\\\nkey\\\\n=\\\\nlambda\\\\nx\\\\n:\\\\nx\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n())\\\\nOut[318]:\\\\n1    a\\\\n0    B\\\\n2    C\\\\ndtype: object\\\\nkey\\\\nwill be given the\\\\nSeries\\\\nof values and should return a\\\\nSeries\\\\nor array of the same shape with the transformed values. For\\\\nDataFrame\\\\nobjects,\\nthe key is applied per column, so the key should still expect a Series and return\\na Series, e.g.\\\\nIn [319]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n\"B\"\\\\n,\\\\n\"a\"\\\\n,\\\\n\"C\"\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]})\\\\nIn [320]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"a\"\\\\n)\\\\nOut[320]:\\\\na  b\\\\n0  B  1\\\\n2  C  3\\\\n1  a  2\\\\nIn [321]:\\\\ndf\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n\"a\"\\\\n,\\\\nkey\\\\n=\\\\nlambda\\\\ncol\\\\n:\\\\ncol\\\\n.\\\\nstr\\\\n.\\\\nlower\\\\n())\\\\nOut[321]:\\\\na  b\\\\n1  a  2\\\\n0  B  1\\\\n2  C  3\\\\nThe name or type of each column can be used to apply different functions to\\ndifferent columns.\\\\nBy indexes and values\\\\n#\\\\nStrings passed as the\\\\nby\\\\nparameter to\\\\nDataFrame.sort_values()\\\\nmay\\nrefer to either columns or index level names.\\\\n# Build MultiIndex\\\\nIn [322]:\\\\nidx\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_tuples\\\\n(\\\\n.....:\\\\n[(\\\\n\"a\"\\\\n,\\\\n1\\\\n),\\\\n(\\\\n\"a\"\\\\n,\\\\n2\\\\n),\\\\n(\\\\n\"a\"\\\\n,\\\\n2\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n2\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n1\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n1\\\\n)]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [323]:\\\\nidx\\\\n.\\\\nnames\\\\n=\\\\n[\\\\n\"first\"\\\\n,\\\\n\"second\"\\\\n]\\\\n# Build DataFrame\\\\nIn [324]:\\\\ndf_multi\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n6\\\\n,\\\\n0\\\\n,\\\\n-\\\\n1\\\\n)},\\\\nindex\\\\n=\\\\nidx\\\\n)\\\\nIn [325]:\\\\ndf_multi\\\\nOut[325]:\\\\nA\\\\nfirst second\\\\na     1       6\\\\n2       5\\\\n2       4\\\\nb     2       3\\\\n1       2\\\\n1       1\\\\nSort by ‘second’ (index) and ‘A’ (column)\\\\nIn [326]:\\\\ndf_multi\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n[\\\\n\"second\"\\\\n,\\\\n\"A\"\\\\n])\\\\nOut[326]:\\\\nA\\\\nfirst second\\\\nb     1       1\\\\n1       2\\\\na     1       6\\\\nb     2       3\\\\na     2       4\\\\n2       5\\\\nNote\\\\nIf a string matches both a column name and an index level name then a\\nwarning is issued and the column takes precedence. This will result in an\\nambiguity error in a future version.\\\\nsearchsorted\\\\n#\\\\nSeries has the\\\\nsearchsorted()\\\\nmethod, which works similarly to\\\\nnumpy.ndarray.searchsorted()\\\\n.\\\\nIn [327]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n])\\\\nIn [328]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n0\\\\n,\\\\n3\\\\n])\\\\nOut[328]:\\\\narray([0, 2])\\\\nIn [329]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n0\\\\n,\\\\n4\\\\n])\\\\nOut[329]:\\\\narray([0, 3])\\\\nIn [330]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n1\\\\n,\\\\n3\\\\n],\\\\nside\\\\n=\\\\n\"right\"\\\\n)\\\\nOut[330]:\\\\narray([1, 3])\\\\nIn [331]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n1\\\\n,\\\\n3\\\\n],\\\\nside\\\\n=\\\\n\"left\"\\\\n)\\\\nOut[331]:\\\\narray([0, 2])\\\\nIn [332]:\\\\nser\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n3\\\\n,\\\\n1\\\\n,\\\\n2\\\\n])\\\\nIn [333]:\\\\nser\\\\n.\\\\nsearchsorted\\\\n([\\\\n0\\\\n,\\\\n3\\\\n],\\\\nsorter\\\\n=\\\\nnp\\\\n.\\\\nargsort\\\\n(\\\\nser\\\\n))\\\\nOut[333]:\\\\narray([0, 2])\\\\nsmallest / largest values\\\\n#\\\\nSeries\\\\nhas the\\\\nnsmallest()\\\\nand\\\\nnlargest()\\\\nmethods which return the\\nsmallest or largest\\\\n\\\\(n\\\\)\\\\nvalues. For a large\\\\nSeries\\\\nthis can be much\\nfaster than sorting the entire Series and calling\\\\nhead(n)\\\\non the result.\\\\nIn [334]:\\\\ns\\\\n=\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\npermutation\\\\n(\\\\n10\\\\n))\\\\nIn [335]:\\\\ns\\\\nOut[335]:\\\\n0    2\\\\n1    0\\\\n2    3\\\\n3    7\\\\n4    1\\\\n5    5\\\\n6    9\\\\n7    6\\\\n8    8\\\\n9    4\\\\ndtype: int64\\\\nIn [336]:\\\\ns\\\\n.\\\\nsort_values\\\\n()\\\\nOut[336]:\\\\n1    0\\\\n4    1\\\\n0    2\\\\n2    3\\\\n9    4\\\\n5    5\\\\n7    6\\\\n3    7\\\\n8    8\\\\n6    9\\\\ndtype: int64\\\\nIn [337]:\\\\ns\\\\n.\\\\nnsmallest\\\\n(\\\\n3\\\\n)\\\\nOut[337]:\\\\n1    0\\\\n4    1\\\\n0    2\\\\ndtype: int64\\\\nIn [338]:\\\\ns\\\\n.\\\\nnlargest\\\\n(\\\\n3\\\\n)\\\\nOut[338]:\\\\n6    9\\\\n8    8\\\\n3    7\\\\ndtype: int64\\\\nDataFrame\\\\nalso has the\\\\nnlargest\\\\nand\\\\nnsmallest\\\\nmethods.\\\\nIn [339]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"a\"\\\\n:\\\\n[\\\\n-\\\\n2\\\\n,\\\\n-\\\\n1\\\\n,\\\\n1\\\\n,\\\\n10\\\\n,\\\\n8\\\\n,\\\\n11\\\\n,\\\\n-\\\\n1\\\\n],\\\\n.....:\\\\n\"b\"\\\\n:\\\\nlist\\\\n(\\\\n\"abdceff\"\\\\n),\\\\n.....:\\\\n\"c\"\\\\n:\\\\n[\\\\n1.0\\\\n,\\\\n2.0\\\\n,\\\\n4.0\\\\n,\\\\n3.2\\\\n,\\\\nnp\\\\n.\\\\nnan\\\\n,\\\\n3.0\\\\n,\\\\n4.0\\\\n],\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [340]:\\\\ndf\\\\n.\\\\nnlargest\\\\n(\\\\n3\\\\n,\\\\n\"a\"\\\\n)\\\\nOut[340]:\\\\na  b    c\\\\n5  11  f  3.0\\\\n3  10  c  3.2\\\\n4   8  e  NaN\\\\nIn [341]:\\\\ndf\\\\n.\\\\nnlargest\\\\n(\\\\n5\\\\n,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n])\\\\nOut[341]:\\\\na  b    c\\\\n5  11  f  3.0\\\\n3  10  c  3.2\\\\n4   8  e  NaN\\\\n2   1  d  4.0\\\\n6  -1  f  4.0\\\\nIn [342]:\\\\ndf\\\\n.\\\\nnsmallest\\\\n(\\\\n3\\\\n,\\\\n\"a\"\\\\n)\\\\nOut[342]:\\\\na  b    c\\\\n0 -2  a  1.0\\\\n1 -1  b  2.0\\\\n6 -1  f  4.0\\\\nIn [343]:\\\\ndf\\\\n.\\\\nnsmallest\\\\n(\\\\n5\\\\n,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"c\"\\\\n])\\\\nOut[343]:\\\\na  b    c\\\\n0 -2  a  1.0\\\\n1 -1  b  2.0\\\\n6 -1  f  4.0\\\\n2  1  d  4.0\\\\n4  8  e  NaN\\\\nSorting by a MultiIndex column\\\\n#\\\\nYou must be explicit about sorting when the column is a MultiIndex, and fully specify\\nall levels to\\\\nby\\\\n.\\\\nIn [344]:\\\\ndf1\\\\n.\\\\ncolumns\\\\n=\\\\npd\\\\n.\\\\nMultiIndex\\\\n.\\\\nfrom_tuples\\\\n(\\\\n.....:\\\\n[(\\\\n\"a\"\\\\n,\\\\n\"one\"\\\\n),\\\\n(\\\\n\"a\"\\\\n,\\\\n\"two\"\\\\n),\\\\n(\\\\n\"b\"\\\\n,\\\\n\"three\"\\\\n)]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [345]:\\\\ndf1\\\\n.\\\\nsort_values\\\\n(\\\\nby\\\\n=\\\\n(\\\\n\"a\"\\\\n,\\\\n\"two\"\\\\n))\\\\nOut[345]:\\\\na         b\\\\none two three\\\\n0   2   1     5\\\\n2   1   2     3\\\\n1   1   3     4\\\\n3   1   4     2\\\\nCopying\\\\n#\\\\nThe\\\\ncopy()\\\\nmethod on pandas objects copies the underlying data (though not\\nthe axis indexes, since they are immutable) and returns a new object. Note that\\\\nit is seldom necessary to copy objects\\\\n. For example, there are only a\\nhandful of ways to alter a DataFrame\\\\nin-place\\\\n:\\\\nInserting, deleting, or modifying a column.\\\\nAssigning to the\\\\nindex\\\\nor\\\\ncolumns\\\\nattributes.\\\\nFor homogeneous data, directly modifying the values via the\\\\nvalues\\\\nattribute or advanced indexing.\\\\nTo be clear, no pandas method has the side effect of modifying your data;\\nalmost every method returns a new object, leaving the original object\\nuntouched. If the data is modified, it is because you did so explicitly.\\\\ndtypes\\\\n#\\\\nFor the most part, pandas uses NumPy arrays and dtypes for Series or individual\\ncolumns of a DataFrame. NumPy provides support for\\\\nfloat\\\\n,\\\\nint\\\\n,\\\\nbool\\\\n,\\\\ntimedelta64[ns]\\\\nand\\\\ndatetime64[ns]\\\\n(note that NumPy\\ndoes not support timezone-aware datetimes).\\\\npandas and third-party libraries\\\\nextend\\\\nNumPy’s type system in a few places.\\nThis section describes the extensions pandas has made internally.\\nSee\\\\nExtension types\\\\nfor how to write your own extension that\\nworks with pandas. See\\\\nthe ecosystem page\\\\nfor a list of third-party\\nlibraries that have implemented an extension.\\\\nThe following table lists all of pandas extension types. For methods requiring\\\\ndtype\\\\narguments, strings can be specified as indicated. See the respective\\ndocumentation sections for more on each type.\\\\nKind of Data\\\\nData Type\\\\nScalar\\\\nArray\\\\nString Aliases\\\\ntz-aware datetime\\\\nDatetimeTZDtype\\\\nTimestamp\\\\narrays.DatetimeArray\\\\n\\'datetime64[ns,\\\\n<tz>]\\'\\\\nCategorical\\\\nCategoricalDtype\\\\n(none)\\\\nCategorical\\\\n\\'category\\'\\\\nperiod (time spans)\\\\nPeriodDtype\\\\nPeriod\\\\narrays.PeriodArray\\\\n\\'Period[<freq>]\\'\\\\n\\'period[<freq>]\\'\\\\n,\\\\nsparse\\\\nSparseDtype\\\\n(none)\\\\narrays.SparseArray\\\\n\\'Sparse\\'\\\\n,\\\\n\\'Sparse[int]\\'\\\\n,\\\\n\\'Sparse[float]\\'\\\\nintervals\\\\nIntervalDtype\\\\nInterval\\\\narrays.IntervalArray\\\\n\\'interval\\'\\\\n,\\\\n\\'Interval\\'\\\\n,\\\\n\\'Interval[<numpy_dtype>]\\'\\\\n,\\\\n\\'Interval[datetime64[ns,\\\\n<tz>]]\\'\\\\n,\\\\n\\'Interval[timedelta64[<freq>]]\\'\\\\nnullable integer\\\\nInt64Dtype\\\\n, …\\\\n(none)\\\\narrays.IntegerArray\\\\n\\'Int8\\'\\\\n,\\\\n\\'Int16\\'\\\\n,\\\\n\\'Int32\\'\\\\n,\\\\n\\'Int64\\'\\\\n,\\\\n\\'UInt8\\'\\\\n,\\\\n\\'UInt16\\'\\\\n,\\\\n\\'UInt32\\'\\\\n,\\\\n\\'UInt64\\'\\\\nnullable float\\\\nFloat64Dtype\\\\n, …\\\\n(none)\\\\narrays.FloatingArray\\\\n\\'Float32\\'\\\\n,\\\\n\\'Float64\\'\\\\nStrings\\\\nStringDtype\\\\nstr\\\\narrays.StringArray\\\\n\\'string\\'\\\\nBoolean (with NA)\\\\nBooleanDtype\\\\nbool\\\\narrays.BooleanArray\\\\n\\'boolean\\'\\\\npandas has two ways to store strings.\\\\nobject\\\\ndtype, which can hold any Python object, including strings.\\\\nStringDtype\\\\n, which is dedicated to strings.\\\\nGenerally, we recommend using\\\\nStringDtype\\\\n. See\\\\nText data types\\\\nfor more.\\\\nFinally, arbitrary objects may be stored using the\\\\nobject\\\\ndtype, but should\\nbe avoided to the extent possible (for performance and interoperability with\\nother libraries and methods. See\\\\nobject conversion\\\\n).\\\\nA convenient\\\\ndtypes\\\\nattribute for DataFrame returns a Series\\nwith the data type of each column.\\\\nIn [346]:\\\\ndft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrand\\\\n(\\\\n3\\\\n),\\\\n.....:\\\\n\"B\"\\\\n:\\\\n1\\\\n,\\\\n.....:\\\\n\"C\"\\\\n:\\\\n\"foo\"\\\\n,\\\\n.....:\\\\n\"D\"\\\\n:\\\\npd\\\\n.\\\\nTimestamp\\\\n(\\\\n\"20010102\"\\\\n),\\\\n.....:\\\\n\"E\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1.0\\\\n]\\\\n*\\\\n3\\\\n)\\\\n.\\\\nastype\\\\n(\\\\n\"float32\"\\\\n),\\\\n.....:\\\\n\"F\"\\\\n:\\\\nFalse\\\\n,\\\\n.....:\\\\n\"G\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n]\\\\n*\\\\n3\\\\n,\\\\ndtype\\\\n=\\\\n\"int8\"\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [347]:\\\\ndft\\\\nOut[347]:\\\\nA  B    C          D    E      F  G\\\\n0  0.035962  1  foo 2001-01-02  1.0  False  1\\\\n1  0.701379  1  foo 2001-01-02  1.0  False  1\\\\n2  0.281885  1  foo 2001-01-02  1.0  False  1\\\\nIn [348]:\\\\ndft\\\\n.\\\\ndtypes\\\\nOut[348]:\\\\nA          float64\\\\nB            int64\\\\nC           object\\\\nD    datetime64[s]\\\\nE          float32\\\\nF             bool\\\\nG             int8\\\\ndtype: object\\\\nOn a\\\\nSeries\\\\nobject, use the\\\\ndtype\\\\nattribute.\\\\nIn [349]:\\\\ndft\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\ndtype\\\\nOut[349]:\\\\ndtype(\\'float64\\')\\\\nIf a pandas object contains data with multiple dtypes\\\\nin a single column\\\\n, the\\ndtype of the column will be chosen to accommodate all of the data types\\n(\\\\nobject\\\\nis the most general).\\\\n# these ints are coerced to floats\\\\nIn [350]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6.0\\\\n])\\\\nOut[350]:\\\\n0    1.0\\\\n1    2.0\\\\n2    3.0\\\\n3    4.0\\\\n4    5.0\\\\n5    6.0\\\\ndtype: float64\\\\n# string data forces an ``object`` dtype\\\\nIn [351]:\\\\npd\\\\n.\\\\nSeries\\\\n([\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n,\\\\n6.0\\\\n,\\\\n\"foo\"\\\\n])\\\\nOut[351]:\\\\n0      1\\\\n1      2\\\\n2      3\\\\n3    6.0\\\\n4    foo\\\\ndtype: object\\\\nThe number of columns of each type in a\\\\nDataFrame\\\\ncan be found by calling\\\\nDataFrame.dtypes.value_counts()\\\\n.\\\\nIn [352]:\\\\ndft\\\\n.\\\\ndtypes\\\\n.\\\\nvalue_counts\\\\n()\\\\nOut[352]:\\\\nfloat64          1\\\\nint64            1\\\\nobject           1\\\\ndatetime64[s]    1\\\\nfloat32          1\\\\nbool             1\\\\nint8             1\\\\nName: count, dtype: int64\\\\nNumeric dtypes will propagate and can coexist in DataFrames.\\nIf a dtype is passed (either directly via the\\\\ndtype\\\\nkeyword, a passed\\\\nndarray\\\\n,\\nor a passed\\\\nSeries\\\\n), then it will be preserved in DataFrame operations. Furthermore,\\ndifferent numeric dtypes will\\\\nNOT\\\\nbe combined. The following example will give you a taste.\\\\nIn [353]:\\\\ndf1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n,\\\\n1\\\\n),\\\\ncolumns\\\\n=\\\\n[\\\\n\"A\"\\\\n],\\\\ndtype\\\\n=\\\\n\"float32\"\\\\n)\\\\nIn [354]:\\\\ndf1\\\\nOut[354]:\\\\nA\\\\n0  0.224364\\\\n1  1.890546\\\\n2  0.182879\\\\n3  0.787847\\\\n4 -0.188449\\\\n5  0.667715\\\\n6 -0.011736\\\\n7 -0.399073\\\\nIn [355]:\\\\ndf1\\\\n.\\\\ndtypes\\\\nOut[355]:\\\\nA    float32\\\\ndtype: object\\\\nIn [356]:\\\\ndf2\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"A\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n),\\\\ndtype\\\\n=\\\\n\"float16\"\\\\n),\\\\n.....:\\\\n\"B\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandn\\\\n(\\\\n8\\\\n)),\\\\n.....:\\\\n\"C\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nnp\\\\n.\\\\nrandom\\\\n.\\\\nrandint\\\\n(\\\\n0\\\\n,\\\\n255\\\\n,\\\\nsize\\\\n=\\\\n8\\\\n),\\\\ndtype\\\\n=\\\\n\"uint8\"\\\\n),\\\\n# [0,255] (range of uint8)\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [357]:\\\\ndf2\\\\nOut[357]:\\\\nA         B    C\\\\n0  0.823242  0.256090   26\\\\n1  1.607422  1.426469   86\\\\n2 -0.333740 -0.416203   46\\\\n3 -0.063477  1.139976  212\\\\n4 -1.014648 -1.193477   26\\\\n5  0.678711  0.096706    7\\\\n6 -0.040863 -1.956850  184\\\\n7 -0.357422 -0.714337  206\\\\nIn [358]:\\\\ndf2\\\\n.\\\\ndtypes\\\\nOut[358]:\\\\nA    float16\\\\nB    float64\\\\nC      uint8\\\\ndtype: object\\\\ndefaults\\\\n#\\\\nBy default integer types are\\\\nint64\\\\nand float types are\\\\nfloat64\\\\n,\\\\nregardless\\\\nof platform (32-bit or 64-bit).\\nThe following will all result in\\\\nint64\\\\ndtypes.\\\\nIn [359]:\\\\npd\\\\n.\\\\nDataFrame\\\\n([\\\\n1\\\\n,\\\\n2\\\\n],\\\\ncolumns\\\\n=\\\\n[\\\\n\"a\"\\\\n])\\\\n.\\\\ndtypes\\\\nOut[359]:\\\\na    int64\\\\ndtype: object\\\\nIn [360]:\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n]})\\\\n.\\\\ndtypes\\\\nOut[360]:\\\\na    int64\\\\ndtype: object\\\\nIn [361]:\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n1\\\\n},\\\\nindex\\\\n=\\\\nlist\\\\n(\\\\nrange\\\\n(\\\\n2\\\\n)))\\\\n.\\\\ndtypes\\\\nOut[361]:\\\\na    int64\\\\ndtype: object\\\\nNote that Numpy will choose\\\\nplatform-dependent\\\\ntypes when creating arrays.\\nThe following\\\\nWILL\\\\nresult in\\\\nint32\\\\non 32-bit platform.\\\\nIn [362]:\\\\nframe\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\nnp\\\\n.\\\\narray\\\\n([\\\\n1\\\\n,\\\\n2\\\\n]))\\\\nupcasting\\\\n#\\\\nTypes can potentially be\\\\nupcasted\\\\nwhen combined with other types, meaning they are promoted\\nfrom the current type (e.g.\\\\nint\\\\nto\\\\nfloat\\\\n).\\\\nIn [363]:\\\\ndf3\\\\n=\\\\ndf1\\\\n.\\\\nreindex_like\\\\n(\\\\ndf2\\\\n)\\\\n.\\\\nfillna\\\\n(\\\\nvalue\\\\n=\\\\n0.0\\\\n)\\\\n+\\\\ndf2\\\\nIn [364]:\\\\ndf3\\\\nOut[364]:\\\\nA         B      C\\\\n0  1.047606  0.256090   26.0\\\\n1  3.497968  1.426469   86.0\\\\n2 -0.150862 -0.416203   46.0\\\\n3  0.724370  1.139976  212.0\\\\n4 -1.203098 -1.193477   26.0\\\\n5  1.346426  0.096706    7.0\\\\n6 -0.052599 -1.956850  184.0\\\\n7 -0.756495 -0.714337  206.0\\\\nIn [365]:\\\\ndf3\\\\n.\\\\ndtypes\\\\nOut[365]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\nDataFrame.to_numpy()\\\\nwill return the\\\\nlower-common-denominator\\\\nof the dtypes, meaning\\nthe dtype that can accommodate\\\\nALL\\\\nof the types in the resulting homogeneous dtyped NumPy array. This can\\nforce some\\\\nupcasting\\\\n.\\\\nIn [366]:\\\\ndf3\\\\n.\\\\nto_numpy\\\\n()\\\\n.\\\\ndtype\\\\nOut[366]:\\\\ndtype(\\'float64\\')\\\\nastype\\\\n#\\\\nYou can use the\\\\nastype()\\\\nmethod to explicitly convert dtypes from one to another. These will by default return a copy,\\neven if the dtype was unchanged (pass\\\\ncopy=False\\\\nto change this behavior). In addition, they will raise an\\nexception if the astype operation is invalid.\\\\nUpcasting is always according to the\\\\nNumPy\\\\nrules. If two different dtypes are involved in an operation,\\nthen the more\\\\ngeneral\\\\none will be used as the result of the operation.\\\\nIn [367]:\\\\ndf3\\\\nOut[367]:\\\\nA         B      C\\\\n0  1.047606  0.256090   26.0\\\\n1  3.497968  1.426469   86.0\\\\n2 -0.150862 -0.416203   46.0\\\\n3  0.724370  1.139976  212.0\\\\n4 -1.203098 -1.193477   26.0\\\\n5  1.346426  0.096706    7.0\\\\n6 -0.052599 -1.956850  184.0\\\\n7 -0.756495 -0.714337  206.0\\\\nIn [368]:\\\\ndf3\\\\n.\\\\ndtypes\\\\nOut[368]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\n# conversion of dtypes\\\\nIn [369]:\\\\ndf3\\\\n.\\\\nastype\\\\n(\\\\n\"float32\"\\\\n)\\\\n.\\\\ndtypes\\\\nOut[369]:\\\\nA    float32\\\\nB    float32\\\\nC    float32\\\\ndtype: object\\\\nConvert a subset of columns to a specified type using\\\\nastype()\\\\n.\\\\nIn [370]:\\\\ndft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n7\\\\n,\\\\n8\\\\n,\\\\n9\\\\n]})\\\\nIn [371]:\\\\ndft\\\\n[[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n=\\\\ndft\\\\n[[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n.\\\\nastype\\\\n(\\\\nnp\\\\n.\\\\nuint8\\\\n)\\\\nIn [372]:\\\\ndft\\\\nOut[372]:\\\\na  b  c\\\\n0  1  4  7\\\\n1  2  5  8\\\\n2  3  6  9\\\\nIn [373]:\\\\ndft\\\\n.\\\\ndtypes\\\\nOut[373]:\\\\na    uint8\\\\nb    uint8\\\\nc    int64\\\\ndtype: object\\\\nConvert certain columns to a specific dtype by passing a dict to\\\\nastype()\\\\n.\\\\nIn [374]:\\\\ndft1\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n0\\\\n,\\\\n1\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n7\\\\n,\\\\n8\\\\n,\\\\n9\\\\n]})\\\\nIn [375]:\\\\ndft1\\\\n=\\\\ndft1\\\\n.\\\\nastype\\\\n({\\\\n\"a\"\\\\n:\\\\nnp\\\\n.\\\\nbool_\\\\n,\\\\n\"c\"\\\\n:\\\\nnp\\\\n.\\\\nfloat64\\\\n})\\\\nIn [376]:\\\\ndft1\\\\nOut[376]:\\\\na  b    c\\\\n0   True  4  7.0\\\\n1  False  5  8.0\\\\n2   True  6  9.0\\\\nIn [377]:\\\\ndft1\\\\n.\\\\ndtypes\\\\nOut[377]:\\\\na       bool\\\\nb      int64\\\\nc    float64\\\\ndtype: object\\\\nNote\\\\nWhen trying to convert a subset of columns to a specified type using\\\\nastype()\\\\nand\\\\nloc()\\\\n, upcasting occurs.\\\\nloc()\\\\ntries to fit in what we are assigning to the current dtypes, while\\\\n[]\\\\nwill overwrite them taking the dtype from the right hand side. Therefore the following piece of code produces the unintended result.\\\\nIn [378]:\\\\ndft\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n({\\\\n\"a\"\\\\n:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n,\\\\n3\\\\n],\\\\n\"b\"\\\\n:\\\\n[\\\\n4\\\\n,\\\\n5\\\\n,\\\\n6\\\\n],\\\\n\"c\"\\\\n:\\\\n[\\\\n7\\\\n,\\\\n8\\\\n,\\\\n9\\\\n]})\\\\nIn [379]:\\\\ndft\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n.\\\\nastype\\\\n(\\\\nnp\\\\n.\\\\nuint8\\\\n)\\\\n.\\\\ndtypes\\\\nOut[379]:\\\\na    uint8\\\\nb    uint8\\\\ndtype: object\\\\nIn [380]:\\\\ndft\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n=\\\\ndft\\\\n.\\\\nloc\\\\n[:,\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n]]\\\\n.\\\\nastype\\\\n(\\\\nnp\\\\n.\\\\nuint8\\\\n)\\\\nIn [381]:\\\\ndft\\\\n.\\\\ndtypes\\\\nOut[381]:\\\\na    int64\\\\nb    int64\\\\nc    int64\\\\ndtype: object\\\\nobject conversion\\\\n#\\\\npandas offers various functions to try to force conversion of types from the\\\\nobject\\\\ndtype to other types.\\nIn cases where the data is already of the correct type, but stored in an\\\\nobject\\\\narray, the\\\\nDataFrame.infer_objects()\\\\nand\\\\nSeries.infer_objects()\\\\nmethods can be used to soft convert\\nto the correct type.\\\\nIn [382]:\\\\nimport\\\\ndatetime\\\\nIn [383]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n[\\\\n.....:\\\\n[\\\\n1\\\\n,\\\\n2\\\\n],\\\\n.....:\\\\n[\\\\n\"a\"\\\\n,\\\\n\"b\"\\\\n],\\\\n.....:\\\\n[\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n),\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)],\\\\n.....:\\\\n]\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [384]:\\\\ndf\\\\n=\\\\ndf\\\\n.\\\\nT\\\\nIn [385]:\\\\ndf\\\\nOut[385]:\\\\n0  1                    2\\\\n0  1  a  2016-03-02 00:00:00\\\\n1  2  b  2016-03-02 00:00:00\\\\nIn [386]:\\\\ndf\\\\n.\\\\ndtypes\\\\nOut[386]:\\\\n0    object\\\\n1    object\\\\n2    object\\\\ndtype: object\\\\nBecause the data was transposed the original inference stored all columns as object, which\\\\ninfer_objects\\\\nwill correct.\\\\nIn [387]:\\\\ndf\\\\n.\\\\ninfer_objects\\\\n()\\\\n.\\\\ndtypes\\\\nOut[387]:\\\\n0             int64\\\\n1            object\\\\n2    datetime64[ns]\\\\ndtype: object\\\\nThe following functions are available for one dimensional object arrays or scalars to perform\\nhard conversion of objects to a specified type:\\\\nto_numeric()\\\\n(conversion to numeric dtypes)\\\\nIn [388]:\\\\nm\\\\n=\\\\n[\\\\n\"1.1\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]\\\\nIn [389]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n)\\\\nOut[389]:\\\\narray([1.1, 2. , 3. ])\\\\nto_datetime()\\\\n(conversion to datetime objects)\\\\nIn [390]:\\\\nimport\\\\ndatetime\\\\nIn [391]:\\\\nm\\\\n=\\\\n[\\\\n\"2016-07-09\"\\\\n,\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)]\\\\nIn [392]:\\\\npd\\\\n.\\\\nto_datetime\\\\n(\\\\nm\\\\n)\\\\nOut[392]:\\\\nDatetimeIndex([\\'2016-07-09\\', \\'2016-03-02\\'], dtype=\\'datetime64[ns]\\', freq=None)\\\\nto_timedelta()\\\\n(conversion to timedelta objects)\\\\nIn [393]:\\\\nm\\\\n=\\\\n[\\\\n\"5us\"\\\\n,\\\\npd\\\\n.\\\\nTimedelta\\\\n(\\\\n\"1day\"\\\\n)]\\\\nIn [394]:\\\\npd\\\\n.\\\\nto_timedelta\\\\n(\\\\nm\\\\n)\\\\nOut[394]:\\\\nTimedeltaIndex([\\'0 days 00:00:00.000005\\', \\'1 days 00:00:00\\'], dtype=\\'timedelta64[ns]\\', freq=None)\\\\nTo force a conversion, we can pass in an\\\\nerrors\\\\nargument, which specifies how pandas should deal with elements\\nthat cannot be converted to desired dtype or object. By default,\\\\nerrors=\\'raise\\'\\\\n, meaning that any errors encountered\\nwill be raised during the conversion process. However, if\\\\nerrors=\\'coerce\\'\\\\n, these errors will be ignored and pandas\\nwill convert problematic elements to\\\\npd.NaT\\\\n(for datetime and timedelta) or\\\\nnp.nan\\\\n(for numeric). This might be\\nuseful if you are reading in data which is mostly of the desired dtype (e.g. numeric, datetime), but occasionally has\\nnon-conforming elements intermixed that you want to represent as missing:\\\\nIn [395]:\\\\nimport\\\\ndatetime\\\\nIn [396]:\\\\nm\\\\n=\\\\n[\\\\n\"apple\"\\\\n,\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)]\\\\nIn [397]:\\\\npd\\\\n.\\\\nto_datetime\\\\n(\\\\nm\\\\n,\\\\nerrors\\\\n=\\\\n\"coerce\"\\\\n)\\\\nOut[397]:\\\\nDatetimeIndex([\\'NaT\\', \\'2016-03-02\\'], dtype=\\'datetime64[ns]\\', freq=None)\\\\nIn [398]:\\\\nm\\\\n=\\\\n[\\\\n\"apple\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]\\\\nIn [399]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\nerrors\\\\n=\\\\n\"coerce\"\\\\n)\\\\nOut[399]:\\\\narray([nan,  2.,  3.])\\\\nIn [400]:\\\\nm\\\\n=\\\\n[\\\\n\"apple\"\\\\n,\\\\npd\\\\n.\\\\nTimedelta\\\\n(\\\\n\"1day\"\\\\n)]\\\\nIn [401]:\\\\npd\\\\n.\\\\nto_timedelta\\\\n(\\\\nm\\\\n,\\\\nerrors\\\\n=\\\\n\"coerce\"\\\\n)\\\\nOut[401]:\\\\nTimedeltaIndex([NaT, \\'1 days\\'], dtype=\\'timedelta64[ns]\\', freq=None)\\\\nIn addition to object conversion,\\\\nto_numeric()\\\\nprovides another argument\\\\ndowncast\\\\n, which gives the\\noption of downcasting the newly (or already) numeric data to a smaller dtype, which can conserve memory:\\\\nIn [402]:\\\\nm\\\\n=\\\\n[\\\\n\"1\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]\\\\nIn [403]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"integer\"\\\\n)\\\\n# smallest signed int dtype\\\\nOut[403]:\\\\narray([1, 2, 3], dtype=int8)\\\\nIn [404]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"signed\"\\\\n)\\\\n# same as \\'integer\\'\\\\nOut[404]:\\\\narray([1, 2, 3], dtype=int8)\\\\nIn [405]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"unsigned\"\\\\n)\\\\n# smallest unsigned int dtype\\\\nOut[405]:\\\\narray([1, 2, 3], dtype=uint8)\\\\nIn [406]:\\\\npd\\\\n.\\\\nto_numeric\\\\n(\\\\nm\\\\n,\\\\ndowncast\\\\n=\\\\n\"float\"\\\\n)\\\\n# smallest float dtype\\\\nOut[406]:\\\\narray([1., 2., 3.], dtype=float32)\\\\nAs these methods apply only to one-dimensional arrays, lists or scalars; they cannot be used directly on multi-dimensional objects such\\nas DataFrames. However, with\\\\napply()\\\\n, we can “apply” the function over each column efficiently:\\\\nIn [407]:\\\\nimport\\\\ndatetime\\\\nIn [408]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n\"2016-07-09\"\\\\n,\\\\ndatetime\\\\n.\\\\ndatetime\\\\n(\\\\n2016\\\\n,\\\\n3\\\\n,\\\\n2\\\\n)]]\\\\n*\\\\n2\\\\n,\\\\ndtype\\\\n=\\\\n\"O\"\\\\n)\\\\nIn [409]:\\\\ndf\\\\nOut[409]:\\\\n0                    1\\\\n0  2016-07-09  2016-03-02 00:00:00\\\\n1  2016-07-09  2016-03-02 00:00:00\\\\nIn [410]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nto_datetime\\\\n)\\\\nOut[410]:\\\\n0          1\\\\n0 2016-07-09 2016-03-02\\\\n1 2016-07-09 2016-03-02\\\\nIn [411]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n\"1.1\"\\\\n,\\\\n2\\\\n,\\\\n3\\\\n]]\\\\n*\\\\n2\\\\n,\\\\ndtype\\\\n=\\\\n\"O\"\\\\n)\\\\nIn [412]:\\\\ndf\\\\nOut[412]:\\\\n0  1  2\\\\n0  1.1  2  3\\\\n1  1.1  2  3\\\\nIn [413]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nto_numeric\\\\n)\\\\nOut[413]:\\\\n0  1  2\\\\n0  1.1  2  3\\\\n1  1.1  2  3\\\\nIn [414]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n([[\\\\n\"5us\"\\\\n,\\\\npd\\\\n.\\\\nTimedelta\\\\n(\\\\n\"1day\"\\\\n)]]\\\\n*\\\\n2\\\\n,\\\\ndtype\\\\n=\\\\n\"O\"\\\\n)\\\\nIn [415]:\\\\ndf\\\\nOut[415]:\\\\n0                1\\\\n0  5us  1 days 00:00:00\\\\n1  5us  1 days 00:00:00\\\\nIn [416]:\\\\ndf\\\\n.\\\\napply\\\\n(\\\\npd\\\\n.\\\\nto_timedelta\\\\n)\\\\nOut[416]:\\\\n0      1\\\\n0 0 days 00:00:00.000005 1 days\\\\n1 0 days 00:00:00.000005 1 days\\\\ngotchas\\\\n#\\\\nPerforming selection operations on\\\\ninteger\\\\ntype data can easily upcast the data to\\\\nfloating\\\\n.\\nThe dtype of the input data will be preserved in cases where\\\\nnans\\\\nare not introduced.\\nSee also\\\\nSupport for integer NA\\\\n.\\\\nIn [417]:\\\\ndfi\\\\n=\\\\ndf3\\\\n.\\\\nastype\\\\n(\\\\n\"int32\"\\\\n)\\\\nIn [418]:\\\\ndfi\\\\n[\\\\n\"E\"\\\\n]\\\\n=\\\\n1\\\\nIn [419]:\\\\ndfi\\\\nOut[419]:\\\\nA  B    C  E\\\\n0  1  0   26  1\\\\n1  3  1   86  1\\\\n2  0  0   46  1\\\\n3  0  1  212  1\\\\n4 -1 -1   26  1\\\\n5  1  0    7  1\\\\n6  0 -1  184  1\\\\n7  0  0  206  1\\\\nIn [420]:\\\\ndfi\\\\n.\\\\ndtypes\\\\nOut[420]:\\\\nA    int32\\\\nB    int32\\\\nC    int32\\\\nE    int64\\\\ndtype: object\\\\nIn [421]:\\\\ncasted\\\\n=\\\\ndfi\\\\n[\\\\ndfi\\\\n>\\\\n0\\\\n]\\\\nIn [422]:\\\\ncasted\\\\nOut[422]:\\\\nA    B    C  E\\\\n0  1.0  NaN   26  1\\\\n1  3.0  1.0   86  1\\\\n2  NaN  NaN   46  1\\\\n3  NaN  1.0  212  1\\\\n4  NaN  NaN   26  1\\\\n5  1.0  NaN    7  1\\\\n6  NaN  NaN  184  1\\\\n7  NaN  NaN  206  1\\\\nIn [423]:\\\\ncasted\\\\n.\\\\ndtypes\\\\nOut[423]:\\\\nA    float64\\\\nB    float64\\\\nC      int32\\\\nE      int64\\\\ndtype: object\\\\nWhile float dtypes are unchanged.\\\\nIn [424]:\\\\ndfa\\\\n=\\\\ndf3\\\\n.\\\\ncopy\\\\n()\\\\nIn [425]:\\\\ndfa\\\\n[\\\\n\"A\"\\\\n]\\\\n=\\\\ndfa\\\\n[\\\\n\"A\"\\\\n]\\\\n.\\\\nastype\\\\n(\\\\n\"float32\"\\\\n)\\\\nIn [426]:\\\\ndfa\\\\n.\\\\ndtypes\\\\nOut[426]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\nIn [427]:\\\\ncasted\\\\n=\\\\ndfa\\\\n[\\\\ndf2\\\\n>\\\\n0\\\\n]\\\\nIn [428]:\\\\ncasted\\\\nOut[428]:\\\\nA         B      C\\\\n0  1.047606  0.256090   26.0\\\\n1  3.497968  1.426469   86.0\\\\n2       NaN       NaN   46.0\\\\n3       NaN  1.139976  212.0\\\\n4       NaN       NaN   26.0\\\\n5  1.346426  0.096706    7.0\\\\n6       NaN       NaN  184.0\\\\n7       NaN       NaN  206.0\\\\nIn [429]:\\\\ncasted\\\\n.\\\\ndtypes\\\\nOut[429]:\\\\nA    float32\\\\nB    float64\\\\nC    float64\\\\ndtype: object\\\\nSelecting columns based on\\\\ndtype\\\\n#\\\\nThe\\\\nselect_dtypes()\\\\nmethod implements subsetting of columns\\nbased on their\\\\ndtype\\\\n.\\\\nFirst, let’s create a\\\\nDataFrame\\\\nwith a slew of different\\ndtypes:\\\\nIn [430]:\\\\ndf\\\\n=\\\\npd\\\\n.\\\\nDataFrame\\\\n(\\\\n.....:\\\\n{\\\\n.....:\\\\n\"string\"\\\\n:\\\\nlist\\\\n(\\\\n\"abc\"\\\\n),\\\\n.....:\\\\n\"int64\"\\\\n:\\\\nlist\\\\n(\\\\nrange\\\\n(\\\\n1\\\\n,\\\\n4\\\\n)),\\\\n.....:\\\\n\"uint8\"\\\\n:\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n3\\\\n,\\\\n6\\\\n)\\\\n.\\\\nastype\\\\n(\\\\n\"u1\"\\\\n),\\\\n.....:\\\\n\"float64\"\\\\n:\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n4.0\\\\n,\\\\n7.0\\\\n),\\\\n.....:\\\\n\"bool1\"\\\\n:\\\\n[\\\\nTrue\\\\n,\\\\nFalse\\\\n,\\\\nTrue\\\\n],\\\\n.....:\\\\n\"bool2\"\\\\n:\\\\n[\\\\nFalse\\\\n,\\\\nTrue\\\\n,\\\\nFalse\\\\n],\\\\n.....:\\\\n\"dates\"\\\\n:\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"now\"\\\\n,\\\\nperiods\\\\n=\\\\n3\\\\n),\\\\n.....:\\\\n\"category\"\\\\n:\\\\npd\\\\n.\\\\nSeries\\\\n(\\\\nlist\\\\n(\\\\n\"ABC\"\\\\n))\\\\n.\\\\nastype\\\\n(\\\\n\"category\"\\\\n),\\\\n.....:\\\\n}\\\\n.....:\\\\n)\\\\n.....:\\\\nIn [431]:\\\\ndf\\\\n[\\\\n\"tdeltas\"\\\\n]\\\\n=\\\\ndf\\\\n.\\\\ndates\\\\n.\\\\ndiff\\\\n()\\\\nIn [432]:\\\\ndf\\\\n[\\\\n\"uint64\"\\\\n]\\\\n=\\\\nnp\\\\n.\\\\narange\\\\n(\\\\n3\\\\n,\\\\n6\\\\n)\\\\n.\\\\nastype\\\\n(\\\\n\"u8\"\\\\n)\\\\nIn [433]:\\\\ndf\\\\n[\\\\n\"other_dates\"\\\\n]\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n3\\\\n)\\\\nIn [434]:\\\\ndf\\\\n[\\\\n\"tz_aware_dates\"\\\\n]\\\\n=\\\\npd\\\\n.\\\\ndate_range\\\\n(\\\\n\"20130101\"\\\\n,\\\\nperiods\\\\n=\\\\n3\\\\n,\\\\ntz\\\\n=\\\\n\"US/Eastern\"\\\\n)\\\\nIn [435]:\\\\ndf\\\\nOut[435]:\\\\nstring  int64  uint8  ...  uint64  other_dates            tz_aware_dates\\\\n0      a      1      3  ...       3   2013-01-01 2013-01-01 00:00:00-05:00\\\\n1      b      2      4  ...       4   2013-01-02 2013-01-02 00:00:00-05:00\\\\n2      c      3      5  ...       5   2013-01-03 2013-01-03 00:00:00-05:00\\\\n[3 rows x 12 columns]\\\\nAnd the dtypes:\\\\nIn [436]:\\\\ndf\\\\n.\\\\ndtypes\\\\nOut[436]:\\\\nstring                                object\\\\nint64                                  int64\\\\nuint8                                  uint8\\\\nfloat64                              float64\\\\nbool1                                   bool\\\\nbool2                                   bool\\\\ndates                         datetime64[ns]\\\\ncategory                            category\\\\ntdeltas                      timedelta64[ns]\\\\nuint64                                uint64\\\\nother_dates                   datetime64[ns]\\\\ntz_aware_dates    datetime64[ns, US/Eastern]\\\\ndtype: object\\\\nselect_dtypes()\\\\nhas two parameters\\\\ninclude\\\\nand\\\\nexclude\\\\nthat allow you to\\nsay “give me the columns\\\\nwith\\\\nthese dtypes” (\\\\ninclude\\\\n) and/or “give the\\ncolumns\\\\nwithout\\\\nthese dtypes” (\\\\nexclude\\\\n).\\\\nFor example, to select\\\\nbool\\\\ncolumns:\\\\nIn [437]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\nbool\\\\n])\\\\nOut[437]:\\\\nbool1  bool2\\\\n0   True  False\\\\n1  False   True\\\\n2   True  False\\\\nYou can also pass the name of a dtype in the\\\\nNumPy dtype hierarchy\\\\n:\\\\nIn [438]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"bool\"\\\\n])\\\\nOut[438]:\\\\nbool1  bool2\\\\n0   True  False\\\\n1  False   True\\\\n2   True  False\\\\nselect_dtypes()\\\\nalso works with generic dtypes as well.\\\\nFor example, to select all numeric and boolean columns while excluding unsigned\\nintegers:\\\\nIn [439]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"number\"\\\\n,\\\\n\"bool\"\\\\n],\\\\nexclude\\\\n=\\\\n[\\\\n\"unsignedinteger\"\\\\n])\\\\nOut[439]:\\\\nint64  float64  bool1  bool2 tdeltas\\\\n0      1      4.0   True  False     NaT\\\\n1      2      5.0  False   True  1 days\\\\n2      3      6.0   True  False  1 days\\\\nTo select string columns you must use the\\\\nobject\\\\ndtype:\\\\nIn [440]:\\\\ndf\\\\n.\\\\nselect_dtypes\\\\n(\\\\ninclude\\\\n=\\\\n[\\\\n\"object\"\\\\n])\\\\nOut[440]:\\\\nstring\\\\n0      a\\\\n1      b\\\\n2      c\\\\nTo see all the child dtypes of a generic\\\\ndtype\\\\nlike\\\\nnumpy.number\\\\nyou\\ncan define a function that returns a tree of child dtypes:\\\\nIn [441]:\\\\ndef\\\\nsubdtypes\\\\n(\\\\ndtype\\\\n):\\\\n.....:\\\\nsubs\\\\n=\\\\ndtype\\\\n.\\\\n__subclasses__\\\\n()\\\\n.....:\\\\nif\\\\nnot\\\\nsubs\\\\n:\\\\n.....:\\\\nreturn\\\\ndtype\\\\n.....:\\\\nreturn\\\\n[\\\\ndtype\\\\n,\\\\n[\\\\nsubdtypes\\\\n(\\\\ndt\\\\n)\\\\nfor\\\\ndt\\\\nin\\\\nsubs\\\\n]]\\\\n.....:\\\\nAll NumPy dtypes are subclasses of\\\\nnumpy.generic\\\\n:\\\\nIn [442]:\\\\nsubdtypes\\\\n(\\\\nnp\\\\n.\\\\ngeneric\\\\n)\\\\nOut[442]:\\\\n[numpy.generic,\\\\n[[numpy.number,\\\\n[[numpy.integer,\\\\n[[numpy.signedinteger,\\\\n[numpy.int8,\\\\nnumpy.int16,\\\\nnumpy.int32,\\\\nnumpy.int64,\\\\nnumpy.longlong,\\\\nnumpy.timedelta64]],\\\\n[numpy.unsignedinteger,\\\\n[numpy.uint8,\\\\nnumpy.uint16,\\\\nnumpy.uint32,\\\\nnumpy.uint64,\\\\nnumpy.ulonglong]]]],\\\\n[numpy.inexact,\\\\n[[numpy.floating,\\\\n[numpy.float16, numpy.float32, numpy.float64, numpy.longdouble]],\\\\n[numpy.complexfloating,\\\\n[numpy.complex64, numpy.complex128, numpy.clongdouble]]]]]],\\\\n[numpy.flexible,\\\\n[[numpy.character, [numpy.bytes_, numpy.str_]],\\\\n[numpy.void, [numpy.record]]]],\\\\nnumpy.bool_,\\\\nnumpy.datetime64,\\\\nnumpy.object_]]\\\\nNote\\\\npandas also defines the types\\\\ncategory\\\\n, and\\\\ndatetime64[ns,\\\\ntz]\\\\n, which are not integrated into the normal\\nNumPy hierarchy and won’t show up with the above function.\\\\nprevious\\\\nIntro to data structures\\\\nnext\\\\nIO tools (text, CSV, HDF5, …)\\\\nOn this page\\\\nHead and tail\\\\nAttributes and underlying data\\\\nAccelerated operations\\\\nFlexible binary operations\\\\nMatching / broadcasting behavior\\\\nMissing data / operations with fill values\\\\nFlexible comparisons\\\\nBoolean reductions\\\\nComparing if objects are equivalent\\\\nComparing array-like objects\\\\nCombining overlapping data sets\\\\nGeneral DataFrame combine\\\\nDescriptive statistics\\\\nSummarizing data: describe\\\\nIndex of min/max values\\\\nValue counts (histogramming) / mode\\\\nDiscretization and quantiling\\\\nFunction application\\\\nTablewise function application\\\\nRow or column-wise function application\\\\nAggregation API\\\\nAggregating with multiple functions\\\\nAggregating with a dict\\\\nCustom describe\\\\nTransform API\\\\nTransform with multiple functions\\\\nTransforming with a dict\\\\nApplying elementwise functions\\\\nReindexing and altering labels\\\\nReindexing to align with another object\\\\nAligning objects with each other with\\\\nalign\\\\nFilling while reindexing\\\\nLimits on filling while reindexing\\\\nDropping labels from an axis\\\\nRenaming / mapping labels\\\\nIteration\\\\nitems\\\\niterrows\\\\nitertuples\\\\n.dt accessor\\\\nVectorized string methods\\\\nSorting\\\\nBy index\\\\nBy values\\\\nBy indexes and values\\\\nsearchsorted\\\\nsmallest / largest values\\\\nSorting by a MultiIndex column\\\\nCopying\\\\ndtypes\\\\ndefaults\\\\nupcasting\\\\nastype\\\\nobject conversion\\\\ngotchas\\\\nSelecting columns based on\\\\ndtype\\\\nShow Source\\\\n\\\\n--- Page Break ---\\\\n\\\\n']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba1b65e4-472f-48a8-9d29-23c7b11821f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=100,\n",
    "    length_function=len,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bd30b71-1b08-40ab-91fc-c9e43715cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = texts_splitter.split_text(docs_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8605ff8d-4ad5-4e27-a474-768695566a90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! The text was split into 281 chunks.\n"
     ]
    }
   ],
   "source": [
    "num_chunks = len(chunks)\n",
    "print(f\"Success! The text was split into {num_chunks} chunks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f908ccf0-ca4d-4571-ac61-c6a97e77caf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'User Guide\\\\n10 minutes to pandas\\\\n10 minutes to pandas\\\\n#\\\\nThis is a short introduction to pandas, geared mainly for new users.\\nYou can see more complex recipes in the\\\\nCookbook\\\\n.\\\\nCustomarily, we import as follows:\\\\nIn [1]:\\\\nimport\\\\nnumpy\\\\nas\\\\nnp\\\\nIn [2]:\\\\nimport\\\\npandas\\\\nas\\\\npd\\\\nBasic data structures in pandas\\\\n#\\\\nPandas provides two types of classes for handling data:\\\\nSeries\\\\n: a one-dimensional labeled array holding data of any type\\\\nsuch as integers, strings, Python objects etc.\\\\nDataFrame\\\\n: a two-dimensional data structure that holds data like\\na two-dimension array or a table with rows and columns.\\\\nObject creation\\\\n#\\\\nSee the\\\\nIntro to data structures section\\\\n.\\\\nCreating a\\\\nSeries\\\\nby passing a list of values, letting pandas create'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2050645d-ffd4-4243-843c-771ed46c7922",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a290d460-8209-44bf-a4c5-7b63c23dbc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "PERSIST_DIRECTORY = 'chroma_db_1'\n",
    "EMBEDDING_MODEL_NAME = \"all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "074f7867-9a94-4d67-a1e0-7247764ea189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain_0():\n",
    "    embedding_model = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    vectordb = Chroma(\n",
    "        persist_directory=PERSIST_DIRECTORY, \n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "    \n",
    "    retriever = vectordb.as_retriever()\n",
    "    \n",
    "    llm = ChatOllama(model=\"llama3\") \n",
    "    \n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=llm,\n",
    "        chain_type=\"stuff\",\n",
    "        retriever=retriever,\n",
    "        return_source_documents=True\n",
    "    )\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9ed7688-630a-4f8f-81d3-361442ffc3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_question_0(chain, query):\n",
    "    result = chain.invoke({\"query\" : query})\n",
    "    print(\"\\n Answer: \")\n",
    "    print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e3870293-0ecc-4ec9-bf56-7d959886c689",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\varri\\AppData\\Local\\Temp\\ipykernel_28548\\1955739520.py:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
      "C:\\Users\\varri\\docu_helper_agent\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\varri\\AppData\\Local\\Temp\\ipykernel_28548\\1955739520.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(\n",
      "C:\\Users\\varri\\AppData\\Local\\Temp\\ipykernel_28548\\1955739520.py:11: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  llm = ChatOllama(model=\"llama3\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Answer: \n",
      "To create a series in pandas, you can use the `pd.Series()` function or the `Series` constructor. Here are some examples:\n",
      "\n",
      "1. From a list:\n",
      "```\n",
      "import pandas as pd\n",
      "\n",
      "my_list = [1, 2, 3, 4, 5]\n",
      "my_series = pd.Series(my_list)\n",
      "print(my_series)\n",
      "```\n",
      "\n",
      "This will create a series with integer values.\n",
      "\n",
      "2. From a dictionary:\n",
      "```\n",
      "import pandas as pd\n",
      "\n",
      "my_dict = {'a': 1, 'b': 2, 'c': 3}\n",
      "my_series = pd.Series(my_dict)\n",
      "print(my_series)\n",
      "```\n",
      "\n",
      "This will create a series with string keys and integer values.\n",
      "\n",
      "3. From a scalar value (repeat the value for all indices):\n",
      "```\n",
      "import pandas as pd\n",
      "\n",
      "scalar_value = 5\n",
      "my_series = pd.Series([scalar_value] * 5, index=range(5))\n",
      "print(my_series)\n",
      "```\n",
      "\n",
      "This will create a series with all elements equal to `scalar_value` and indices from 0 to 4.\n",
      "\n",
      "Note that if you don't specify an index, pandas will automatically assign default integer indices starting from 0.\n"
     ]
    }
   ],
   "source": [
    "qa_chain = create_qa_chain_0()\n",
    "\n",
    "question = \"How do I create a Series in pandas?\"\n",
    "\n",
    "ask_question_0(qa_chain, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a7c336-bb44-421e-99a2-025af9375068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab483f5f-efb2-4c74-b129-10a84d0d943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "302177e7-0b92-46a6-9dc1-0be0f6109de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qa_chain_1():\n",
    "    embedding_model = SentenceTransformerEmbeddings(model_name=EMBEDDING_MODEL_NAME)\n",
    "    \n",
    "    vectordb = Chroma(\n",
    "        persist_directory=PERSIST_DIRECTORY, \n",
    "        embedding_function=embedding_model\n",
    "    )\n",
    "    \n",
    "    retriever = vectordb.as_retriever()\n",
    "    \n",
    "    llm = ChatOllama(model=\"llama3\")\n",
    "\n",
    "    memory = ConversationBufferMemory(\n",
    "        memory_key=\"chat_history\", \n",
    "        return_messages=True\n",
    "    )\n",
    "\n",
    "    qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "        llm=llm,\n",
    "        retriever=retriever,\n",
    "        memory=memory\n",
    "    )\n",
    "\n",
    "    return qa_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9211fc0b-ff92-4625-b3fb-dc0b39eb7905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot ready! Type 'exit' to end the conversation.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question about pandas:  How do I create a Series in pandas?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: To create a Series in pandas, you can use the `pandas.Series()` function or pass a dictionary or iterable to the `pandas.DataFrame()` function.\n",
      "\n",
      "Here are some examples:\n",
      "\n",
      "1. Create a Series from a dictionary:\n",
      "```\n",
      "import pandas as pd\n",
      "data = {'A': 1, 'B': 2, 'C': 3}\n",
      "series = pd.Series(data)\n",
      "print(series)\n",
      "```\n",
      "\n",
      "This will create a Series with the keys from the dictionary and values.\n",
      "\n",
      "2. Create a Series from an iterable (like a list or tuple):\n",
      "```\n",
      "import pandas as pd\n",
      "data = [1, 2, 3, 4, 5]\n",
      "series = pd.Series(data)\n",
      "print(series)\n",
      "```\n",
      "\n",
      "In this case, the indices will be automatically created based on the order of the values in the iterable.\n",
      "\n",
      "3. Create a Series with specific index:\n",
      "```\n",
      "import pandas as pd\n",
      "data = [1, 2, 3, 4, 5]\n",
      "index = ['A', 'B', 'C', 'D', 'E']\n",
      "series = pd.Series(data, index=index)\n",
      "print(series)\n",
      "```\n",
      "\n",
      "In this case, you can specify the indices for your Series.\n",
      "\n",
      "Remember to import pandas as `pd` before creating a Series.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Ask a question about pandas:  exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "qa_chain = create_qa_chain_1()\n",
    "\n",
    "print(\"Chatbot ready! Type 'exit' to end the conversation.\")\n",
    "\n",
    "while True:\n",
    "    query = input(\"Ask a question about pandas: \")\n",
    "    \n",
    "    if query.lower() == 'exit':\n",
    "        print(\"Goodbye!\")\n",
    "        break\n",
    "    \n",
    "    if query:\n",
    "        result = qa_chain.invoke({\"question\": query})\n",
    "        print(\"Answer:\", result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34274496-711d-4581-86ef-d81c1b5a3b3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdf082b-6026-4636-8367-cec5426c093f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed21600-205a-411d-ac9a-f545dacbdf32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d5503-32d4-4aed-b553-3d7a0d6a5d53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14c0774-14ef-429f-b866-84d06f501943",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74de951-d0da-486d-a01d-cda144cecb49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d740ffa-3900-4f0a-b4bd-50c15e2fe993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df1bb4a-b123-47a4-bf10-5445e40d2b4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a643b2f-b5e3-41a4-80cb-095a4294e1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain import hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5532307-ceac-4ed3-b67b-600253aa7a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model_name=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923e4d26-1738-43dc-b971-1bd2d3326736",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = create_qa_chain(llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5679c67c-cf45-419b-863d-0060548ca30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    Tool(\n",
    "        name=\"pandas_documentation_search\",\n",
    "        func=qa_chain.invoke,\n",
    "        description=\"\"\"Use this tool whenever you need to answer a question about the Python pandas library. This is your primary source for pandas-related queries.\"\"\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1afb51-4009-40e6-ac27-4983de43bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = hub.pull(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd9523b-4f0b-43e2-a5f6-11cfdc3b76f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c803cdc-faba-435e-bf6e-5e5643fd2f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352acca6-7299-4404-8ae2-761e98fd0f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How do I create a Series in pandas?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcce6d2-877a-4d47-aa97-b65649d0f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = agent_executor.invoke({\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f7533e-1384-4b9e-8b36-6b1f75398045",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[\"output\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5209d067-72da-4ac0-88f3-dfd7a1351eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8c0615-a4f6-400c-8218-494c730dffe5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (docu_helper_agent)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
